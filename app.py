# ==========================================
# B2B ì¶œê³  ëŒ€ì‹œë³´ë“œ (Google Sheet ê¸°ë°˜)
# - ë©”ë‰´ ìˆœì„œ: â‘  SKUë³„ ì¡°íšŒ -> â‘¡ ì£¼ì°¨ìš”ì•½ -> â‘¢ ì›”ê°„ìš”ì•½ -> â‘£ êµ­ê°€ë³„ ì¡°íšŒ -> â‘¤ BPëª…ë³„ ì¡°íšŒ
# - SKUë³„ ì¡°íšŒ UI: í’ˆëª©ì½”ë“œ ê²€ìƒ‰(ìƒë‹¨) -> ëˆ„ì  SKU Top10(í•˜ë‹¨)
# - SKU ìë™ ì½”ë©˜íŠ¸(ë£° ê¸°ë°˜): MoM(2ê°œì›”), ì¶”ì´(3ê°œì›”: íŒ¨í„´ ìƒì„¸), BP ê¸‰ì¦ ì‚¬ë¡€(ì›”ë‹¨ìœ„)
# - ì½”ë©˜íŠ¸ UI: í—¤ë”-ë‚´ìš©ì€ ë¶™ì´ê³ , ë¸”ë¡ ê°„ê²©ë§Œ í™•ë³´(ê°€ë…ì„± ê°œì„ )
# - ì£¼ì°¨ ë¼ë²¨: ì¶œê³ ì¼ì ìš°ì„ (ì—†ìœ¼ë©´ ì‘ì—…ì™„ë£Œì¼)ë¡œ ì‚°ì •í•˜ì—¬ ìœ ë ¹ ì£¼ì°¨ ë°©ì§€
# - ì „ì£¼/ì „ì›” +30% ê¸‰ì¦ ë¦¬í¬íŠ¸: dtype(object) ì—ëŸ¬ ë°©ì§€(ì¦ê°€ë°°ìˆ˜ numeric ê°•ì œ)
# - âœ… ì£¼ì°¨/ì›”ê°„ ìë™ì½”ë©˜íŠ¸(ê¸°ì¡´ ìœ ì§€):
#    1) ì‹ ê·œ BP ì¶œê³ (ê³¼ê±° ì „ì²´ê¸°ê°„ì— ì—†ë˜ BPê°€ í•´ë‹¹ ì£¼/ì›”ì— ì²˜ìŒ ë“±ì¥)
#    2) ì§ì „ê¸°ê°„ ëŒ€ë¹„ KPI(í˜„ì¬ê°’ + ì¦ê° í‘œê¸°): ë°œì£¼ê±´ìˆ˜(ì£¼ë¬¸ë²ˆí˜¸ distinct)/ì¶œê³ ê±´ìˆ˜(ëŒ€í‘œí–‰)/ì¶œê³ ìˆ˜ëŸ‰/í‰ê·  ë¦¬ë“œíƒ€ì„
#    3) ì¹´í…Œê³ ë¦¬ ë¼ì¸ TOP2(ì¶œê³ ìˆ˜ëŸ‰ ê¸°ì¤€)
#    4) Top BP ì§‘ì¤‘ë„: BPëª…(ìˆ˜ëŸ‰) + ì ìœ ìœ¨
#    5) Top SKU ì§‘ì¤‘ë„: í’ˆëª©ì½”ë“œ/í’ˆëª©ëª…(ìˆ˜ëŸ‰) + ì ìœ ìœ¨
#    6) ì¶œê³ ì¼ ë¯¸ì • ë¦¬ìŠ¤í¬(ê°€ëŠ¥í•  ë•Œë§Œ í‘œì‹œ)
# - âœ… ì›”ê°„ ë¦¬í¬íŠ¸(ë²„íŠ¼ í´ë¦­ ì‹œ ìƒì„± + ë³µì‚¬ ê°€ëŠ¥):
#    - í•´ì™¸B2B/êµ­ë‚´B2B ì„¹ì…˜ ë¶„ë¦¬
#    - BPëª… ê¸°ë°˜ "ì‚¬ëŒì´ ì“°ëŠ” ë¬¸ì¥" í˜•íƒœ ìë™ ìƒì„±(ì¿ íŒ¡/ì˜¬ì˜/êµ­êµ°ë³µì§€ë‹¨ ë“±)
#    - í•´ì™¸B2Bë§Œ JP/CN ë¼ì¸ ì œì™¸ ì „ì›” ëŒ€ë¹„ ì¦ê°€ SKU(%ë¡œ í‘œí˜„)
#    - ì°¨ì›”(ë‹¤ìŒë‹¬) ëŒ€ëŸ‰ ì¶œê³  ì˜ˆì • Top3: ì¶œê³ ì¼ì ê¸°ì¤€, BP/í’ˆëª©/ìˆ˜ëŸ‰ + (íŠ¹ì´ ì—†ìœ¼ë©´ ìƒëµ)
# ==========================================

import re
import streamlit as st
import pandas as pd
import html
from datetime import date

# =========================
# ì»¬ëŸ¼ëª… í‘œì¤€í™” (RAW ê¸°ì¤€)
# =========================
COL_QTY = "ìš”ì²­ìˆ˜ëŸ‰"
COL_YEAR = "ë…„"
COL_MONTH = "ì›”1"
COL_WEEK_LABEL = "ì£¼ì°¨"
COL_DONE = "ì‘ì—…ì™„ë£Œ"
COL_SHIP = "ì¶œê³ ì¼ì"
COL_LT2 = "ë¦¬ë“œíƒ€ì„2"
COL_BP = "BPëª…"
COL_MAIN = "ëŒ€í‘œí–‰"
COL_CUST1 = "ê±°ë˜ì²˜êµ¬ë¶„1"
COL_CUST2 = "ê±°ë˜ì²˜êµ¬ë¶„2"
COL_CLASS = "ì œí’ˆë¶„ë¥˜"
COL_ITEM_CODE = "í’ˆëª©ì½”ë“œ"
COL_ITEM_NAME = "í’ˆëª©ëª…"
COL_ORDER_DATE = "ë°œì£¼ì¼ì"
COL_ORDER_NO = "ì£¼ë¬¸ë²ˆí˜¸"  # âœ… ë°œì£¼ê±´ìˆ˜ = ì£¼ë¬¸ë²ˆí˜¸ distinct (ì¤‘ë³µ ì œê±°)

CATEGORY_COL_CANDIDATES = [
    "ì¹´í…Œê³ ë¦¬ ë¼ì¸", "ì¹´í…Œê³ ë¦¬ë¼ì¸", "ì¹´í…Œê³ ë¦¬", "ì¹´í…Œê³ ë¦¬(Line)", "ì¹´í…Œê³ ë¦¬_LINE", "Category Line", "Category"
]

KEEP_CLASSES = ["B0", "B1"]
LT_ONLY_CUST1 = "í•´ì™¸B2B"
SPIKE_FACTOR = 1.3  # +30%

# =========================
# Google Sheet ì„¤ì •
# =========================
GSHEET_ID = "1jbWMgV3fudWCQ1qhG0lCysZGGFCo4loTIf-j3iuaqOI"
GSHEET_GID = "15468212"
HEADER_ROW_0BASED = 6

# =========================
# Streamlit ì„¤ì •
# =========================
st.set_page_config(page_title="B2B ì¶œê³  ëŒ€ì‹œë³´ë“œ (Google Sheet ê¸°ë°˜)", layout="wide")

# -------------------------
# UI Style
# -------------------------
BASE_CSS = """
<style>
.block-container {padding-top: 1.2rem; padding-bottom: 2.5rem;}
h1, h2, h3 {letter-spacing: -0.2px;}
.small-note {color:#6b7280; font-size: 0.9rem;}

.kpi-wrap {display:flex; gap:0.75rem; flex-wrap:wrap; margin: 0.25rem 0 0.75rem 0;}
.kpi-card {
  background: #ffffff;
  border: 1px solid #e5e7eb;
  border-radius: 14px;
  padding: 0.9rem 0.95rem;
  min-width: 180px;
  flex: 1 1 180px;
  box-shadow: 0 1px 0 rgba(0,0,0,0.02);
}
.kpi-title {color:#6b7280; font-size:0.9rem; margin-bottom:0.35rem;}
.kpi-value {font-size:1.35rem; font-weight:700; color:#111827; line-height:1.2;}
.kpi-big {font-size:1.55rem; font-weight:800; color:#111827; line-height:1.15;}
.kpi-muted {color:#6b7280; font-size:0.85rem; margin-top:0.15rem; white-space:normal; word-break:break-word;}

.mini-kpi-wrap{display:flex; gap:0.6rem; flex-wrap:wrap; margin:0.55rem 0 0.25rem 0;}
.mini-kpi{
  background:#f9fafb;
  border:1px solid #e5e7eb;
  border-radius:12px;
  padding:0.55rem 0.7rem;
  display:flex;
  align-items:baseline;
  gap:0.55rem;
}
.mini-kpi .t{color:#6b7280; font-size:0.9rem;}
.mini-kpi .v{color:#111827; font-size:1.05rem; font-weight:800; font-variant-numeric: tabular-nums;}

.pretty-table-wrap {margin-top: 0.25rem;}
.table-frame{
  border: 1px solid #e5e7eb;
  border-radius: 14px;
  overflow: hidden;
  background: #fff;
}
.table-scroll{
  height: 520px;
  overflow: auto;
  position: relative;
}
table.pretty-table{
  width: 100%;
  border-collapse: separate;
  border-spacing: 0;
  background: #fff;
  font-size: 0.93rem;
}
.pretty-table thead th{
  position: -webkit-sticky;
  position: sticky;
  top: 0;
  background: #f9fafb;
  color: #111827;
  text-align: left;
  padding: 10px 10px;
  border-bottom: 1px solid #e5e7eb;
  z-index: 10;
  white-space: nowrap;
  box-shadow: 0 1px 0 rgba(0,0,0,0.06);
}
.pretty-table tbody td{
  padding: 10px 10px;
  border-bottom: 1px solid #f3f4f6;
  vertical-align: top;
}
.pretty-table tbody tr:nth-child(even) td {background: #fcfcfd;}
.pretty-table tbody tr:hover td {background: #f7fbff;}
.wrap {white-space: normal; word-break: break-word; line-height: 1.25rem;}
.mono {font-variant-numeric: tabular-nums;}
hr {margin: 1.2rem 0;}

/* âœ… ì½”ë©˜íŠ¸ UI */
.comment-block { margin: 0.6rem 0 1.05rem 0; }
.comment-title{
  font-weight: 900;
  font-size: 1.06rem;
  margin: 0.2rem 0 0.25rem 0;
}
.comment{
  margin: 0.08rem 0 0 0;
  line-height: 1.55;
}
</style>
"""
st.markdown(BASE_CSS, unsafe_allow_html=True)

# -------------------------
# Utils
# -------------------------
def to_bool_true(s: pd.Series) -> pd.Series:
    x = s.fillna("").astype(str).str.strip().str.upper()
    return x.isin(["TRUE", "T", "1", "Y", "YES"])

def safe_dt(df: pd.DataFrame, col: str) -> None:
    if col in df.columns:
        df[col] = pd.to_datetime(df[col], errors="coerce")

def safe_num(df: pd.DataFrame, col: str) -> None:
    if col in df.columns:
        s = df[col].astype(str).str.replace(",", "", regex=False).str.strip()
        s = s.replace({"": None, "nan": None, "None": None})
        df[col] = pd.to_numeric(s, errors="coerce")

def uniq_sorted(df: pd.DataFrame, col: str):
    if col not in df.columns:
        return []
    return sorted(df[col].dropna().astype(str).unique().tolist())

def fmt_date(dtval) -> str:
    if pd.isna(dtval):
        return "-"
    return pd.to_datetime(dtval).strftime("%Y-%m-%d")

def need_cols(df: pd.DataFrame, cols: list[str], title: str = "í•„ìš” ì»¬ëŸ¼ ëˆ„ë½"):
    missing = [c for c in cols if c not in df.columns]
    if missing:
        st.warning(f"{title}: {missing}")
        return False
    return True

def normalize_text_cols(df: pd.DataFrame, cols: list[str]) -> None:
    for c in cols:
        if c in df.columns:
            df[c] = df[c].astype(str).str.strip()

def _escape(x) -> str:
    if pd.isna(x):
        return ""
    return html.escape(str(x))

def _fmt_num_for_table(v) -> str:
    if pd.isna(v):
        return ""
    try:
        if isinstance(v, (int,)) and not isinstance(v, bool):
            return f"{v:,}"
        if isinstance(v, float):
            if float(v).is_integer():
                return f"{int(v):,}"
            return f"{v:,.2f}"
        vv = float(v)
        if vv.is_integer():
            return f"{int(vv):,}"
        return f"{vv:,.2f}"
    except Exception:
        return str(v)

def render_pretty_table(
    df: pd.DataFrame,
    height: int = 520,
    wrap_cols: list[str] | None = None,
    col_width_px: dict[str, int] | None = None,
    number_cols: list[str] | None = None,
):
    wrap_cols = wrap_cols or []
    col_width_px = col_width_px or {}
    number_cols = number_cols or []

    if df is None or df.empty:
        st.info("í‘œì‹œí•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return

    cols = list(df.columns)

    colgroup = "<colgroup>"
    for c in cols:
        w = col_width_px.get(c)
        colgroup += f'<col style="width:{int(w)}px;">' if w else "<col>"
    colgroup += "</colgroup>"

    thead = "<thead><tr>" + "".join([f"<th>{_escape(c)}</th>" for c in cols]) + "</tr></thead>"

    tbody_rows = []
    for _, row in df.iterrows():
        tds = []
        for c in cols:
            v = row[c]
            cls = []
            if c in wrap_cols:
                cls.append("wrap")
            if c in number_cols:
                cls.append("mono")
                v_disp = _fmt_num_for_table(v)
            else:
                v_disp = "" if pd.isna(v) else str(v)
            class_attr = f' class="{" ".join(cls)}"' if cls else ""
            tds.append(f"<td{class_attr}>{_escape(v_disp)}</td>")
        tbody_rows.append("<tr>" + "".join(tds) + "</tr>")
    tbody = "<tbody>" + "".join(tbody_rows) + "</tbody>"

    st.markdown(
        f"""
        <div class="pretty-table-wrap">
          <div class="table-frame">
            <div class="table-scroll" style="height:{int(height)}px;">
              <table class="pretty-table">
                {colgroup}
                {thead}
                {tbody}
              </table>
            </div>
          </div>
        </div>
        """,
        unsafe_allow_html=True
    )

def render_mini_kpi(label: str, value: str):
    st.markdown(
        f"""
        <div class="mini-kpi-wrap">
          <div class="mini-kpi">
            <div class="t">{html.escape(label)}</div>
            <div class="v">{html.escape(value)}</div>
          </div>
        </div>
        """,
        unsafe_allow_html=True
    )

# -------------------------
# Label helpers
# -------------------------
def make_month_label(year: int, month: int) -> str:
    return f"{int(year)}ë…„ {int(month)}ì›”"

def parse_week_label_key(label: str) -> tuple[int, int, int]:
    y = m = w = 0
    try:
        my = re.search(r"(\d{4})\s*ë…„", str(label))
        mm = re.search(r"(\d+)\s*ì›”", str(label))
        mw = re.search(r"(\d+)\s*ì£¼ì°¨", str(label))
        if my: y = int(my.group(1))
        if mm: m = int(mm.group(1))
        if mw: w = int(mw.group(1))
    except Exception:
        pass
    return (y, m, w)

def parse_month_label_key(label: str) -> tuple[int, int]:
    y = m = 0
    try:
        my = re.search(r"(\d{4})\s*ë…„", str(label))
        mm = re.search(r"(\d+)\s*ì›”", str(label))
        if my: y = int(my.group(1))
        if mm: m = int(mm.group(1))
    except Exception:
        pass
    return (y, m)

def week_label_from_date(dt: pd.Timestamp) -> str | None:
    if pd.isna(dt):
        return None
    y = int(dt.year)
    m = int(dt.month)
    d = int(dt.day)
    wk = (d - 1) // 7 + 1
    return f"{y}ë…„ {m}ì›” {wk}ì£¼ì°¨"

def build_week_label_from_row_safe(row: pd.Series) -> str | None:
    ship_dt = row.get(COL_SHIP, pd.NaT)
    done_dt = row.get(COL_DONE, pd.NaT)
    base_dt = ship_dt if pd.notna(ship_dt) else done_dt
    if pd.notna(base_dt):
        return week_label_from_date(pd.to_datetime(base_dt, errors="coerce"))
    return None

def week_key_num_from_label(label: str) -> int | None:
    y, m, w = parse_week_label_key(label)
    if y <= 0 or m <= 0 or w <= 0:
        return None
    return y * 10000 + m * 100 + w

def month_key_num_from_label(label: str) -> int | None:
    y, m = parse_month_label_key(label)
    if y <= 0 or m <= 0:
        return None
    return y * 100 + m

# -------------------------
# ì½”ë©˜íŠ¸ ë Œë”
# -------------------------
def render_numbered_block(title: str, items: list[str]):
    if not items:
        return
    st.markdown(
        f"""
        <div class="comment-block">
          <div class="comment-title">{html.escape(title)}</div>
        """,
        unsafe_allow_html=True
    )
    for i, line in enumerate(items, start=1):
        st.markdown(f"""<div class="comment">{i}) {line}</div>""", unsafe_allow_html=True)
    st.markdown("</div>", unsafe_allow_html=True)

# -------------------------
# SKU ìë™ ì½”ë©˜íŠ¸
# -------------------------
def _fmt_int(x) -> str:
    try:
        return f"{int(round(float(x))):,}"
    except Exception:
        return "0"

def _fmt_date_or_mijung(x) -> str:
    if pd.isna(x) or x is None or str(x).strip() == "":
        return "ë¯¸ì •"
    try:
        return pd.to_datetime(x).strftime("%Y-%m-%d")
    except Exception:
        return str(x)

def sku_comment_mom(sku_month: pd.DataFrame) -> list[str]:
    if sku_month is None or sku_month.empty:
        return []
    m = sku_month.sort_values("_month_key")
    if len(m) < 2:
        return []
    prev = m.iloc[-2]
    cur = m.iloc[-1]
    prev_q = float(prev["qty"]) if pd.notna(prev["qty"]) else 0.0
    cur_q = float(cur["qty"]) if pd.notna(cur["qty"]) else 0.0
    if prev_q <= 0:
        return [f"ìµœê·¼ ì›”({cur['_month_label']}) ì¶œê³ ìˆ˜ëŸ‰ {_fmt_int(cur_q)} (ì§ì „ì›”({prev['_month_label']}) ë°ì´í„° 0/ë¶€ì¡±ìœ¼ë¡œ ì¦ê°ë¥  ì‚°ì • ë¶ˆê°€)"]
    pct = (cur_q / prev_q - 1) * 100
    direction = "ìƒìŠ¹" if pct > 0 else "í•˜ë½" if pct < 0 else "ë³€ë™ ì—†ìŒ"
    return [f"{prev['_month_label']} ëŒ€ë¹„ {cur['_month_label']} ì¶œê³ ëŸ‰ **{direction} ({pct:+.0f}%)** Â· {_fmt_int(prev_q)} â†’ {_fmt_int(cur_q)}"]

def sku_comment_trend(sku_month: pd.DataFrame) -> list[str]:
    if sku_month is None or sku_month.empty:
        return []
    m = sku_month.sort_values("_month_key")
    if len(m) < 3:
        return []

    last3 = m.iloc[-3:].copy()
    q0, q1, q2 = [float(x) if pd.notna(x) else 0.0 for x in last3["qty"].tolist()]
    l0, l1, l2 = last3["_month_label"].astype(str).tolist()

    if q0 < q1 < q2:
        return [f"ìµœê·¼ 3ê°œì›”({l0} â†’ {l2}) ê¸°ì¤€: ì¶œê³ ëŸ‰ **ì§€ì† ìƒìŠ¹** ( {_fmt_int(q0)} â†’ {_fmt_int(q2)} )"]
    if q0 > q1 > q2:
        return [f"ìµœê·¼ 3ê°œì›”({l0} â†’ {l2}) ê¸°ì¤€: ì¶œê³ ëŸ‰ **ì§€ì† í•˜ë½** ( {_fmt_int(q0)} â†’ {_fmt_int(q2)} )"]

    if q1 >= q0 and q1 >= q2 and (q1 > q0 or q1 > q2):
        d1 = q1 - q0
        d2 = q2 - q1
        return [f"ìµœê·¼ 3ê°œì›”({l0} â†’ {l2}) ê¸°ì¤€: **ìƒìŠ¹ í›„ í•˜ë½(í”¼í¬í˜•)** Â· {l0}â†’{l1} {_fmt_int(d1)} / {l1}â†’{l2} {_fmt_int(d2)}"]
    if q1 <= q0 and q1 <= q2 and (q1 < q0 or q1 < q2):
        d1 = q1 - q0
        d2 = q2 - q1
        return [f"ìµœê·¼ 3ê°œì›”({l0} â†’ {l2}) ê¸°ì¤€: **í•˜ë½ í›„ ë°˜ë“±(ë°”ë‹¥í˜•)** Â· {l0}â†’{l1} {_fmt_int(d1)} / {l1}â†’{l2} {_fmt_int(d2)}"]

    mid_vs_avg = q1 - (q0 + q2) / 2
    sign = "ìƒíšŒ" if mid_vs_avg > 0 else "í•˜íšŒ" if mid_vs_avg < 0 else "ìœ ì‚¬"
    return [f"ìµœê·¼ 3ê°œì›”({l0} â†’ {l2}) ê¸°ì¤€: **ë³€ë™(í˜¼ì¡°)** Â· ì¤‘ê°„ì›”({l1})ì´ ì–‘ë í‰ê·  ëŒ€ë¹„ {sign} ({_fmt_int(mid_vs_avg)})"]

def sku_comment_bp_spike(df_sku: pd.DataFrame, spike_factor=1.5, top_n=3) -> list[str]:
    if df_sku.empty or (COL_BP not in df_sku.columns) or (COL_QTY not in df_sku.columns):
        return []
    if "_month_label" not in df_sku.columns:
        return []

    m = (
        df_sku.dropna(subset=["_month_label"])
        .groupby([COL_BP, "_month_label"], dropna=False)[COL_QTY]
        .sum(min_count=1)
        .reset_index()
        .rename(columns={COL_QTY: "m_qty"})
    )
    if m.empty:
        return []

    m["_month_key"] = m["_month_label"].astype(str).apply(parse_month_label_key)

    spikes = []
    for bp, sub in m.groupby(COL_BP, dropna=False):
        sub = sub.sort_values("_month_key")
        if len(sub) < 2:
            continue

        for _, r in sub.iterrows():
            cur_month = r["_month_label"]
            cur_qty = float(r["m_qty"]) if pd.notna(r["m_qty"]) else 0.0
            others = sub[sub["_month_label"] != cur_month]["m_qty"].astype(float)
            baseline = float(others.mean()) if len(others) > 0 else 0.0
            if baseline <= 0:
                continue
            if cur_qty < baseline * spike_factor:
                continue
            pct = (cur_qty / baseline - 1) * 100

            sub_ship = df_sku[
                (df_sku[COL_BP].astype(str).str.strip() == str(bp).strip()) &
                (df_sku["_month_label"].astype(str) == str(cur_month))
            ].copy()
            ship_dt = pd.to_datetime(sub_ship[COL_SHIP], errors="coerce") if COL_SHIP in sub_ship.columns else pd.Series([pd.NaT])
            ship_pick = ship_dt.min() if ship_dt.notna().any() else pd.NaT

            spikes.append({
                "bp": str(bp),
                "month": str(cur_month),
                "ship": ship_pick,
                "pct": pct,
                "qty": cur_qty,
                "baseline": baseline
            })

    if not spikes:
        return []

    spikes = sorted(spikes, key=lambda x: x["pct"], reverse=True)[:top_n]
    out = []
    for s in spikes:
        out.append(
            f"{s['bp']} ì—ì„œ {_fmt_date_or_mijung(s['ship'])} ({s['month']}) ê¸°ì¡´ í‰ê·  ëŒ€ë¹„ **{s['pct']:+.0f}%** Â· {_fmt_int(s['baseline'])} â†’ {_fmt_int(s['qty'])}"
        )
    return out

# -------------------------
# BP list helpers (í’ˆëª© Top5/Top10ìš©)
# -------------------------
def build_bp_list_map(df_period: pd.DataFrame) -> pd.DataFrame:
    if df_period.empty:
        return pd.DataFrame(columns=[COL_ITEM_CODE, COL_ITEM_NAME, "BPëª…(ìš”ì²­ìˆ˜ëŸ‰)"])

    bp_break = (
        df_period.groupby([COL_ITEM_CODE, COL_ITEM_NAME, COL_BP], dropna=False)[COL_QTY]
        .sum(min_count=1)
        .reset_index()
        .rename(columns={COL_QTY: "BPìš”ì²­ìˆ˜ëŸ‰"})
    )

    def format_bp_list(sub: pd.DataFrame) -> str:
        sub = sub.sort_values("BPìš”ì²­ìˆ˜ëŸ‰", ascending=False, na_position="last")
        out = []
        for _, r in sub.iterrows():
            bp = str(r.get(COL_BP, "")).strip()
            q = r.get("BPìš”ì²­ìˆ˜ëŸ‰", 0)
            if pd.isna(q):
                q = 0
            out.append(f"{bp}({int(round(q, 0)):,})")
        return ", ".join(out)

    return (
        bp_break.groupby([COL_ITEM_CODE, COL_ITEM_NAME], dropna=False)
        .apply(format_bp_list)
        .reset_index(name="BPëª…(ìš”ì²­ìˆ˜ëŸ‰)")
    )

def build_item_top5_with_bp(df_period: pd.DataFrame) -> pd.DataFrame:
    if df_period.empty:
        return pd.DataFrame(columns=["ìˆœìœ„", COL_ITEM_CODE, COL_ITEM_NAME, "ìš”ì²­ìˆ˜ëŸ‰_í•©", "BPëª…(ìš”ì²­ìˆ˜ëŸ‰)"])

    top5 = (
        df_period.groupby([COL_ITEM_CODE, COL_ITEM_NAME], dropna=False)[COL_QTY]
        .sum(min_count=1)
        .reset_index()
        .rename(columns={COL_QTY: "ìš”ì²­ìˆ˜ëŸ‰_í•©"})
        .sort_values("ìš”ì²­ìˆ˜ëŸ‰_í•©", ascending=False, na_position="last")
        .head(5)
        .copy()
    )

    bp_map = build_bp_list_map(df_period)
    top5 = top5.merge(bp_map, on=[COL_ITEM_CODE, COL_ITEM_NAME], how="left")
    top5.insert(0, "ìˆœìœ„", range(1, len(top5) + 1))
    top5["ìš”ì²­ìˆ˜ëŸ‰_í•©"] = top5["ìš”ì²­ìˆ˜ëŸ‰_í•©"].fillna(0).round(0).astype(int)
    top5["BPëª…(ìš”ì²­ìˆ˜ëŸ‰)"] = top5["BPëª…(ìš”ì²­ìˆ˜ëŸ‰)"].fillna("")
    return top5[["ìˆœìœ„", COL_ITEM_CODE, COL_ITEM_NAME, "ìš”ì²­ìˆ˜ëŸ‰_í•©", "BPëª…(ìš”ì²­ìˆ˜ëŸ‰)"]]

def build_item_top10_with_bp(df_period: pd.DataFrame) -> pd.DataFrame:
    if df_period.empty:
        return pd.DataFrame(columns=["ìˆœìœ„", COL_ITEM_CODE, COL_ITEM_NAME, "ìš”ì²­ìˆ˜ëŸ‰_í•©", "BPëª…(ìš”ì²­ìˆ˜ëŸ‰)"])

    top10 = (
        df_period.groupby([COL_ITEM_CODE, COL_ITEM_NAME], dropna=False)[COL_QTY]
        .sum(min_count=1)
        .reset_index()
        .rename(columns={COL_QTY: "ìš”ì²­ìˆ˜ëŸ‰_í•©"})
        .sort_values("ìš”ì²­ìˆ˜ëŸ‰_í•©", ascending=False, na_position="last")
        .head(10)
        .copy()
    )

    bp_map = build_bp_list_map(df_period)
    top10 = top10.merge(bp_map, on=[COL_ITEM_CODE, COL_ITEM_NAME], how="left")
    top10.insert(0, "ìˆœìœ„", range(1, len(top10) + 1))
    top10["ìš”ì²­ìˆ˜ëŸ‰_í•©"] = top10["ìš”ì²­ìˆ˜ëŸ‰_í•©"].fillna(0).round(0).astype(int)
    top10["BPëª…(ìš”ì²­ìˆ˜ëŸ‰)"] = top10["BPëª…(ìš”ì²­ìˆ˜ëŸ‰)"].fillna("")
    return top10[["ìˆœìœ„", COL_ITEM_CODE, COL_ITEM_NAME, "ìš”ì²­ìˆ˜ëŸ‰_í•©", "BPëª…(ìš”ì²­ìˆ˜ëŸ‰)"]]

def build_spike_report_only(cur_df: pd.DataFrame, prev_df: pd.DataFrame) -> pd.DataFrame:
    cols = [COL_ITEM_CODE, COL_ITEM_NAME, "ì´ì „_ìš”ì²­ìˆ˜ëŸ‰", "í˜„ì¬_ìš”ì²­ìˆ˜ëŸ‰", "ì¦ê°€ë°°ìˆ˜", "BPëª…(ìš”ì²­ìˆ˜ëŸ‰)"]
    if cur_df.empty:
        return pd.DataFrame(columns=cols)

    cur_sku = (
        cur_df.groupby([COL_ITEM_CODE, COL_ITEM_NAME], dropna=False)[COL_QTY]
        .sum(min_count=1)
        .reset_index(name="í˜„ì¬_ìš”ì²­ìˆ˜ëŸ‰")
    )

    prev_sku = (
        prev_df.groupby([COL_ITEM_CODE, COL_ITEM_NAME], dropna=False)[COL_QTY]
        .sum(min_count=1)
        .reset_index(name="ì´ì „_ìš”ì²­ìˆ˜ëŸ‰")
    ) if not prev_df.empty else pd.DataFrame(columns=[COL_ITEM_CODE, COL_ITEM_NAME, "ì´ì „_ìš”ì²­ìˆ˜ëŸ‰"])

    cmp = cur_sku.merge(prev_sku, on=[COL_ITEM_CODE, COL_ITEM_NAME], how="left")
    cmp["ì´ì „_ìš”ì²­ìˆ˜ëŸ‰"] = pd.to_numeric(cmp["ì´ì „_ìš”ì²­ìˆ˜ëŸ‰"], errors="coerce").fillna(0)
    cmp["í˜„ì¬_ìš”ì²­ìˆ˜ëŸ‰"] = pd.to_numeric(cmp["í˜„ì¬_ìš”ì²­ìˆ˜ëŸ‰"], errors="coerce").fillna(0)

    cmp["ì¦ê°€ë°°ìˆ˜"] = cmp.apply(
        lambda r: (r["í˜„ì¬_ìš”ì²­ìˆ˜ëŸ‰"] / r["ì´ì „_ìš”ì²­ìˆ˜ëŸ‰"]) if r["ì´ì „_ìš”ì²­ìˆ˜ëŸ‰"] > 0 else pd.NA,
        axis=1
    )

    spike = cmp[(cmp["ì´ì „_ìš”ì²­ìˆ˜ëŸ‰"] > 0) & (cmp["í˜„ì¬_ìš”ì²­ìˆ˜ëŸ‰"] >= cmp["ì´ì „_ìš”ì²­ìˆ˜ëŸ‰"] * SPIKE_FACTOR)].copy()

    bp_map = build_bp_list_map(cur_df)
    spike = spike.merge(bp_map, on=[COL_ITEM_CODE, COL_ITEM_NAME], how="left")

    spike = spike.sort_values("í˜„ì¬_ìš”ì²­ìˆ˜ëŸ‰", ascending=False, na_position="last")
    spike["í˜„ì¬_ìš”ì²­ìˆ˜ëŸ‰"] = spike["í˜„ì¬_ìš”ì²­ìˆ˜ëŸ‰"].fillna(0).round(0).astype(int)
    spike["ì´ì „_ìš”ì²­ìˆ˜ëŸ‰"] = spike["ì´ì „_ìš”ì²­ìˆ˜ëŸ‰"].fillna(0).round(0).astype(int)
    spike["ì¦ê°€ë°°ìˆ˜"] = pd.to_numeric(spike["ì¦ê°€ë°°ìˆ˜"], errors="coerce").round(2)
    spike["BPëª…(ìš”ì²­ìˆ˜ëŸ‰)"] = spike["BPëª…(ìš”ì²­ìˆ˜ëŸ‰)"].fillna("")
    return spike[cols]

# -------------------------
# âœ… ì£¼ì°¨/ì›”ê°„ ìë™ ì½”ë©˜íŠ¸ helpers (ê¸°ì¡´ ìœ ì§€)
# -------------------------
def _delta_arrow(diff: float) -> str:
    if pd.isna(diff) or abs(diff) < 1e-12:
        return "-"
    return "â–²" if diff > 0 else "â–¼"

def _delta_text(diff: float) -> str:
    if pd.isna(diff):
        return "-"
    try:
        d = int(round(float(diff)))
        return f"{d:+,}"
    except Exception:
        return "-"

def _fmt_delta(diff: float) -> str:
    return f"{_delta_text(diff)} {_delta_arrow(diff)}"

def _clean_nunique(series: pd.Series) -> int:
    if series is None:
        return 0
    s = series.astype(str).str.strip()
    s = s.replace({"": pd.NA, "nan": pd.NA, "None": pd.NA})
    return int(s.dropna().nunique())

def _get_order_cnt(df: pd.DataFrame) -> int:
    if df is None or df.empty or COL_ORDER_NO not in df.columns:
        return 0
    return _clean_nunique(df[COL_ORDER_NO])

def _get_ship_cnt(df: pd.DataFrame) -> int:
    """
    âœ… ì¶œê³ ê±´ìˆ˜ëŠ” ë°œì£¼ê±´ìˆ˜(ì£¼ë¬¸ë²ˆí˜¸)ì™€ ë¶„ë¦¬
    - ëŒ€í‘œí–‰(TRUE) ê¸°ì¤€ ì¹´ìš´íŠ¸ ìœ ì§€
    """
    if df is None or df.empty:
        return 0
    if "_is_rep" in df.columns:
        return int(df["_is_rep"].sum())
    return int(df.shape[0])

def _get_qty(df: pd.DataFrame) -> int:
    if df is None or df.empty or COL_QTY not in df.columns:
        return 0
    return int(round(float(df[COL_QTY].fillna(0).sum()), 0))

def _get_lt_mean(df: pd.DataFrame) -> float:
    if df is None or df.empty or COL_LT2 not in df.columns:
        return float("nan")
    s = pd.to_numeric(df[COL_LT2], errors="coerce").dropna()
    if s.empty:
        return float("nan")
    return float(s.mean())

def _find_category_col(df: pd.DataFrame) -> str | None:
    for c in CATEGORY_COL_CANDIDATES:
        if c in df.columns:
            return c
    return None

def new_bp_comment(all_df: pd.DataFrame, cur_df: pd.DataFrame, key_col_num: str, cur_key_num: int | None, top_n: int = 5) -> list[str]:
    if cur_df is None or cur_df.empty or COL_BP not in cur_df.columns:
        return []

    hist = all_df.copy()
    if key_col_num in hist.columns and cur_key_num is not None:
        hist_key = pd.to_numeric(hist[key_col_num], errors="coerce")
        hist = hist[hist_key.notna() & (hist_key.astype(int) < int(cur_key_num))]

    hist_bps = set(hist[COL_BP].dropna().astype(str).str.strip().tolist()) if (COL_BP in hist.columns and not hist.empty) else set()
    cur_bps = set(cur_df[COL_BP].dropna().astype(str).str.strip().tolist())

    new_bps = [bp for bp in cur_bps if bp and bp not in hist_bps]
    if not new_bps:
        return ["ì‹ ê·œ ì¶œê³  BP: ì—†ìŒ"]

    sub = cur_df[cur_df[COL_BP].astype(str).str.strip().isin(new_bps)].copy()
    if COL_QTY in sub.columns:
        g = sub.groupby(COL_BP)[COL_QTY].sum().sort_values(ascending=False).head(top_n)
        desc = ", ".join([f"{idx}({_fmt_int(val)})" for idx, val in g.items()])
    else:
        desc = ", ".join(new_bps[:top_n])

    return [f"ì‹ ê·œ ì¶œê³  BP: {desc}"]

def category_top_comment(cur_df: pd.DataFrame, top_n: int = 2) -> list[str]:
    if cur_df is None or cur_df.empty:
        return []
    cat_col = _find_category_col(cur_df)
    if not cat_col:
        return []
    if COL_QTY not in cur_df.columns:
        return []

    tmp = cur_df.copy()
    tmp[cat_col] = tmp[cat_col].astype(str).str.strip()
    g = (
        tmp.groupby(cat_col, dropna=False)[COL_QTY]
        .sum(min_count=1)
        .sort_values(ascending=False)
        .head(top_n)
    )
    if g.empty:
        return []
    desc = ", ".join([f"{idx}({_fmt_int(val)})" for idx, val in g.items()])
    return [f"ì¹´í…Œê³ ë¦¬ TOP{top_n}: {desc}"]

def concentration_comment(cur_df: pd.DataFrame) -> list[str]:
    """
    - 4) Top BP ì§‘ì¤‘ë„: 1ìœ„ BPëª…(ìˆ˜ëŸ‰) ì ìœ ìœ¨
    - 5) Top SKU ì§‘ì¤‘ë„: 1ìœ„ í’ˆëª©ì½”ë“œ / í’ˆëª©ëª…(ìˆ˜ëŸ‰) ì ìœ ìœ¨
    """
    if cur_df is None or cur_df.empty or COL_QTY not in cur_df.columns:
        return []

    total = float(cur_df[COL_QTY].fillna(0).sum())
    if total <= 0:
        return []

    out = []

    # Top BP
    if COL_BP in cur_df.columns:
        g = (
            cur_df.groupby(COL_BP, dropna=False)[COL_QTY]
            .sum(min_count=1)
            .sort_values(ascending=False)
        )
        if not g.empty:
            top_bp = str(g.index[0]).strip()
            top_bp_qty = float(g.iloc[0])
            top_bp_share = top_bp_qty / total * 100
            out.append(f"Top BP ì§‘ì¤‘ë„: 1ìœ„ {top_bp}({_fmt_int(top_bp_qty)}) {top_bp_share:.0f}%")

    # Top SKU
    if all(c in cur_df.columns for c in [COL_ITEM_CODE, COL_ITEM_NAME]):
        g2 = (
            cur_df.groupby([COL_ITEM_CODE, COL_ITEM_NAME], dropna=False)[COL_QTY]
            .sum(min_count=1)
            .sort_values(ascending=False)
        )
        if not g2.empty:
            (top_code, top_name) = g2.index[0]
            top_code = str(top_code).strip()
            top_name = str(top_name).strip()
            top_qty = float(g2.iloc[0])
            top_share = top_qty / total * 100
            out.append(f"Top SKU ì§‘ì¤‘ë„: 1ìœ„ {top_code} / {top_name}({_fmt_int(top_qty)}) {top_share:.0f}%")

    return out[:2]

def undated_ship_risk_comment(cur_df: pd.DataFrame) -> list[str]:
    if cur_df is None or cur_df.empty:
        return []
    if COL_SHIP not in cur_df.columns or COL_QTY not in cur_df.columns:
        return []

    total_qty = float(cur_df[COL_QTY].fillna(0).sum())
    if total_qty <= 0:
        return []

    ship_dt = pd.to_datetime(cur_df[COL_SHIP], errors="coerce")
    miss = cur_df[ship_dt.isna()].copy()
    miss_qty = float(miss[COL_QTY].fillna(0).sum()) if not miss.empty else 0.0

    if miss_qty <= 0:
        return []
    pct = miss_qty / total_qty * 100
    return [f"ì¶œê³ ì¼ ë¯¸ì • ìˆ˜ëŸ‰: {_fmt_int(miss_qty)} ({pct:.0f}%)"]

def period_kpi_delta_comment(cur_df: pd.DataFrame, prev_df: pd.DataFrame) -> list[str]:
    """
    ì˜ˆ) ë°œì£¼ê±´ìˆ˜ 35ê±´ (-17 â–¼) / ì¶œê³ ê±´ìˆ˜ 18ê±´ (+3 â–²) / ì¶œê³ ìˆ˜ëŸ‰ 10,000ê°œ (-500 â–¼) / í‰ê·  ë¦¬ë“œíƒ€ì„ 6.2ì¼ (-2 â–¼)
    """
    cur_order = _get_order_cnt(cur_df)
    prev_order = _get_order_cnt(prev_df)

    cur_ship = _get_ship_cnt(cur_df)
    prev_ship = _get_ship_cnt(prev_df)

    cur_qty = _get_qty(cur_df)
    prev_qty = _get_qty(prev_df)

    cur_lt = _get_lt_mean(cur_df)
    prev_lt = _get_lt_mean(prev_df)

    order_diff = cur_order - prev_order
    ship_diff = cur_ship - prev_ship
    qty_diff = cur_qty - prev_qty

    order_part = f"ë°œì£¼ê±´ìˆ˜ {cur_order}ê±´ ({_fmt_delta(order_diff)})"
    ship_part = f"ì¶œê³ ê±´ìˆ˜ {cur_ship}ê±´ ({_fmt_delta(ship_diff)})"
    qty_part = f"ì¶œê³ ìˆ˜ëŸ‰ {cur_qty:,}ê°œ ({_fmt_delta(qty_diff)})"

    if (not pd.isna(cur_lt)) and (not pd.isna(prev_lt)):
        lt_diff = cur_lt - prev_lt
        lt_part = f"í‰ê·  ë¦¬ë“œíƒ€ì„ {cur_lt:.1f}ì¼ ({_fmt_delta(lt_diff)})"
    elif (not pd.isna(cur_lt)) and pd.isna(prev_lt):
        lt_part = f"í‰ê·  ë¦¬ë“œíƒ€ì„ {cur_lt:.1f}ì¼ (ì§ì „ê¸°ê°„ ë°ì´í„° ë¶€ì¡±)"
    else:
        lt_part = "í‰ê·  ë¦¬ë“œíƒ€ì„ -"

    return [f"ì§ì „ê¸°ê°„ ëŒ€ë¹„: {order_part} / {ship_part} / {qty_part} / {lt_part}"]

# =========================
# âœ… ì›”ê°„ ë¦¬í¬íŠ¸(ë¬¸ì¥í˜•) helpers
# =========================
def _pct(curr: float, prev: float) -> float | None:
    if prev is None or prev <= 0:
        return None
    return (curr / prev - 1.0) * 100.0

def _sum_qty(df: pd.DataFrame) -> int:
    if df is None or df.empty or COL_QTY not in df.columns:
        return 0
    return int(round(float(df[COL_QTY].fillna(0).sum()), 0))

def _nunique(df: pd.DataFrame, col: str) -> int:
    if df is None or df.empty or col not in df.columns:
        return 0
    s = df[col].astype(str).str.strip().replace({"": pd.NA, "nan": pd.NA, "None": pd.NA})
    return int(s.dropna().nunique())

def _month_key(label: str) -> tuple[int, int]:
    return parse_month_label_key(label)

def _month_label_from_dt(dtval: pd.Timestamp) -> str | None:
    if pd.isna(dtval):
        return None
    return make_month_label(int(dtval.year), int(dtval.month))

def _top_bp_list(df: pd.DataFrame, top_n: int = 3) -> list[str]:
    if df is None or df.empty or COL_BP not in df.columns or COL_QTY not in df.columns:
        return []
    g = df.groupby(COL_BP)[COL_QTY].sum().sort_values(ascending=False).head(top_n)
    return [str(x) for x in g.index.tolist()]

def _format_bp_qty_breakdown(df: pd.DataFrame, sku_code: str, top_n: int = 3) -> str:
    if df is None or df.empty:
        return ""
    sub = df[df[COL_ITEM_CODE].astype(str).str.strip() == str(sku_code).strip()].copy()
    if sub.empty or COL_BP not in sub.columns or COL_QTY not in sub.columns:
        return ""
    g = sub.groupby(COL_BP)[COL_QTY].sum().sort_values(ascending=False).head(top_n)
    parts = [f"{bp}({_fmt_int(q)})" for bp, q in g.items()]
    return " / ".join(parts)

def _top_sku_mass_shipments(df: pd.DataFrame, top_n: int = 4, bp_break_top: int = 3) -> list[str]:
    if df is None or df.empty or not all(c in df.columns for c in [COL_ITEM_CODE, COL_ITEM_NAME, COL_QTY]):
        return []
    g = (
        df.groupby([COL_ITEM_CODE, COL_ITEM_NAME])[COL_QTY]
        .sum().sort_values(ascending=False).head(top_n)
    )
    out = []
    rank = 1
    for (code, name), qty in g.items():
        bd = _format_bp_qty_breakdown(df, code, top_n=bp_break_top)
        out.append(f"{rank}ï¸âƒ£ {code} {name} : {_fmt_int(qty)}ê°œ")
        if bd:
            out.append(f"â†’ {bd}")
        rank += 1
    return out

def _sku_mom_change_lines(cur_df: pd.DataFrame, prev_df: pd.DataFrame, top_n: int = 6) -> list[str]:
    if cur_df is None or cur_df.empty or COL_QTY not in cur_df.columns:
        return []
    cur = (
        cur_df.groupby([COL_ITEM_CODE, COL_ITEM_NAME])[COL_QTY]
        .sum().reset_index(name="cur")
    )
    prev = (
        prev_df.groupby([COL_ITEM_CODE, COL_ITEM_NAME])[COL_QTY]
        .sum().reset_index(name="prev")
    ) if (prev_df is not None and not prev_df.empty and COL_QTY in prev_df.columns) else pd.DataFrame(columns=[COL_ITEM_CODE, COL_ITEM_NAME, "prev"])

    m = cur.merge(prev, on=[COL_ITEM_CODE, COL_ITEM_NAME], how="left")
    m["prev"] = pd.to_numeric(m["prev"], errors="coerce").fillna(0)
    m["cur"] = pd.to_numeric(m["cur"], errors="coerce").fillna(0)

    m = m[m["prev"] > 0].copy()
    if m.empty:
        return []

    m["pct"] = (m["cur"] / m["prev"] - 1.0) * 100.0
    m = m.sort_values(["cur"], ascending=False).head(top_n)

    out = []
    for _, r in m.iterrows():
        code = str(r[COL_ITEM_CODE]).strip()
        name = str(r[COL_ITEM_NAME]).strip()
        pct = float(r["pct"])
        out.append(f"- {code} {name} : {pct:+.0f}%")
    return out

def _jp_cn_excluded_increase(cur_df: pd.DataFrame, prev_df: pd.DataFrame, jp_cn_tokens: list[str], top_n: int = 5) -> list[str]:
    if cur_df is None or cur_df.empty or COL_CUST2 not in cur_df.columns:
        return []

    def _is_jp_cn(x) -> bool:
        s = str(x).upper()
        return any(tok in s for tok in jp_cn_tokens)

    cur2 = cur_df[~cur_df[COL_CUST2].astype(str).apply(_is_jp_cn)].copy()
    prev2 = prev_df.copy()
    if prev2 is not None and not prev2.empty and COL_CUST2 in prev2.columns:
        prev2 = prev2[~prev2[COL_CUST2].astype(str).apply(_is_jp_cn)].copy()

    cur = cur2.groupby([COL_ITEM_CODE, COL_ITEM_NAME])[COL_QTY].sum().reset_index(name="cur")
    prev = prev2.groupby([COL_ITEM_CODE, COL_ITEM_NAME])[COL_QTY].sum().reset_index(name="prev") if (prev2 is not None and not prev2.empty) else pd.DataFrame(columns=[COL_ITEM_CODE, COL_ITEM_NAME, "prev"])

    m = cur.merge(prev, on=[COL_ITEM_CODE, COL_ITEM_NAME], how="left")
    m["prev"] = pd.to_numeric(m["prev"], errors="coerce").fillna(0)
    m["cur"] = pd.to_numeric(m["cur"], errors="coerce").fillna(0)

    m = m[(m["prev"] > 0) & (m["cur"] > m["prev"])].copy()
    if m.empty:
        return []

    m["pct"] = (m["cur"] / m["prev"] - 1.0) * 100.0
    m = m.sort_values(["pct", "cur"], ascending=False).head(top_n)

    out = []
    for _, r in m.iterrows():
        code = str(r[COL_ITEM_CODE]).strip()
        name = str(r[COL_ITEM_NAME]).strip()
        prevv = int(round(float(r["prev"]), 0))
        curr = int(round(float(r["cur"]), 0))
        pct = float(r["pct"])
        bd = _format_bp_qty_breakdown(cur2, code, top_n=3)
        out.append(f"- {code} {name}")
        out.append(f"  ì „ì›”: {prevv:,} â†’ ì´ë²ˆë‹¬: {curr:,} ({pct:+.0f}%)")
        if bd:
            out.append(f"  â†’ {bd}")
    return out

def _new_bp_first_ship_section(all_df: pd.DataFrame, cur_df: pd.DataFrame, cur_month_key_num: int | None, top_new: int = 3) -> list[str]:
    if cur_df is None or cur_df.empty or COL_BP not in cur_df.columns:
        return []

    hist = all_df.copy()
    if "_month_key_num" in hist.columns and cur_month_key_num is not None:
        hist = hist[pd.to_numeric(hist["_month_key_num"], errors="coerce").fillna(0).astype(int) < int(cur_month_key_num)]

    hist_bps = set(hist[COL_BP].dropna().astype(str).str.strip().tolist()) if (hist is not None and not hist.empty and COL_BP in hist.columns) else set()
    cur_bps = sorted(set(cur_df[COL_BP].dropna().astype(str).str.strip().tolist()))
    new_bps = [bp for bp in cur_bps if bp and bp not in hist_bps]
    if not new_bps:
        return []

    sub = cur_df[cur_df[COL_BP].astype(str).str.strip().isin(new_bps)].copy()
    g = sub.groupby(COL_BP)[COL_QTY].sum().sort_values(ascending=False).head(top_new)

    out = ["âœ… ì‹ ê·œ ì—…ì²´ ì²« ì¶œê³ "]
    for bp, qty in g.items():
        bpdf = sub[sub[COL_BP].astype(str).str.strip() == str(bp).strip()].copy()
        sku_cnt = _nunique(bpdf, COL_ITEM_CODE)
        out.append(f"- ì—…ì²´ëª… : {bp}")
        out.append(f"  ì´ {sku_cnt}SKU/ {_fmt_int(qty)}ê°œ ìˆ˜ëŸ‰ ì¶œê³ ")

        top_items = (
            bpdf.groupby([COL_ITEM_CODE, COL_ITEM_NAME])[COL_QTY]
            .sum().sort_values(ascending=False).head(4)
        )
        if not top_items.empty:
            out.append("  ì£¼ìš” ì¶œê³  í’ˆëª©")
            for (code, name), _q in top_items.items():
                out.append(f"  Â· {code}\t{name}")
    return out

def _next_month_heavy_plan(df_all_view: pd.DataFrame, cur_month_label: str, cust1_value: str, top_n: int = 3, min_qty: int = 10000) -> list[str]:
    if df_all_view is None or df_all_view.empty:
        return []
    if not all(c in df_all_view.columns for c in [COL_SHIP, COL_CUST1, COL_BP, COL_ITEM_CODE, COL_ITEM_NAME, COL_QTY]):
        return []

    y, m = _month_key(cur_month_label)
    if y <= 0 or m <= 0:
        return []
    ny, nm = (y + 1, 1) if m == 12 else (y, m + 1)
    next_month_label = make_month_label(ny, nm)

    ship_dt = pd.to_datetime(df_all_view[COL_SHIP], errors="coerce")
    sub = df_all_view[ship_dt.notna()].copy()
    sub = sub[sub[COL_CUST1].astype(str).str.strip() == cust1_value].copy()
    if sub.empty:
        return []

    sub["_ship_month"] = ship_dt.loc[sub.index].apply(_month_label_from_dt)
    sub = sub[sub["_ship_month"].astype(str) == str(next_month_label)].copy()
    if sub.empty:
        return []

    agg = sub.groupby([COL_BP, COL_ITEM_CODE, COL_ITEM_NAME])[COL_QTY].sum().reset_index(name="qty")

    idx = agg.groupby(COL_BP)["qty"].idxmax()
    pick = agg.loc[idx].sort_values("qty", ascending=False).head(top_n)

    if pick.empty:
        return []
    if float(pick["qty"].max()) < float(min_qty):
        return []  # íŠ¹ì´ ì—†ìœ¼ë©´ ìƒëµ

    out = [f"ğŸ—“ï¸ ì°¨ì›”({next_month_label}) ëŒ€ëŸ‰ ì¶œê³  ì˜ˆì • Top {min(top_n, len(pick))}"]
    for _, r in pick.iterrows():
        bp = str(r[COL_BP]).strip()
        code = str(r[COL_ITEM_CODE]).strip()
        name = str(r[COL_ITEM_NAME]).strip()
        qty = int(round(float(r["qty"]), 0))
        out.append(f"- {bp} / {code} {name} {qty:,}")
    return out

# ---- BPëª… ê¸°ë°˜ ë¬¸ì¥ í…œí”Œë¦¿(êµ­ë‚´B2B) ----
DOM_BP_PATTERNS = [
    ("ì¿ íŒ¡", ["ì¿ íŒ¡", "COUPANG"]),
    ("ì˜¬ì˜", ["ì˜¬ì˜", "OLIVE", "ì˜¬ë¦¬ë¸Œì˜", "OY"]),
    ("êµ­êµ°ë³µì§€ë‹¨", ["êµ­êµ°ë³µì§€ë‹¨", "PX", "êµ°", "ë³µì§€ë‹¨"]),
]

def _match_dom_bp_name(bp: str) -> str | None:
    s = str(bp).upper()
    for canon, toks in DOM_BP_PATTERNS:
        for t in toks:
            if str(t).upper() in s:
                return canon
    return None

def _bp_share_by_qty(df: pd.DataFrame, bp_name: str) -> float:
    if df is None or df.empty or COL_QTY not in df.columns or COL_BP not in df.columns:
        return 0.0
    tot = float(df[COL_QTY].fillna(0).sum())
    if tot <= 0:
        return 0.0
    sub = df[df[COL_BP].astype(str) == str(bp_name)].copy()
    return float(sub[COL_QTY].fillna(0).sum()) / tot

def _bp_share_by_orders(df: pd.DataFrame, bp_name: str) -> float:
    if df is None or df.empty or COL_ORDER_NO not in df.columns or COL_BP not in df.columns:
        return 0.0
    tot = _get_order_cnt(df)
    if tot <= 0:
        return 0.0
    sub = df[df[COL_BP].astype(str) == str(bp_name)].copy()
    return _get_order_cnt(sub) / tot

def _top_sku_for_bp(df: pd.DataFrame, bp_name: str) -> tuple[str, str, int] | None:
    if df is None or df.empty:
        return None
    sub = df[df[COL_BP].astype(str) == str(bp_name)].copy()
    if sub.empty:
        return None
    g = sub.groupby([COL_ITEM_CODE, COL_ITEM_NAME])[COL_QTY].sum().sort_values(ascending=False).head(1)
    if g.empty:
        return None
    (code, name), qty = g.index[0], float(g.iloc[0])
    return (str(code).strip(), str(name).strip(), int(round(qty, 0)))

def _mom_for_bp_sku(cur_df: pd.DataFrame, prev_df: pd.DataFrame, bp_name: str, sku_code: str) -> float | None:
    if prev_df is None or prev_df.empty:
        return None
    cur_sub = cur_df[(cur_df[COL_BP].astype(str) == str(bp_name)) & (cur_df[COL_ITEM_CODE].astype(str) == str(sku_code))]
    prev_sub = prev_df[(prev_df[COL_BP].astype(str) == str(bp_name)) & (prev_df[COL_ITEM_CODE].astype(str) == str(sku_code))]
    cur_qty = float(cur_sub[COL_QTY].fillna(0).sum()) if not cur_sub.empty else 0.0
    prev_qty = float(prev_sub[COL_QTY].fillna(0).sum()) if not prev_sub.empty else 0.0
    if prev_qty <= 0:
        return None
    return (cur_qty / prev_qty - 1.0) * 100.0

def _domestic_focus_section_human(cur_dom: pd.DataFrame, prev_dom: pd.DataFrame) -> list[str]:
    """
    âœ… êµ­ë‚´B2B 'ì‚¬ëŒì´ ì“°ëŠ” ë¬¸ì¥' í˜•íƒœ
    - ì „ì›” ëŒ€ë¹„ ì¶œê³ ê±´ìˆ˜(ì£¼ë¬¸ë²ˆí˜¸ distinct) ì¦ê°
    - ì¶œê³ ê±´ìˆ˜ Top BP / ì¶œê³ ìˆ˜ëŸ‰ Top BP ê°ê° ë¹„ì¤‘(%) í¬í•¨
    - ì¿ íŒ¡/ì˜¬ì˜/êµ­êµ°ë³µì§€ë‹¨ ë“± ë§¤ì¹­ë˜ëŠ” BPëŠ” ë¬¸ì¥ í…œí”Œë¦¿ìœ¼ë¡œ 1~2ì¤„ ìë™ ìƒì„±
    """
    if cur_dom is None or cur_dom.empty:
        return ["(êµ­ë‚´B2B) ì´ë²ˆë‹¬ ë°ì´í„° ì—†ìŒ"]

    out = []

    cur_orders = _get_order_cnt(cur_dom)
    prev_orders = _get_order_cnt(prev_dom)
    diff_orders = cur_orders - prev_orders
    out.append("âœ… ì „ì›” ëŒ€ë¹„ ì¶œê³ ê±´ìˆ˜ ì¦ê°€, ê±°ë˜ì²˜ëŠ” ì†Œìˆ˜ ì§‘ì¤‘" if diff_orders > 0 else "âœ… ì „ì›” ëŒ€ë¹„ ì¶œê³ ê±´ìˆ˜ ë³€ë™/ê°ì†Œ")
    out.append(f"- ë°œì£¼/ì¶œê³ ê±´ìˆ˜(ì£¼ë¬¸ë²ˆí˜¸ distinct): {cur_orders}ê±´ ({_fmt_delta(diff_orders)})")

    # Top BP by orders
    if COL_ORDER_NO in cur_dom.columns:
        tmp = cur_dom.copy()
        tmp["_ord"] = tmp[COL_ORDER_NO].astype(str).str.strip().replace({"": pd.NA, "nan": pd.NA, "None": pd.NA})
        ord_bp = tmp.dropna(subset=["_ord"]).groupby(COL_BP)["_ord"].nunique().sort_values(ascending=False)
        if not ord_bp.empty:
            top_bp_cnt = str(ord_bp.index[0])
            top_bp_cnt_val = int(ord_bp.iloc[0])
            top_bp_cnt_share = _bp_share_by_orders(cur_dom, top_bp_cnt) * 100
        else:
            top_bp_cnt = "-"
            top_bp_cnt_val = 0
            top_bp_cnt_share = 0.0
    else:
        top_bp_cnt = "-"
        top_bp_cnt_val = 0
        top_bp_cnt_share = 0.0

    # Top BP by qty
    if COL_QTY in cur_dom.columns:
        qty_bp = cur_dom.groupby(COL_BP)[COL_QTY].sum().sort_values(ascending=False)
        if not qty_bp.empty:
            top_bp_qty = str(qty_bp.index[0])
            top_bp_qty_val = int(round(float(qty_bp.iloc[0]), 0))
            top_bp_qty_share = _bp_share_by_qty(cur_dom, top_bp_qty) * 100
        else:
            top_bp_qty = "-"
            top_bp_qty_val = 0
            top_bp_qty_share = 0.0
    else:
        top_bp_qty = "-"
        top_bp_qty_val = 0
        top_bp_qty_share = 0.0

    out.append("âœ… ì¶œê³ ê±´ìˆ˜ ë¹„ì¤‘ì€ {}/ ì¶œê³ ìˆ˜ëŸ‰ ë¹„ì¤‘ì€ {} â†‘".format(top_bp_cnt if top_bp_cnt != "-" else "ìƒìœ„BP", top_bp_qty if top_bp_qty != "-" else "ìƒìœ„BP"))
    out.append(f"- ì¶œê³ ê±´ìˆ˜ Top BP: {top_bp_cnt} ({top_bp_cnt_val}ê±´, ì•½ {top_bp_cnt_share:.0f}%)")
    out.append(f"- ì¶œê³ ìˆ˜ëŸ‰ Top BP: {top_bp_qty} ({top_bp_qty_val:,}ê°œ, ì•½ {top_bp_qty_share:.0f}%)")

    # BPë³„ ë¬¸ì¥ ìƒì„±(ì¿ íŒ¡/ì˜¬ì˜/êµ­êµ°ë³µì§€ë‹¨)
    # 1) ìš°ì„  ì´ë²ˆë‹¬ ë“±ì¥ BP ì¤‘ ë§¤ì¹­ë˜ëŠ” BPë¥¼ ì°¾ëŠ”ë‹¤
    bps = cur_dom[COL_BP].dropna().astype(str).tolist() if COL_BP in cur_dom.columns else []
    # ê°™ì€ canonicalì´ ì—¬ëŸ¬ ê°œë©´(ì˜ˆ: ì˜¬ì˜ OY/ì˜¬ì˜) ìˆ˜ëŸ‰ í° BP í•˜ë‚˜ë§Œ
    canon_best = {}
    for bp in set([str(x).strip() for x in bps]):
        canon = _match_dom_bp_name(bp)
        if not canon:
            continue
        q = float(cur_dom[cur_dom[COL_BP].astype(str) == bp][COL_QTY].fillna(0).sum())
        if canon not in canon_best or q > canon_best[canon]["qty"]:
            canon_best[canon] = {"bp": bp, "qty": q}

    # 2) canonical ìš°ì„ ìˆœìœ„ëŒ€ë¡œ ë¬¸ì¥ ìƒì„±
    for canon in ["ì¿ íŒ¡", "ì˜¬ì˜", "êµ­êµ°ë³µì§€ë‹¨"]:
        if canon not in canon_best:
            continue
        bp_name = canon_best[canon]["bp"]
        top_sku = _top_sku_for_bp(cur_dom, bp_name)
        if not top_sku:
            continue
        code, name, qty = top_sku
        mom = _mom_for_bp_sku(cur_dom, prev_dom, bp_name, code)

        if canon == "ì¿ íŒ¡":
            share = _bp_share_by_qty(cur_dom, bp_name) * 100
            if mom is None:
                out.append(f"- {bp_name} : {code} {name} â†‘ : {bp_name} ì¶œê³ ëŸ‰ ì•½ {share:.0f}% ì°¨ì§€")
            else:
                out.append(f"- {bp_name} : {code} {name} â†‘ ({mom:+.0f}%) : {bp_name} ì¶œê³ ëŸ‰ ì•½ {share:.0f}% ì°¨ì§€")

        elif canon == "ì˜¬ì˜":
            # ë§ê³° í‚¤ì›Œë“œ ê°ì§€
            has_mg = ("ë§ê³°" in name) or (cur_dom[(cur_dom[COL_BP].astype(str) == bp_name) & (cur_dom[COL_ITEM_NAME].astype(str).str.contains("ë§ê³°", na=False))].shape[0] > 0)
            if has_mg:
                out.append(f"- {bp_name} : ë§ê³° ì„¸íŠ¸ ì¶œê³  ì§„í–‰ (ëŒ€í‘œ SKU: {code} {name} / {qty:,}ê°œ)")
            else:
                out.append(f"- {bp_name} : {code} {name} â†‘ ({qty:,}ê°œ)")

        elif canon == "êµ­êµ°ë³µì§€ë‹¨":
            out.append(f"- {bp_name} : {code} {name} {qty:,}ê°œ ì¶”ê°€ ì¶œê³ ")

    return out

def make_monthly_report_text_rich(
    month_label: str,
    all_view_df: pd.DataFrame,
    cur_month_df: pd.DataFrame,
    prev_month_df: pd.DataFrame,
    cur_month_key_num: int | None,
    jp_cn_tokens: list[str] = None,
) -> str:
    jp_cn_tokens = jp_cn_tokens or ["JP", "JAPAN", "CN", "CHINA", "ì¤‘êµ­", "ì¼ë³¸"]

    lines = []
    lines.append(f"{month_label} B2B í˜„í™© ê³µìœ  ë“œë¦½ë‹ˆë‹¤. (SAPí˜„í™©ì— ë”°ë¼ ìë£ŒëŠ” ì˜¤ì°¨ë²”ìœ„ê°€ ìˆì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤ğŸ™‚)")
    lines.append(":link:B2B ì›”ê°„ë¦¬í¬íŠ¸")
    lines.append("")

    # --- í•´ì™¸/êµ­ë‚´ ë¶„ë¦¬ ---
    cur_over = cur_month_df[cur_month_df[COL_CUST1].astype(str).str.strip() == "í•´ì™¸B2B"].copy() if (cur_month_df is not None and not cur_month_df.empty and COL_CUST1 in cur_month_df.columns) else pd.DataFrame()
    prev_over = prev_month_df[prev_month_df[COL_CUST1].astype(str).str.strip() == "í•´ì™¸B2B"].copy() if (prev_month_df is not None and not prev_month_df.empty and COL_CUST1 in prev_month_df.columns) else pd.DataFrame()

    cur_dom = cur_month_df[cur_month_df[COL_CUST1].astype(str).str.strip().isin(["êµ­ë‚´B2B", "êµ­ë‚´ B2B"])].copy() if (cur_month_df is not None and not cur_month_df.empty and COL_CUST1 in cur_month_df.columns) else pd.DataFrame()
    prev_dom = prev_month_df[prev_month_df[COL_CUST1].astype(str).str.strip().isin(["êµ­ë‚´B2B", "êµ­ë‚´ B2B"])].copy() if (prev_month_df is not None and not prev_month_df.empty and COL_CUST1 in prev_month_df.columns) else pd.DataFrame()

    # =====================
    # í•´ì™¸B2B ë¦¬í¬íŠ¸
    # =====================
    lines.append("í•´ì™¸B2B")

    # 1) ì‹ ê·œ ì—…ì²´ ì²« ì¶œê³ 
    new_bp_block = _new_bp_first_ship_section(all_df=all_view_df, cur_df=cur_over, cur_month_key_num=cur_month_key_num, top_new=3)
    if new_bp_block:
        lines += new_bp_block
        lines.append("")

    # 2) ì¶œê³ ëŸ‰ ì¦ê° ìš”ì•½ + ì£¼ìš” ì—…ì²´
    over_cur_qty = _sum_qty(cur_over)
    over_prev_qty = _sum_qty(prev_over)
    over_diff = over_cur_qty - over_prev_qty
    over_pct = _pct(over_cur_qty, over_prev_qty)
    if over_prev_qty > 0 and over_pct is not None:
        lines.append("âœ… ì¶œê³ ëŸ‰ ì¦ê° ìš”ì•½")
        lines.append(f"- ì¶œê³ ëŸ‰ ì „ì›” ëŒ€ë¹„ {'ëŒ€í­ ì¦ê°€' if over_diff > 0 else 'ê°ì†Œ/ë³€ë™'} ({over_diff:+,})")
        top_bps = _top_bp_list(cur_over, top_n=3)
        if top_bps:
            lines.append("- ì£¼ìš” ì—…ì²´")
            for bp in top_bps:
                lines.append(f"  {bp}")
        lines.append("")

    # 3) íŠ¹ì • SKU ëŒ€ëŸ‰ ì¶œê³ 
    mass_lines = _top_sku_mass_shipments(cur_over, top_n=4, bp_break_top=3)
    if mass_lines:
        lines.append("âœ… íŠ¹ì • SKU ëŒ€ëŸ‰ ì¶œê³  (Top4)")
        lines += mass_lines
        lines.append("")

    # 4) ì „ì›” ëŒ€ë¹„ ì£¼ìš” SKU ì¦ê° (ì§€ì†ì¶œê³  ëŒ€ì‹  'ì „ì›” ëŒ€ë¹„ ì¦ê°'ìœ¼ë¡œ í‘œê¸°)
    mom_sku_lines = _sku_mom_change_lines(cur_over, prev_over, top_n=6)
    if mom_sku_lines:
        lines.append("âœ… ì „ì›” ëŒ€ë¹„ ì£¼ìš” SKU ì¦ê°")
        lines += mom_sku_lines
        lines.append("")

    # 5) JP/CN ì œì™¸ ì¦ê°€ SKU (í•´ì™¸ë§Œ)
    jp_cn_lines = _jp_cn_excluded_increase(cur_over, prev_over, jp_cn_tokens=jp_cn_tokens, top_n=3)
    if jp_cn_lines:
        lines.append("âœ… JP, CN ë¼ì¸ ì œì™¸ ì „ì›” ëŒ€ë¹„ ì¶œê³ ëŸ‰ ì¦ê°€ SKU")
        lines += jp_cn_lines
        lines.append("")

    # 6) ì°¨ì›”(ë‹¤ìŒë‹¬) ëŒ€ëŸ‰ ì¶œê³  ì˜ˆì • Top3 (íŠ¹ì´ ì—†ìœ¼ë©´ ìƒëµ)
    next_plan = _next_month_heavy_plan(
        df_all_view=all_view_df,
        cur_month_label=month_label,
        cust1_value="í•´ì™¸B2B",
        top_n=3,
        min_qty=10000,
    )
    if next_plan:
        lines.append("")
        lines += next_plan

    lines.append("")
    lines.append("")

    # =====================
    # êµ­ë‚´B2B ë¦¬í¬íŠ¸ (ì‚¬ëŒ ë¬¸ì¥í˜•)
    # =====================
    lines.append("êµ­ë‚´B2B")
    lines += _domestic_focus_section_human(cur_dom, prev_dom)

    return "\n".join(lines)

# -------------------------
# Load RAW
# -------------------------
@st.cache_data(ttl=300)
def load_raw_from_gsheet() -> pd.DataFrame:
    csv_url = f"https://docs.google.com/spreadsheets/d/{GSHEET_ID}/export?format=csv&gid={GSHEET_GID}"
    df = pd.read_csv(csv_url, header=HEADER_ROW_0BASED)

    df.columns = df.columns.astype(str).str.strip()
    df = df.loc[:, ~df.columns.str.match(r"^Unnamed")]

    for c in [COL_SHIP, COL_DONE, COL_ORDER_DATE]:
        safe_dt(df, c)

    for c in [COL_QTY, COL_LT2, "ë¦¬ë“œíƒ€ì„1"]:
        safe_num(df, c)

    if (COL_LT2 not in df.columns) or (df[COL_LT2].dropna().empty):
        if all(c in df.columns for c in [COL_DONE, COL_ORDER_DATE]):
            df[COL_LT2] = (df[COL_DONE] - df[COL_ORDER_DATE]).dt.days
            safe_num(df, COL_LT2)

    normalize_text_cols(
        df,
        [COL_BP, COL_ITEM_CODE, COL_ITEM_NAME, COL_CUST1, COL_CUST2, COL_WEEK_LABEL, COL_CLASS, COL_MAIN, COL_ORDER_NO]
    )

    df["_is_rep"] = to_bool_true(df[COL_MAIN]) if COL_MAIN in df.columns else False
    df["_week_label"] = df.apply(build_week_label_from_row_safe, axis=1)

    if (COL_YEAR in df.columns) and (COL_MONTH in df.columns):
        y = pd.to_numeric(df[COL_YEAR], errors="coerce")
        m = pd.to_numeric(df[COL_MONTH], errors="coerce")
        df["_month_label"] = [
            make_month_label(yy, mm) if pd.notna(yy) and pd.notna(mm) else None
            for yy, mm in zip(y, m)
        ]
    else:
        df["_month_label"] = None

    df["_week_key_num"] = df["_week_label"].apply(lambda x: week_key_num_from_label(x) if pd.notna(x) else None)
    df["_month_key_num"] = df["_month_label"].apply(lambda x: month_key_num_from_label(x) if pd.notna(x) else None)

    return df

# -------------------------
# Main
# -------------------------
st.title("ğŸ“¦ B2B ì¶œê³  ëŒ€ì‹œë³´ë“œ")
st.caption("Google Sheet RAW ê¸°ë°˜ | ì œí’ˆë¶„ë¥˜ B0/B1 ê³ ì • | í•„í„°(ê±°ë˜ì²˜êµ¬ë¶„1/2/ì›”/BP) ë°˜ì˜")

if st.button("ğŸ”„ ë°ì´í„° ìƒˆë¡œê³ ì¹¨"):
    st.cache_data.clear()
    reset_keys = [
        "nav_menu", "wk_sel_week", "m_sel_month",
        "sku_query", "sku_candidate_pick", "sku_show_all_history",
        "f_cust1", "f_cust2", "f_month", "f_bp",
        "sku_ignore_month_filter",
        "monthly_report_text"
    ]
    for k in reset_keys:
        if k in st.session_state:
            del st.session_state[k]
    st.session_state["nav_menu"] = "â‘  SKUë³„ ì¡°íšŒ"
    st.rerun()

try:
    raw = load_raw_from_gsheet().copy()
except Exception as e:
    st.error("Google Sheetì—ì„œ RAW ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì˜¤ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
    st.code(str(e))
    st.stop()

if COL_CLASS in raw.columns:
    raw = raw[raw[COL_CLASS].astype(str).str.strip().isin(KEEP_CLASSES)].copy()
else:
    st.warning(f"'{COL_CLASS}' ì»¬ëŸ¼ì´ ì—†ì–´ ì œí’ˆë¶„ë¥˜(B0/B1) ê³ ì • í•„í„°ë¥¼ ì ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

# =========================
# Sidebar filters
# =========================
st.sidebar.header("í•„í„°")
st.sidebar.caption("ì œí’ˆë¶„ë¥˜ ê³ ì •: B0, B1")

cust1_list = uniq_sorted(raw, COL_CUST1)
sel_cust1 = st.sidebar.selectbox("ê±°ë˜ì²˜êµ¬ë¶„1", ["ì „ì²´"] + cust1_list, index=0, key="f_cust1")

pool1 = raw.copy()
if sel_cust1 != "ì „ì²´" and COL_CUST1 in pool1.columns:
    pool1 = pool1[pool1[COL_CUST1].astype(str).str.strip() == sel_cust1]

cust2_list = uniq_sorted(pool1, COL_CUST2)
sel_cust2 = st.sidebar.selectbox("ê±°ë˜ì²˜êµ¬ë¶„2", ["ì „ì²´"] + cust2_list, index=0, key="f_cust2")

pool2 = pool1.copy()
if sel_cust2 != "ì „ì²´" and COL_CUST2 in pool2.columns:
    pool2 = pool2[pool2[COL_CUST2].astype(str).str.strip() == sel_cust2]

month_labels = []
if "_month_label" in pool2.columns:
    month_labels = [x for x in pool2["_month_label"].dropna().astype(str).unique().tolist() if x.strip() != ""]
    month_labels = list(dict.fromkeys(month_labels))
    month_labels = sorted(month_labels, key=parse_month_label_key)

sel_month_label = st.sidebar.selectbox("ì›”", ["ì „ì²´"] + month_labels, index=0, key="f_month")

pool3 = pool2.copy()
if sel_month_label != "ì „ì²´":
    pool3 = pool3[pool3["_month_label"].astype(str) == str(sel_month_label)]

bp_list = uniq_sorted(pool3, COL_BP)
sel_bp = st.sidebar.selectbox("BPëª…", ["ì „ì²´"] + bp_list, index=0, key="f_bp")

df_view = pool3.copy()
if sel_bp != "ì „ì²´" and COL_BP in df_view.columns:
    df_view = df_view[df_view[COL_BP].astype(str).str.strip() == sel_bp]

df_rep = df_view[df_view["_is_rep"]].copy()

# =========================
# KPI cards
# =========================
total_qty = df_view[COL_QTY].fillna(0).sum() if COL_QTY in df_view.columns else None
total_cnt = int(df_rep.shape[0])
latest_done = df_view[COL_DONE].max() if COL_DONE in df_view.columns else None

avg_lt2_overseas = None
if all(c in df_view.columns for c in [COL_CUST1, COL_LT2]):
    overseas = df_view[df_view[COL_CUST1].astype(str).str.strip() == LT_ONLY_CUST1]
    if not overseas.empty and not overseas[COL_LT2].dropna().empty:
        avg_lt2_overseas = float(overseas[COL_LT2].dropna().mean())

top_bp_qty_name = "-"
top_bp_qty_val = "-"
if all(c in df_view.columns for c in [COL_BP, COL_QTY]) and not df_view.empty:
    g = df_view.groupby(COL_BP, dropna=False)[COL_QTY].sum().sort_values(ascending=False)
    if not g.empty:
        top_bp_qty_name = str(g.index[0])
        top_bp_qty_val = f"{float(g.iloc[0]):,.0f}"

top_bp_cnt_name = "-"
top_bp_cnt_val = "-"
if COL_BP in df_rep.columns and not df_rep.empty:
    g2 = df_rep.groupby(COL_BP).size().sort_values(ascending=False)
    if not g2.empty:
        top_bp_cnt_name = str(g2.index[0])
        top_bp_cnt_val = f"{int(g2.iloc[0]):,}"

st.markdown(
    f"""
    <div class="kpi-wrap">
      <div class="kpi-card">
        <div class="kpi-title">ì´ ì¶œê³ ìˆ˜ëŸ‰(í•©)</div>
        <div class="kpi-value">{(f"{total_qty:,.0f}" if total_qty is not None else "-")}</div>
      </div>
      <div class="kpi-card">
        <div class="kpi-title">ì´ ì¶œê³ ê±´ìˆ˜(í•©)</div>
        <div class="kpi-value">{total_cnt:,}</div>
      </div>
      <div class="kpi-card">
        <div class="kpi-title">ìµœê·¼ ì‘ì—…ì™„ë£Œì¼</div>
        <div class="kpi-value">{fmt_date(latest_done)}</div>
      </div>
      <div class="kpi-card">
        <div class="kpi-title">ë¦¬ë“œíƒ€ì„ í‰ê·  (í•´ì™¸B2B)</div>
        <div class="kpi-value">{(f"{avg_lt2_overseas:.1f}ì¼" if avg_lt2_overseas is not None else "-")}</div>
      </div>
      <div class="kpi-card">
        <div class="kpi-title">ì¶œê³ ìˆ˜ëŸ‰ TOP BP</div>
        <div class="kpi-big">{html.escape(top_bp_qty_val)}</div>
        <div class="kpi-muted">{html.escape(top_bp_qty_name)}</div>
      </div>
      <div class="kpi-card">
        <div class="kpi-title">ì¶œê³ ê±´ìˆ˜ TOP BP</div>
        <div class="kpi-big">{html.escape(top_bp_cnt_val)}</div>
        <div class="kpi-muted">{html.escape(top_bp_cnt_name)}</div>
      </div>
    </div>
    """,
    unsafe_allow_html=True
)
st.caption("â€» ë¦¬ë“œíƒ€ì„ ì§€í‘œëŠ” í•´ì™¸B2B(ê±°ë˜ì²˜êµ¬ë¶„1=í•´ì™¸B2B)ë§Œì„ ëŒ€ìƒìœ¼ë¡œ ê³„ì‚°ë©ë‹ˆë‹¤.")
st.divider()

# =========================
# Navigation
# =========================
nav = st.radio(
    "ë©”ë‰´",
    ["â‘  SKUë³„ ì¡°íšŒ", "â‘¡ ì£¼ì°¨ìš”ì•½", "â‘¢ ì›”ê°„ìš”ì•½", "â‘£ êµ­ê°€ë³„ ì¡°íšŒ", "â‘¤ BPëª…ë³„ ì¡°íšŒ"],
    horizontal=True,
    key="nav_menu"
)

# =========================
# â‘  SKUë³„ ì¡°íšŒ
# =========================
if nav == "â‘  SKUë³„ ì¡°íšŒ":
    st.subheader("SKUë³„ ì¡°íšŒ")

    ignore_month = st.checkbox("ì›” í•„í„° ë¬´ì‹œ(ì „ì²´ê¸°ê°„ ê¸°ì¤€ìœ¼ë¡œ SKU ì¡°íšŒ/ì½”ë©˜íŠ¸)", value=True, key="sku_ignore_month_filter")
    sku_scope = pool2.copy() if ignore_month else df_view.copy()

    if not need_cols(sku_scope, [COL_ITEM_CODE, COL_ITEM_NAME, COL_QTY, COL_SHIP, COL_BP], "SKUë³„ ì¡°íšŒ"):
        st.stop()

    st.markdown("### í’ˆëª©ì½”ë“œ ê²€ìƒ‰")
    show_all_history = st.checkbox("ì „ì²´ íˆìŠ¤í† ë¦¬ ë³´ê¸°", value=True, key="sku_show_all_history")

    base = sku_scope.copy()
    base[COL_ITEM_CODE] = base[COL_ITEM_CODE].astype(str).str.strip()
    base[COL_ITEM_NAME] = base[COL_ITEM_NAME].astype(str).str.strip()

    q = st.text_input(
        "í’ˆëª©ì½”ë“œ ê²€ìƒ‰ (ë¶€ë¶„ê²€ìƒ‰ ê°€ëŠ¥)",
        value="",
        placeholder="ì˜ˆ: B0GF057A1",
        key="sku_query"
    )

    if q.strip():
        q_norm = q.strip().upper()

        candidates = (
            base[base[COL_ITEM_CODE].str.upper().str.contains(re.escape(q_norm), na=False)][[COL_ITEM_CODE, COL_ITEM_NAME]]
            .dropna(subset=[COL_ITEM_CODE])
            .drop_duplicates(subset=[COL_ITEM_CODE])
            .sort_values(COL_ITEM_CODE)
            .reset_index(drop=True)
        )

        if candidates.empty:
            st.warning("í•´ë‹¹ í’ˆëª©ì½”ë“œê°€ í˜„ì¬ í•„í„° ë²”ìœ„ì—ì„œ ì¡°íšŒë˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
        else:
            if len(candidates) > 1:
                cand_map = dict(zip(candidates[COL_ITEM_CODE], candidates[COL_ITEM_NAME]))
                sel_code = st.selectbox(
                    "ê²€ìƒ‰ ê²°ê³¼ì—ì„œ ì„ íƒ",
                    candidates[COL_ITEM_CODE].tolist(),
                    key="sku_candidate_pick",
                    format_func=lambda x: f"{x} / {cand_map.get(x, '')}".strip()
                )
            else:
                sel_code = candidates.iloc[0][COL_ITEM_CODE]

            dsku = base[base[COL_ITEM_CODE] == sel_code].copy()

            item_name = "-"
            nn = dsku[COL_ITEM_NAME].dropna()
            if not nn.empty:
                item_name = str(nn.iloc[0]).strip()

            st.markdown(f"- **í’ˆëª©ì½”ë“œ:** {html.escape(sel_code)}")
            st.markdown(f"- **í’ˆëª©ëª…:** {html.escape(item_name)}")

            dsku[COL_SHIP] = dsku[COL_SHIP].replace("", pd.NA)

            if not show_all_history:
                today_ts = pd.Timestamp(date.today())
                ship_dt = pd.to_datetime(dsku[COL_SHIP], errors="coerce")
                dsku = dsku[(ship_dt.isna()) | (ship_dt >= today_ts)].copy()

            def ship_to_label(x):
                if pd.isna(x):
                    return "ë¯¸ì •"
                return fmt_date(x)

            dsku["ì¶œê³ ì˜ˆì •ì¼"] = dsku[COL_SHIP].apply(ship_to_label)

            st.markdown("### íŠ¹ì´ / ì´ìŠˆ í¬ì¸íŠ¸ (SKU ìë™ ì½”ë©˜íŠ¸)")

            sku_month = (
                dsku.dropna(subset=["_month_label"])
                .assign(_month_key=lambda x: x["_month_label"].astype(str).apply(parse_month_label_key))
                .groupby(["_month_label", "_month_key"], dropna=False)[COL_QTY]
                .sum(min_count=1)
                .reset_index()
                .rename(columns={COL_QTY: "qty"})
                .sort_values("_month_key")
            )

            mom_items = sku_comment_mom(sku_month)
            trend_items = sku_comment_trend(sku_month)
            bp_spike_items = sku_comment_bp_spike(dsku)

            if mom_items:
                render_numbered_block("ì›”ê°„ ì¦ê° (ìµœê·¼ 2ê°œì›”)", mom_items)
            if trend_items:
                render_numbered_block("ì¶”ì´ ì½”ë©˜íŠ¸ (ìµœê·¼ 3ê°œì›”, ë£° ê¸°ë°˜)", trend_items)
            if bp_spike_items:
                render_numbered_block("BPë³„ í‰ì†Œ ëŒ€ë¹„ ê¸‰ì¦ ì‚¬ë¡€(ì›” ë‹¨ìœ„)", bp_spike_items)

            if (not mom_items) and (not trend_items) and (not bp_spike_items):
                st.caption("ì½”ë©˜íŠ¸ ì‚°ì¶œì— í•„ìš”í•œ ì›”ë³„ ë°ì´í„°ê°€ ë¶€ì¡±í•©ë‹ˆë‹¤. (ì›” ë°ì´í„° 2ê°œì›” ì´ìƒ í•„ìš”)")

            st.divider()

            out = (
                dsku.groupby(["ì¶œê³ ì˜ˆì •ì¼", COL_BP], dropna=False)[COL_QTY]
                .sum(min_count=1)
                .reset_index()
                .rename(columns={COL_BP: "BPëª…", COL_QTY: "ìš”ì²­ìˆ˜ëŸ‰"})
            )
            out["ìš”ì²­ìˆ˜ëŸ‰"] = out["ìš”ì²­ìˆ˜ëŸ‰"].fillna(0).round(0).astype(int)
            total_sku_qty = int(out["ìš”ì²­ìˆ˜ëŸ‰"].fillna(0).sum()) if not out.empty else 0
            render_mini_kpi("ìš”ì²­ìˆ˜ëŸ‰ í•©ì‚°", f"{total_sku_qty:,}")

            out["_sort_date"] = pd.to_datetime(out["ì¶œê³ ì˜ˆì •ì¼"], errors="coerce")
            out = out.sort_values(
                by=["_sort_date", "ì¶œê³ ì˜ˆì •ì¼", "ìš”ì²­ìˆ˜ëŸ‰"],
                ascending=[True, True, False],
                na_position="last"
            ).drop(columns=["_sort_date"])

            render_pretty_table(
                out[["ì¶œê³ ì˜ˆì •ì¼", "BPëª…", "ìš”ì²­ìˆ˜ëŸ‰"]],
                height=520,
                wrap_cols=["BPëª…"],
                col_width_px={"ì¶œê³ ì˜ˆì •ì¼": 140, "BPëª…": 420, "ìš”ì²­ìˆ˜ëŸ‰": 120},
                number_cols=["ìš”ì²­ìˆ˜ëŸ‰"],
            )
    else:
        st.info("ìƒë‹¨ì— í’ˆëª©ì½”ë“œë¥¼ ì…ë ¥í•˜ë©´, í•´ë‹¹ SKUì˜ ì½”ë©˜íŠ¸ ë° íˆìŠ¤í† ë¦¬ê°€ í‘œì‹œë©ë‹ˆë‹¤.")

    st.divider()

    period_title = "ëˆ„ì  SKU Top10 (ìš”ì²­ìˆ˜ëŸ‰ ê¸°ì¤€)" if sel_month_label == "ì „ì²´" else f"{sel_month_label} SKU Top10 (ìš”ì²­ìˆ˜ëŸ‰ ê¸°ì¤€)"
    st.markdown(f"### {period_title}")

    top10_sku = build_item_top10_with_bp(df_view.copy())
    render_pretty_table(
        top10_sku,
        height=520,
        wrap_cols=[COL_ITEM_NAME, "BPëª…(ìš”ì²­ìˆ˜ëŸ‰)"],
        col_width_px={"ìˆœìœ„": 60, COL_ITEM_CODE: 130, COL_ITEM_NAME: 420, "ìš”ì²­ìˆ˜ëŸ‰_í•©": 120, "BPëª…(ìš”ì²­ìˆ˜ëŸ‰)": 520},
        number_cols=["ìš”ì²­ìˆ˜ëŸ‰_í•©"],
    )
    st.caption("â€» BPëª…(ìš”ì²­ìˆ˜ëŸ‰)ì€ í•´ë‹¹ SKUì˜ ì¶œê³ ì²˜ë³„ ìˆ˜ëŸ‰ í•©ê³„ì…ë‹ˆë‹¤. (ì™¼ìª½ í•„í„° ë²”ìœ„ ê¸°ì¤€)")

# =========================
# â‘¡ ì£¼ì°¨ìš”ì•½
# =========================
elif nav == "â‘¡ ì£¼ì°¨ìš”ì•½":
    st.subheader("ì£¼ì°¨ìš”ì•½")

    d = df_view.copy()
    if not need_cols(d, [COL_QTY, COL_BP, COL_ITEM_CODE, COL_ITEM_NAME], "ì£¼ì°¨ìš”ì•½"):
        st.stop()

    week_list = [x for x in d["_week_label"].dropna().astype(str).unique().tolist() if x.strip() != ""]
    week_list = sorted(week_list, key=parse_week_label_key)

    if not week_list:
        st.info("ì£¼ì°¨ ëª©ë¡ì´ ì—†ìŠµë‹ˆë‹¤.")
        st.stop()

    sel_week = st.selectbox("ì£¼ì°¨ ì„ íƒ", week_list, index=len(week_list) - 1, key="wk_sel_week")
    wdf = d[d["_week_label"].astype(str) == str(sel_week)].copy()

    cur_key_num = week_key_num_from_label(sel_week)
    cur_idx = week_list.index(sel_week) if sel_week in week_list else None

    if cur_idx is None or cur_idx == 0:
        prev_wdf = pd.DataFrame()
        prev_week = None
    else:
        prev_week = week_list[cur_idx - 1]
        prev_wdf = d[d["_week_label"].astype(str) == str(prev_week)].copy()

    comment_items = []
    comment_items += new_bp_comment(all_df=d, cur_df=wdf, key_col_num="_week_key_num", cur_key_num=cur_key_num)
    comment_items += period_kpi_delta_comment(cur_df=wdf, prev_df=prev_wdf)
    comment_items += category_top_comment(wdf, top_n=2)
    comment_items += concentration_comment(wdf)
    comment_items += undated_ship_risk_comment(wdf)

    render_numbered_block("ì£¼ê°„ íŠ¹ì´ì‚¬í•­ (ìë™ ì½”ë©˜íŠ¸)", comment_items)
    if prev_week:
        st.caption(f"â€» ë¹„êµ ê¸°ì¤€: ì„ íƒ ì£¼ì°¨({sel_week}) vs ì „ì£¼({prev_week})")
    st.divider()

    st.subheader("ì£¼ì°¨ ì„ íƒ â†’ Top 10 (BP/í’ˆëª©ì½”ë“œ/í’ˆëª©ëª…/ìš”ì²­ìˆ˜ëŸ‰)")

    top10 = (
        wdf.groupby([COL_BP, COL_ITEM_CODE, COL_ITEM_NAME], dropna=False)[COL_QTY]
        .sum(min_count=1)
        .reset_index()
        .sort_values(COL_QTY, ascending=False, na_position="last")
        .head(10)
        .copy()
    )
    top10.insert(0, "ìˆœìœ„", range(1, len(top10) + 1))
    top10[COL_QTY] = top10[COL_QTY].fillna(0).round(0).astype(int)

    render_pretty_table(
        top10,
        height=420,
        wrap_cols=[COL_BP, COL_ITEM_NAME],
        col_width_px={"ìˆœìœ„": 60, COL_BP: 240, COL_ITEM_CODE: 120, COL_ITEM_NAME: 420, COL_QTY: 120},
        number_cols=[COL_QTY],
    )
    st.caption("â€» Top10ì€ ì„ íƒ ì£¼ì°¨ ë‚´ â€˜ìš”ì²­ìˆ˜ëŸ‰ í•©â€™ ê¸°ì¤€ìœ¼ë¡œ ê°€ì¥ ë§ì´ ì¶œê³ ëœ (BP+í’ˆëª©) 10ê°œì…ë‹ˆë‹¤.")
    st.divider()

    st.subheader("ì£¼ì°¨ ì„ íƒ â†’ í’ˆëª© Top 5 (í’ˆëª© ê¸°ì¤€) + BPëª…(ë³µìˆ˜)")
    top5_item = build_item_top5_with_bp(wdf)
    render_pretty_table(
        top5_item,
        height=360,
        wrap_cols=[COL_ITEM_NAME, "BPëª…(ìš”ì²­ìˆ˜ëŸ‰)"],
        col_width_px={"ìˆœìœ„": 60, COL_ITEM_CODE: 130, COL_ITEM_NAME: 420, "ìš”ì²­ìˆ˜ëŸ‰_í•©": 120, "BPëª…(ìš”ì²­ìˆ˜ëŸ‰)": 520},
        number_cols=["ìš”ì²­ìˆ˜ëŸ‰_í•©"],
    )
    st.caption("â€» í’ˆëª© Top5ëŠ” ì„ íƒ ì£¼ì°¨ ë‚´ â€˜í’ˆëª© ê¸°ì¤€ ìš”ì²­ìˆ˜ëŸ‰ í•©â€™ TOP5ì´ë©°, BPëª…ì€ í•´ë‹¹ í’ˆëª©ì— í¬í•¨ëœ BPë¥¼ (BPë³„ ìˆ˜ëŸ‰)ê³¼ í•¨ê»˜ ë‚˜ì—´í•©ë‹ˆë‹¤.")
    st.divider()

    st.subheader("ì „ì£¼ ëŒ€ë¹„ ê¸‰ì¦ SKU ë¦¬í¬íŠ¸ (+30% ì´ìƒ ì¦ê°€)")
    if cur_idx is None or cur_idx == 0:
        st.info("ì „ì£¼ ë¹„êµë¥¼ ìœ„í•´ì„œëŠ” ì„ íƒ ì£¼ì°¨ ì´ì „ì˜ ì£¼ì°¨ ë°ì´í„°ê°€ í•„ìš”í•©ë‹ˆë‹¤.")
    else:
        prev_week2 = week_list[cur_idx - 1]
        prev_wdf2 = d[d["_week_label"].astype(str) == str(prev_week2)].copy()
        spike_df = build_spike_report_only(wdf, prev_wdf2)

        st.caption(
            f"â€» ë¹„êµ ê¸°ì¤€: ì„ íƒ ì£¼ì°¨({sel_week}) vs ì „ì£¼({prev_week2}) | "
            f"ê¸‰ì¦ ì •ì˜: í˜„ì¬ ìš”ì²­ìˆ˜ëŸ‰ â‰¥ ì „ì£¼ ìš”ì²­ìˆ˜ëŸ‰ Ã— {SPIKE_FACTOR} (ì „ì£¼ ëŒ€ë¹„ +30% ì´ìƒ ì¦ê°€)"
        )

        render_pretty_table(
            spike_df,
            height=520,
            wrap_cols=[COL_ITEM_NAME, "BPëª…(ìš”ì²­ìˆ˜ëŸ‰)"],
            col_width_px={
                COL_ITEM_CODE: 130, COL_ITEM_NAME: 420,
                "ì´ì „_ìš”ì²­ìˆ˜ëŸ‰": 120, "í˜„ì¬_ìš”ì²­ìˆ˜ëŸ‰": 120,
                "ì¦ê°€ë°°ìˆ˜": 90, "BPëª…(ìš”ì²­ìˆ˜ëŸ‰)": 520
            },
            number_cols=["ì´ì „_ìš”ì²­ìˆ˜ëŸ‰", "í˜„ì¬_ìš”ì²­ìˆ˜ëŸ‰", "ì¦ê°€ë°°ìˆ˜"],
        )

# =========================
# â‘¢ ì›”ê°„ìš”ì•½
# =========================
elif nav == "â‘¢ ì›”ê°„ìš”ì•½":
    st.subheader("ì›”ê°„ìš”ì•½")

    d = df_view.copy()
    if not need_cols(d, [COL_QTY, COL_BP, COL_ITEM_CODE, COL_ITEM_NAME], "ì›”ê°„ìš”ì•½"):
        st.stop()

    month_list = [x for x in d["_month_label"].dropna().astype(str).unique().tolist() if x.strip() != ""]
    month_list = list(dict.fromkeys(month_list))
    month_list = sorted(month_list, key=parse_month_label_key)

    if not month_list:
        st.info("ì›” ëª©ë¡ì´ ì—†ìŠµë‹ˆë‹¤. RAWì˜ 'ë…„', 'ì›”1' ì»¬ëŸ¼ì„ í™•ì¸í•´ ì£¼ì„¸ìš”.")
        st.stop()

    sel_month_label2 = st.selectbox("ì›” ì„ íƒ", month_list, index=len(month_list) - 1, key="m_sel_month")
    mdf = d[d["_month_label"].astype(str) == str(sel_month_label2)].copy()

    cur_key_num = month_key_num_from_label(sel_month_label2)
    cur_idx = month_list.index(sel_month_label2) if sel_month_label2 in month_list else None

    if cur_idx is None or cur_idx == 0:
        prev_mdf = pd.DataFrame()
        prev_month = None
    else:
        prev_month = month_list[cur_idx - 1]
        prev_mdf = d[d["_month_label"].astype(str) == str(prev_month)].copy()

    # âœ… ê¸°ì¡´ ì›”ê°„ ìë™ì½”ë©˜íŠ¸ ìœ ì§€
    comment_items = []
    comment_items += new_bp_comment(all_df=d, cur_df=mdf, key_col_num="_month_key_num", cur_key_num=cur_key_num)
    comment_items += period_kpi_delta_comment(cur_df=mdf, prev_df=prev_mdf)
    comment_items += category_top_comment(mdf, top_n=2)
    comment_items += concentration_comment(mdf)
    comment_items += undated_ship_risk_comment(mdf)

    render_numbered_block("ì›”ê°„ íŠ¹ì´ì‚¬í•­ (ìë™ ì½”ë©˜íŠ¸)", comment_items)
    if prev_month:
        st.caption(f"â€» ë¹„êµ ê¸°ì¤€: ì„ íƒ ì›”({sel_month_label2}) vs ì „ì›”({prev_month})")

    st.divider()

    # âœ… ì›”ê°„ ë¦¬í¬íŠ¸ ìƒì„±(ë²„íŠ¼ í´ë¦­ + ë³µì‚¬ ê°€ëŠ¥)
    st.subheader("ğŸ“Œ ì›”ê°„ ë¦¬í¬íŠ¸ (ë³µì‚¬/ê³µìœ ìš©)")
    st.caption("ë²„íŠ¼ í´ë¦­ ì‹œ, í•´ì™¸B2B/êµ­ë‚´B2B ì„¹ì…˜ì„ ë‚˜ëˆ  â€˜ì‚¬ëŒì´ ì“°ëŠ” ë¬¸ì¥â€™ í˜•íƒœë¡œ ë¦¬í¬íŠ¸ê°€ ìƒì„±ë©ë‹ˆë‹¤.")

    if st.button("ğŸ“ ì›”ê°„ ë¦¬í¬íŠ¸ ìƒì„±"):
        st.session_state["monthly_report_text"] = make_monthly_report_text_rich(
            month_label=sel_month_label2,
            all_view_df=df_view,   # âœ… ë‹¤ìŒë‹¬ ì˜ˆì • ì‚°ì¶œ ë•Œë¬¸ì— 'í˜„ì¬ í•„í„° ë²”ìœ„ ì „ì²´' í•„ìš”
            cur_month_df=mdf,
            prev_month_df=prev_mdf,
            cur_month_key_num=cur_key_num,
            jp_cn_tokens=["JP", "JAPAN", "CN", "CHINA", "ì¤‘êµ­", "ì¼ë³¸"],
        )

    report_text = st.session_state.get("monthly_report_text", "")
    st.text_area("ìƒì„±ëœ ë¦¬í¬íŠ¸(ì „ì²´ ë³µì‚¬í•´ì„œ ìŠ¬ë™/ë©”ì¼ì— ë¶™ì—¬ë„£ê¸°)", value=report_text, height=380)

    st.divider()

    st.subheader("ì›” ì„ íƒ â†’ Top 10 (BP/í’ˆëª©ì½”ë“œ/í’ˆëª©ëª…/ìš”ì²­ìˆ˜ëŸ‰)")

    top10 = (
        mdf.groupby([COL_BP, COL_ITEM_CODE, COL_ITEM_NAME], dropna=False)[COL_QTY]
        .sum(min_count=1)
        .reset_index()
        .sort_values(COL_QTY, ascending=False, na_position="last")
        .head(10)
        .copy()
    )
    top10.insert(0, "ìˆœìœ„", range(1, len(top10) + 1))
    top10[COL_QTY] = top10[COL_QTY].fillna(0).round(0).astype(int)

    render_pretty_table(
        top10,
        height=420,
        wrap_cols=[COL_BP, COL_ITEM_NAME],
        col_width_px={"ìˆœìœ„": 60, COL_BP: 240, COL_ITEM_CODE: 120, COL_ITEM_NAME: 420, COL_QTY: 120},
        number_cols=[COL_QTY],
    )
    st.caption("â€» Top10ì€ ì„ íƒ ì›” ë‚´ì—ì„œ â€˜ìš”ì²­ìˆ˜ëŸ‰ í•©â€™ ê¸°ì¤€ìœ¼ë¡œ ê°€ì¥ ë§ì´ ì¶œê³ ëœ (BP+í’ˆëª©) 10ê°œì…ë‹ˆë‹¤.")
    st.divider()

    st.subheader("ì›” ì„ íƒ â†’ í’ˆëª© Top 5 (í’ˆëª© ê¸°ì¤€) + BPëª…(ë³µìˆ˜)")
    top5_item = build_item_top5_with_bp(mdf)
    render_pretty_table(
        top5_item,
        height=360,
        wrap_cols=[COL_ITEM_NAME, "BPëª…(ìš”ì²­ìˆ˜ëŸ‰)"],
        col_width_px={"ìˆœìœ„": 60, COL_ITEM_CODE: 130, COL_ITEM_NAME: 420, "ìš”ì²­ìˆ˜ëŸ‰_í•©": 120, "BPëª…(ìš”ì²­ìˆ˜ëŸ‰)": 520},
        number_cols=["ìš”ì²­ìˆ˜ëŸ‰_í•©"],
    )
    st.caption("â€» í’ˆëª© Top5ëŠ” ì„ íƒ ì›” ë‚´ â€˜í’ˆëª© ê¸°ì¤€ ìš”ì²­ìˆ˜ëŸ‰ í•©â€™ TOP5ì´ë©°, BPëª…ì€ í•´ë‹¹ í’ˆëª©ì— í¬í•¨ëœ BPë¥¼ (BPë³„ ìˆ˜ëŸ‰)ê³¼ í•¨ê»˜ ë‚˜ì—´í•©ë‹ˆë‹¤.")
    st.divider()

    st.subheader("ì „ì›” ëŒ€ë¹„ ê¸‰ì¦ SKU ë¦¬í¬íŠ¸ (+30% ì´ìƒ ì¦ê°€)")
    if cur_idx is None or cur_idx == 0:
        st.info("ì „ì›” ë¹„êµë¥¼ ìœ„í•´ì„œëŠ” ì„ íƒ ì›” ì´ì „ì˜ ì›” ë°ì´í„°ê°€ í•„ìš”í•©ë‹ˆë‹¤.")
    else:
        prev_month_label = month_list[cur_idx - 1]
        prev_mdf2 = d[d["_month_label"].astype(str) == str(prev_month_label)].copy()
        spike_df = build_spike_report_only(mdf, prev_mdf2)

        st.caption(
            f"â€» ë¹„êµ ê¸°ì¤€: ì„ íƒ ì›”({sel_month_label2}) vs ì „ì›”({prev_month_label}) | "
            f"ê¸‰ì¦ ì •ì˜: í˜„ì¬ ìš”ì²­ìˆ˜ëŸ‰ â‰¥ ì „ì›” ìš”ì²­ìˆ˜ëŸ‰ Ã— {SPIKE_FACTOR} (ì „ì›” ëŒ€ë¹„ +30% ì´ìƒ ì¦ê°€)"
        )

        render_pretty_table(
            spike_df,
            height=520,
            wrap_cols=[COL_ITEM_NAME, "BPëª…(ìš”ì²­ìˆ˜ëŸ‰)"],
            col_width_px={
                COL_ITEM_CODE: 130, COL_ITEM_NAME: 420,
                "ì´ì „_ìš”ì²­ìˆ˜ëŸ‰": 120, "í˜„ì¬_ìš”ì²­ìˆ˜ëŸ‰": 120,
                "ì¦ê°€ë°°ìˆ˜": 90, "BPëª…(ìš”ì²­ìˆ˜ëŸ‰)": 520
            },
            number_cols=["ì´ì „_ìš”ì²­ìˆ˜ëŸ‰", "í˜„ì¬_ìš”ì²­ìˆ˜ëŸ‰", "ì¦ê°€ë°°ìˆ˜"],
        )

# =========================
# â‘£ êµ­ê°€ë³„ ì¡°íšŒ
# =========================
elif nav == "â‘£ êµ­ê°€ë³„ ì¡°íšŒ":
    st.subheader("êµ­ê°€ë³„ ì¡°íšŒ (ê±°ë˜ì²˜êµ¬ë¶„2 ê¸°ì¤€)")

    if not need_cols(df_view, [COL_CUST2, COL_QTY, COL_LT2], "êµ­ê°€ë³„ ì¡°íšŒ"):
        st.stop()

    base = df_view.copy()

    out = base.groupby(COL_CUST2, dropna=False).agg(
        ìš”ì²­ìˆ˜ëŸ‰_í•©=(COL_QTY, "sum"),
        í‰ê· _ë¦¬ë“œíƒ€ì„_ì‘ì—…ì™„ë£Œê¸°ì¤€=(COL_LT2, "mean"),
        ë¦¬ë“œíƒ€ì„_ì¤‘ê°„ê°’_ì‘ì—…ì™„ë£Œê¸°ì¤€=(COL_LT2, "median"),
        p90_tmp=(COL_LT2, lambda s: s.quantile(0.9)),
        ì§‘ê³„í–‰ìˆ˜_í‘œë³¸=(COL_CUST2, "size"),
    ).reset_index()

    out = out.rename(columns={"p90_tmp": "ë¦¬ë“œíƒ€ì„ ëŠë¦° ìƒìœ„10% ê¸°ì¤€(P90)"})

    rep_cnt = base[base["_is_rep"]].groupby(COL_CUST2).size()
    out["ì¶œê³ ê±´ìˆ˜"] = out[COL_CUST2].astype(str).map(rep_cnt).fillna(0).astype(int)

    for c in ["í‰ê· _ë¦¬ë“œíƒ€ì„_ì‘ì—…ì™„ë£Œê¸°ì¤€", "ë¦¬ë“œíƒ€ì„_ì¤‘ê°„ê°’_ì‘ì—…ì™„ë£Œê¸°ì¤€", "ë¦¬ë“œíƒ€ì„ ëŠë¦° ìƒìœ„10% ê¸°ì¤€(P90)"]:
        out[c] = out[c].round(2)

    out = out.sort_values("ìš”ì²­ìˆ˜ëŸ‰_í•©", ascending=False, na_position="last")

    render_pretty_table(
        out[[COL_CUST2, "ìš”ì²­ìˆ˜ëŸ‰_í•©", "í‰ê· _ë¦¬ë“œíƒ€ì„_ì‘ì—…ì™„ë£Œê¸°ì¤€", "ë¦¬ë“œíƒ€ì„_ì¤‘ê°„ê°’_ì‘ì—…ì™„ë£Œê¸°ì¤€",
             "ë¦¬ë“œíƒ€ì„ ëŠë¦° ìƒìœ„10% ê¸°ì¤€(P90)", "ì¶œê³ ê±´ìˆ˜", "ì§‘ê³„í–‰ìˆ˜_í‘œë³¸"]],
        height=520,
        wrap_cols=[COL_CUST2],
        col_width_px={COL_CUST2: 200, "ìš”ì²­ìˆ˜ëŸ‰_í•©": 120, "ì¶œê³ ê±´ìˆ˜": 90, "ì§‘ê³„í–‰ìˆ˜_í‘œë³¸": 110},
        number_cols=["ìš”ì²­ìˆ˜ëŸ‰_í•©", "ì¶œê³ ê±´ìˆ˜", "ì§‘ê³„í–‰ìˆ˜_í‘œë³¸"],
    )
    st.caption("â€» P90ì€ â€˜ëŠë¦° ìƒìœ„ 10%â€™ ê²½ê³„ê°’(ë¦¬ë“œíƒ€ì„ì´ í° êµ¬ê°„)ì…ë‹ˆë‹¤.")

# =========================
# â‘¤ BPëª…ë³„ ì¡°íšŒ
# =========================
elif nav == "â‘¤ BPëª…ë³„ ì¡°íšŒ":
    st.subheader("BPëª…ë³„ ì¡°íšŒ")

    if not need_cols(df_view, [COL_BP, COL_QTY, COL_LT2], "BPëª…ë³„ ì¡°íšŒ"):
        st.stop()

    base = df_view.copy()

    out = base.groupby(COL_BP, dropna=False).agg(
        ìš”ì²­ìˆ˜ëŸ‰_í•©=(COL_QTY, "sum"),
        í‰ê· _ë¦¬ë“œíƒ€ì„_ì‘ì—…ì™„ë£Œê¸°ì¤€=(COL_LT2, "mean"),
        ë¦¬ë“œíƒ€ì„_ì¤‘ê°„ê°’_ì‘ì—…ì™„ë£Œê¸°ì¤€=(COL_LT2, "median"),
        ìµœê·¼_ì¶œê³ ì¼=(COL_SHIP, "max"),
        ìµœê·¼_ì‘ì—…ì™„ë£Œì¼=(COL_DONE, "max"),
        ì§‘ê³„í–‰ìˆ˜_í‘œë³¸=(COL_BP, "size"),
    ).reset_index()

    rep_cnt = base[base["_is_rep"]].groupby(COL_BP).size()
    out["ì¶œê³ ê±´ìˆ˜"] = out[COL_BP].astype(str).map(rep_cnt).fillna(0).astype(int)

    out["ìµœê·¼_ì¶œê³ ì¼"] = out["ìµœê·¼_ì¶œê³ ì¼"].apply(fmt_date)
    out["ìµœê·¼_ì‘ì—…ì™„ë£Œì¼"] = out["ìµœê·¼_ì‘ì—…ì™„ë£Œì¼"].apply(fmt_date)

    for c in ["í‰ê· _ë¦¬ë“œíƒ€ì„_ì‘ì—…ì™„ë£Œê¸°ì¤€", "ë¦¬ë“œíƒ€ì„_ì¤‘ê°„ê°’_ì‘ì—…ì™„ë£Œê¸°ì¤€"]:
        out[c] = out[c].round(2)

    out = out[[COL_BP, "ìš”ì²­ìˆ˜ëŸ‰_í•©", "í‰ê· _ë¦¬ë“œíƒ€ì„_ì‘ì—…ì™„ë£Œê¸°ì¤€", "ë¦¬ë“œíƒ€ì„_ì¤‘ê°„ê°’_ì‘ì—…ì™„ë£Œê¸°ì¤€",
               "ìµœê·¼_ì¶œê³ ì¼", "ìµœê·¼_ì‘ì—…ì™„ë£Œì¼", "ì¶œê³ ê±´ìˆ˜", "ì§‘ê³„í–‰ìˆ˜_í‘œë³¸"]].sort_values("ìš”ì²­ìˆ˜ëŸ‰_í•©", ascending=False, na_position="last")

    render_pretty_table(
        out,
        height=520,
        wrap_cols=[COL_BP],
        col_width_px={COL_BP: 280, "ìš”ì²­ìˆ˜ëŸ‰_í•©": 120, "ì¶œê³ ê±´ìˆ˜": 90, "ì§‘ê³„í–‰ìˆ˜_í‘œë³¸": 110},
        number_cols=["ìš”ì²­ìˆ˜ëŸ‰_í•©", "ì¶œê³ ê±´ìˆ˜", "ì§‘ê³„í–‰ìˆ˜_í‘œë³¸"],
    )

st.caption("â€» ëª¨ë“  ì§‘ê³„ëŠ” Google Sheet RAW ê¸°ë°˜ì´ë©°, ì œí’ˆë¶„ë¥˜(B0/B1) ê³ ì • + ì„ íƒí•œ í•„í„° ë²”ìœ„ ë‚´ì—ì„œ ê³„ì‚°ë©ë‹ˆë‹¤.")
