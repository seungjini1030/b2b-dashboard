# ==========================================
# B2B ì¶œê³  ëŒ€ì‹œë³´ë“œ (Google Sheet ê¸°ë°˜)
# - âœ… â‘ /â‘¡ ë©”ë‰´ëª…: ì£¼ì°¨ìš”ì•½/ì›”ê°„ìš”ì•½
# - âœ… ì£¼ì°¨/ì›”ê°„ ìë™ ì½”ë©˜íŠ¸ (ë£° ê¸°ë°˜)
# - âœ… ì£¼ì°¨ ë¼ë²¨ ì˜¤ë¥˜ ë°©ì§€: ì¶œê³ ì¼ì/ì‘ì—…ì™„ë£Œì¼ ê¸°ë°˜ ë³´ì •(12ì›” 5ì£¼ì°¨ ê°™ì€ ì´ìƒ ë¼ë²¨ ì œê±°)
# - âœ… ì‹ ê·œ BP ê¸°ì¤€ ë³€ê²½: "ì „ì²´ RAW ê¸°ì¤€ ìµœì´ˆ ë“±ì¥"ì¸ BPë§Œ ë…¸ì¶œ(ì£¼ì°¨/ì›” ë‹¨ìœ„ ì²« ë“±ì¥)
# - âœ… ì½”ë©˜íŠ¸ì— í’ˆëª©ì½”ë“œ+í’ˆëª… ê°™ì´ í‘œê¸°
# - âœ… UX: ì„¹ì…˜ íƒ€ì´í‹€ + ë²ˆí˜¸í˜• ë¦¬ìŠ¤íŠ¸ë¡œ í‘œì‹œ
# ==========================================

import re
import streamlit as st
import pandas as pd
import html
from datetime import date

# =========================
# ì»¬ëŸ¼ëª… í‘œì¤€í™” (RAW ê¸°ì¤€)
# =========================
COL_QTY = "ìš”ì²­ìˆ˜ëŸ‰"
COL_YEAR = "ë…„"
COL_MONTH = "ì›”1"
COL_WEEK_LABEL = "ì£¼ì°¨"
COL_DONE = "ì‘ì—…ì™„ë£Œ"
COL_SHIP = "ì¶œê³ ì¼ì"
COL_LT2 = "ë¦¬ë“œíƒ€ì„2"
COL_BP = "BPëª…"
COL_MAIN = "ëŒ€í‘œí–‰"
COL_CUST1 = "ê±°ë˜ì²˜êµ¬ë¶„1"
COL_CUST2 = "ê±°ë˜ì²˜êµ¬ë¶„2"
COL_CLASS = "ì œí’ˆë¶„ë¥˜"
COL_ITEM_CODE = "í’ˆëª©ì½”ë“œ"
COL_ITEM_NAME = "í’ˆëª©ëª…"
COL_ORDER_DATE = "ë°œì£¼ì¼ì"
COL_ORDERNO = "ì£¼ë¬¸ë²ˆí˜¸"

INVOICE_CANDIDATES = [
    "ì¸ë³´ì´ìŠ¤No.", "ì¸ë³´ì´ìŠ¤No", "ì¸ë³´ì´ìŠ¤ë²ˆí˜¸", "Invoice No.", "InvoiceNo", "INVOICE NO", "INVOICE",
    "ì†¡ì¥ë²ˆí˜¸", "ë¬¸ì„œë²ˆí˜¸"
]

KEEP_CLASSES = ["B0", "B1"]
LT_ONLY_CUST1 = "í•´ì™¸B2B"
SPIKE_FACTOR = 1.3  # +30%

SPECIAL_BPS = {"ë°•ìŠ¤ë¯¸", "CGETC", "ëŸ¬ë©”ì–´í™€ë”©ìŠ¤"}

# =========================
# Google Sheet ì„¤ì •
# =========================
GSHEET_ID = "1jbWMgV3fudWCQ1qhG0lCysZGGFCo4loTIf-j3iuaqOI"
GSHEET_GID = "15468212"
HEADER_ROW_0BASED = 6

# =========================
# Streamlit ì„¤ì •
# =========================
st.set_page_config(page_title="B2B ì¶œê³  ëŒ€ì‹œë³´ë“œ (Google Sheet ê¸°ë°˜)", layout="wide")

# -------------------------
# UI Style
# -------------------------
BASE_CSS = """
<style>
.block-container {padding-top: 1.2rem; padding-bottom: 2.5rem;}
h1, h2, h3 {letter-spacing: -0.2px;}
.small-note {color:#6b7280; font-size: 0.9rem;}

.kpi-wrap {display:flex; gap:0.75rem; flex-wrap:wrap; margin: 0.25rem 0 0.75rem 0;}
.kpi-card {
  background: #ffffff;
  border: 1px solid #e5e7eb;
  border-radius: 14px;
  padding: 0.9rem 0.95rem;
  min-width: 180px;
  flex: 1 1 180px;
  box-shadow: 0 1px 0 rgba(0,0,0,0.02);
}
.kpi-title {color:#6b7280; font-size:0.9rem; margin-bottom:0.35rem;}
.kpi-value {font-size:1.35rem; font-weight:700; color:#111827; line-height:1.2;}
.kpi-big {font-size:1.55rem; font-weight:800; color:#111827; line-height:1.15;}
.kpi-muted {color:#6b7280; font-size:0.85rem; margin-top:0.15rem; white-space:normal; word-break:break-word;}

.mini-kpi-wrap{display:flex; gap:0.6rem; flex-wrap:wrap; margin:0.55rem 0 0.25rem 0;}
.mini-kpi{
  background:#f9fafb;
  border:1px solid #e5e7eb;
  border-radius:12px;
  padding:0.55rem 0.7rem;
  display:flex;
  align-items:baseline;
  gap:0.55rem;
}
.mini-kpi .t{color:#6b7280; font-size:0.9rem;}
.mini-kpi .v{color:#111827; font-size:1.05rem; font-weight:800; font-variant-numeric: tabular-nums;}

.pretty-table-wrap {margin-top: 0.25rem;}
.table-frame{
  border: 1px solid #e5e7eb;
  border-radius: 14px;
  overflow: hidden;
  background: #fff;
}
.table-scroll{
  height: 520px;
  overflow: auto;
  position: relative;
}
table.pretty-table{
  width: 100%;
  border-collapse: separate;
  border-spacing: 0;
  background: #fff;
  font-size: 0.93rem;
}
.pretty-table thead th{
  position: -webkit-sticky;
  position: sticky;
  top: 0;
  background: #f9fafb;
  color: #111827;
  text-align: left;
  padding: 10px 10px;
  border-bottom: 1px solid #e5e7eb;
  z-index: 10;
  white-space: nowrap;
  box-shadow: 0 1px 0 rgba(0,0,0,0.06);
}
.pretty-table tbody td{
  padding: 10px 10px;
  border-bottom: 1px solid #f3f4f6;
  vertical-align: top;
}
.pretty-table tbody tr:nth-child(even) td {background: #fcfcfd;}
.pretty-table tbody tr:hover td {background: #f7fbff;}
.wrap {white-space: normal; word-break: break-word; line-height: 1.25rem;}
.mono {font-variant-numeric: tabular-nums;}
hr {margin: 1.2rem 0;}
</style>
"""
st.markdown(BASE_CSS, unsafe_allow_html=True)

# -------------------------
# Utils
# -------------------------
def to_bool_true(s: pd.Series) -> pd.Series:
    x = s.fillna("").astype(str).str.strip().str.upper()
    return x.isin(["TRUE", "T", "1", "Y", "YES"])

def safe_dt(df: pd.DataFrame, col: str) -> None:
    if col in df.columns:
        df[col] = pd.to_datetime(df[col], errors="coerce")

def safe_num(df: pd.DataFrame, col: str) -> None:
    if col in df.columns:
        s = df[col].astype(str).str.replace(",", "", regex=False).str.strip()
        s = s.replace({"": None, "nan": None, "None": None})
        df[col] = pd.to_numeric(s, errors="coerce")

def uniq_sorted(df: pd.DataFrame, col: str):
    if col not in df.columns:
        return []
    return sorted(df[col].dropna().astype(str).unique().tolist())

def fmt_date(dtval) -> str:
    if pd.isna(dtval):
        return "-"
    return pd.to_datetime(dtval).strftime("%Y-%m-%d")

def need_cols(df: pd.DataFrame, cols: list[str], title: str = "í•„ìš” ì»¬ëŸ¼ ëˆ„ë½"):
    missing = [c for c in cols if c not in df.columns]
    if missing:
        st.warning(f"{title}: {missing}")
        return False
    return True

def normalize_text_cols(df: pd.DataFrame, cols: list[str]) -> None:
    for c in cols:
        if c in df.columns:
            df[c] = df[c].astype(str).str.strip()

def _escape(x) -> str:
    if pd.isna(x):
        return ""
    return html.escape(str(x))

def _fmt_num_for_table(v) -> str:
    if pd.isna(v):
        return ""
    try:
        if isinstance(v, (int,)) and not isinstance(v, bool):
            return f"{v:,}"
        if isinstance(v, float):
            if float(v).is_integer():
                return f"{int(v):,}"
            return f"{v:,.2f}"
        vv = float(v)
        if vv.is_integer():
            return f"{int(vv):,}"
        return f"{vv:,.2f}"
    except Exception:
        return str(v)

def render_pretty_table(
    df: pd.DataFrame,
    height: int = 520,
    wrap_cols: list[str] | None = None,
    col_width_px: dict[str, int] | None = None,
    number_cols: list[str] | None = None,
):
    wrap_cols = wrap_cols or []
    col_width_px = col_width_px or {}
    number_cols = number_cols or []

    if df is None or df.empty:
        st.info("í‘œì‹œí•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return

    cols = list(df.columns)

    colgroup = "<colgroup>"
    for c in cols:
        w = col_width_px.get(c)
        colgroup += f'<col style="width:{int(w)}px;">' if w else "<col>"
    colgroup += "</colgroup>"

    thead = "<thead><tr>" + "".join([f"<th>{_escape(c)}</th>" for c in cols]) + "</tr></thead>"

    tbody_rows = []
    for _, row in df.iterrows():
        tds = []
        for c in cols:
            v = row[c]
            cls = []
            if c in wrap_cols:
                cls.append("wrap")
            if c in number_cols:
                cls.append("mono")
                v_disp = _fmt_num_for_table(v)
            else:
                v_disp = "" if pd.isna(v) else str(v)
            class_attr = f' class="{" ".join(cls)}"' if cls else ""
            tds.append(f"<td{class_attr}>{_escape(v_disp)}</td>")
        tbody_rows.append("<tr>" + "".join(tds) + "</tr>")
    tbody = "<tbody>" + "".join(tbody_rows) + "</tbody>"

    st.markdown(
        f"""
        <div class="pretty-table-wrap">
          <div class="table-frame">
            <div class="table-scroll" style="height:{int(height)}px;">
              <table class="pretty-table">
                {colgroup}
                {thead}
                {tbody}
              </table>
            </div>
          </div>
        </div>
        """,
        unsafe_allow_html=True
    )

def render_mini_kpi(label: str, value: str):
    st.markdown(
        f"""
        <div class="mini-kpi-wrap">
          <div class="mini-kpi">
            <div class="t">{html.escape(label)}</div>
            <div class="v">{html.escape(value)}</div>
          </div>
        </div>
        """,
        unsafe_allow_html=True
    )

def find_invoice_col(df: pd.DataFrame) -> str | None:
    for c in INVOICE_CANDIDATES:
        if c in df.columns:
            return c
    return None

# -------------------------
# Label helpers
# -------------------------
def make_month_label(year: int, month: int) -> str:
    return f"{int(year)}ë…„ {int(month)}ì›”"

def parse_week_label_key(label: str) -> tuple[int, int, int]:
    y = m = w = 0
    try:
        my = re.search(r"(\d{4})\s*ë…„", label)
        mm = re.search(r"(\d+)\s*ì›”", label)
        mw = re.search(r"(\d+)\s*ì£¼ì°¨", label)
        if my: y = int(my.group(1))
        if mm: m = int(mm.group(1))
        if mw: w = int(mw.group(1))
    except Exception:
        pass
    return (y, m, w)

def parse_month_label_key(label: str) -> tuple[int, int]:
    y = m = 0
    try:
        my = re.search(r"(\d{4})\s*ë…„", label)
        mm = re.search(r"(\d+)\s*ì›”", label)
        if my: y = int(my.group(1))
        if mm: m = int(mm.group(1))
    except Exception:
        pass
    return (y, m)

def week_label_from_date(dt: pd.Timestamp) -> str | None:
    if pd.isna(dt):
        return None
    y = int(dt.year)
    m = int(dt.month)
    d = int(dt.day)
    wk = (d - 1) // 7 + 1
    return f"{y}ë…„ {m}ì›” {wk}ì£¼ì°¨"

def build_week_label_from_raw_safe(row: pd.Series) -> str | None:
    """
    âœ… í•µì‹¬ ìˆ˜ì • í¬ì¸íŠ¸:
    - ì¶œê³ ì¼ì(ìš°ì„ ) or ì‘ì—…ì™„ë£Œì¼ì´ ìˆìœ¼ë©´ ê·¸ ë‚ ì§œë¡œ ì£¼ì°¨ ë¼ë²¨ ìƒì„± (RAW ì£¼ì°¨/ì›” ê°’ ì‹ ë¢° X)
    - ë‚ ì§œê°€ ì—†ì„ ë•Œë§Œ RAW 'ì£¼ì°¨'ë¥¼ íŒŒì‹±í•´ì„œ ì“°ë˜, ê°’ì´ ì´ìƒí•˜ë©´ None ì²˜ë¦¬
    - RAW íŒŒì‹± ê²°ê³¼ê°€ ë‚ ì§œ ì›”ê³¼ ë‹¤ë¥´ë©´ ë‚ ì§œ ê¸°ë°˜ ë¼ë²¨ë¡œ êµì •
    """
    ship_dt = row.get(COL_SHIP, pd.NaT)
    done_dt = row.get(COL_DONE, pd.NaT)

    # 1) ë‚ ì§œê°€ ìˆìœ¼ë©´ ë‚ ì§œ ê¸°ë°˜ìœ¼ë¡œ ê°•ì œ ìƒì„± (ê°€ì¥ ì•ˆì „)
    base_dt = ship_dt if pd.notna(ship_dt) else done_dt
    if pd.notna(base_dt):
        return week_label_from_date(pd.to_datetime(base_dt, errors="coerce"))

    # 2) ë‚ ì§œê°€ ì—†ì„ ë•Œë§Œ RAW ì£¼ì°¨ íŒŒì‹±
    wk_raw = str(row.get(COL_WEEK_LABEL, "")).strip()
    if wk_raw == "" or wk_raw.lower() == "nan":
        return None

    # "2026ë…„ 2ì›” 2ì£¼ì°¨" ê°™ì€ ì™„ì„±í˜•ì´ë©´ ê·¸ëŒ€ë¡œ(ë‹¨ ê°’ ê²€ì¦)
    y = m = w = None
    my = re.search(r"(\d{4})\s*ë…„", wk_raw)
    mm = re.search(r"(\d+)\s*ì›”", wk_raw)
    mw = re.search(r"(\d+)\s*ì£¼ì°¨", wk_raw)
    if my and mm and mw:
        y = int(my.group(1)); m = int(mm.group(1)); w = int(mw.group(1))
    else:
        # "2ì£¼ì°¨"ì²˜ëŸ¼ ì›”/ë…„ ì—†ëŠ” ê²½ìš°: ë…„/ì›”1 ë³´ì¡°
        if mw:
            w = int(mw.group(1))
        else:
            return None

        yy = row.get(COL_YEAR, None)
        mo = row.get(COL_MONTH, None)
        try:
            y = int(pd.to_numeric(yy, errors="coerce"))
            m = int(pd.to_numeric(mo, errors="coerce"))
        except Exception:
            return None

    # ê°’ ê²€ì¦ (ì—¬ê¸°ì„œ 12ì›” 5ì£¼ì°¨ ê°™ì€ "ì‹¤ì œ ì¡´ì¬ ì—¬ë¶€"ëŠ” ëª¨ë¥´ì§€ë§Œ ìµœì†Œ ë²”ìœ„ ë§‰ê¸°)
    if not (y and 2000 <= y <= 2100):
        return None
    if not (m and 1 <= m <= 12):
        return None
    if not (w and 1 <= w <= 6):
        return None

    return f"{y}ë…„ {m}ì›” {w}ì£¼ì°¨"

# -------------------------
# BP list helpers
# -------------------------
def build_item_name_map(df: pd.DataFrame) -> dict[str, str]:
    """
    í’ˆëª©ì½”ë“œ -> ëŒ€í‘œ í’ˆëª©ëª…(ê°€ì¥ ë§ì´ ë“±ì¥í•œ ê°’) ë§¤í•‘
    """
    if df.empty or COL_ITEM_CODE not in df.columns:
        return {}
    tmp = df[[COL_ITEM_CODE, COL_ITEM_NAME]].dropna(subset=[COL_ITEM_CODE]).copy()
    tmp[COL_ITEM_CODE] = tmp[COL_ITEM_CODE].astype(str).str.strip()
    if COL_ITEM_NAME in tmp.columns:
        tmp[COL_ITEM_NAME] = tmp[COL_ITEM_NAME].astype(str).str.strip()
    else:
        tmp[COL_ITEM_NAME] = ""
    out = {}
    for code, sub in tmp.groupby(COL_ITEM_CODE):
        name = sub[COL_ITEM_NAME].value_counts().index[0] if not sub[COL_ITEM_NAME].value_counts().empty else ""
        out[str(code)] = str(name)
    return out

def build_bp_list_map(df_period: pd.DataFrame) -> pd.DataFrame:
    if df_period.empty:
        return pd.DataFrame(columns=[COL_ITEM_CODE, COL_ITEM_NAME, "BPëª…(ìš”ì²­ìˆ˜ëŸ‰)"])

    bp_break = (
        df_period.groupby([COL_ITEM_CODE, COL_ITEM_NAME, COL_BP], dropna=False)[COL_QTY]
        .sum(min_count=1)
        .reset_index()
        .rename(columns={COL_QTY: "BPìš”ì²­ìˆ˜ëŸ‰"})
    )

    def format_bp_list(sub: pd.DataFrame) -> str:
        sub = sub.sort_values("BPìš”ì²­ìˆ˜ëŸ‰", ascending=False, na_position="last")
        out = []
        for _, r in sub.iterrows():
            bp = str(r.get(COL_BP, "")).strip()
            q = r.get("BPìš”ì²­ìˆ˜ëŸ‰", 0)
            if pd.isna(q):
                q = 0
            out.append(f"{bp}({int(round(q, 0)):,})")
        return ", ".join(out)

    return (
        bp_break.groupby([COL_ITEM_CODE, COL_ITEM_NAME], dropna=False)
        .apply(format_bp_list)
        .reset_index(name="BPëª…(ìš”ì²­ìˆ˜ëŸ‰)")
    )

def build_item_top5_with_bp(df_period: pd.DataFrame) -> pd.DataFrame:
    if df_period.empty:
        return pd.DataFrame(columns=["ìˆœìœ„", COL_ITEM_CODE, COL_ITEM_NAME, "ìš”ì²­ìˆ˜ëŸ‰_í•©", "BPëª…(ìš”ì²­ìˆ˜ëŸ‰)"])

    top5 = (
        df_period.groupby([COL_ITEM_CODE, COL_ITEM_NAME], dropna=False)[COL_QTY]
        .sum(min_count=1)
        .reset_index()
        .rename(columns={COL_QTY: "ìš”ì²­ìˆ˜ëŸ‰_í•©"})
        .sort_values("ìš”ì²­ìˆ˜ëŸ‰_í•©", ascending=False, na_position="last")
        .head(5)
        .copy()
    )
    bp_map = build_bp_list_map(df_period)
    top5 = top5.merge(bp_map, on=[COL_ITEM_CODE, COL_ITEM_NAME], how="left")
    top5.insert(0, "ìˆœìœ„", range(1, len(top5) + 1))
    top5["ìš”ì²­ìˆ˜ëŸ‰_í•©"] = top5["ìš”ì²­ìˆ˜ëŸ‰_í•©"].fillna(0).round(0).astype(int)
    top5["BPëª…(ìš”ì²­ìˆ˜ëŸ‰)"] = top5["BPëª…(ìš”ì²­ìˆ˜ëŸ‰)"].fillna("")
    return top5[["ìˆœìœ„", COL_ITEM_CODE, COL_ITEM_NAME, "ìš”ì²­ìˆ˜ëŸ‰_í•©", "BPëª…(ìš”ì²­ìˆ˜ëŸ‰)"]]

def build_item_top10_with_bp(df_period: pd.DataFrame) -> pd.DataFrame:
    if df_period.empty:
        return pd.DataFrame(columns=["ìˆœìœ„", COL_ITEM_CODE, COL_ITEM_NAME, "ìš”ì²­ìˆ˜ëŸ‰_í•©", "BPëª…(ìš”ì²­ìˆ˜ëŸ‰)"])

    top10 = (
        df_period.groupby([COL_ITEM_CODE, COL_ITEM_NAME], dropna=False)[COL_QTY]
        .sum(min_count=1)
        .reset_index()
        .rename(columns={COL_QTY: "ìš”ì²­ìˆ˜ëŸ‰_í•©"})
        .sort_values("ìš”ì²­ìˆ˜ëŸ‰_í•©", ascending=False, na_position="last")
        .head(10)
        .copy()
    )
    bp_map = build_bp_list_map(df_period)
    top10 = top10.merge(bp_map, on=[COL_ITEM_CODE, COL_ITEM_NAME], how="left")
    top10.insert(0, "ìˆœìœ„", range(1, len(top10) + 1))
    top10["ìš”ì²­ìˆ˜ëŸ‰_í•©"] = top10["ìš”ì²­ìˆ˜ëŸ‰_í•©"].fillna(0).round(0).astype(int)
    top10["BPëª…(ìš”ì²­ìˆ˜ëŸ‰)"] = top10["BPëª…(ìš”ì²­ìˆ˜ëŸ‰)"].fillna("")
    return top10[["ìˆœìœ„", COL_ITEM_CODE, COL_ITEM_NAME, "ìš”ì²­ìˆ˜ëŸ‰_í•©", "BPëª…(ìš”ì²­ìˆ˜ëŸ‰)"]]

def build_spike_report_only(cur_df: pd.DataFrame, prev_df: pd.DataFrame) -> pd.DataFrame:
    cols = [COL_ITEM_CODE, COL_ITEM_NAME, "ì´ì „_ìš”ì²­ìˆ˜ëŸ‰", "í˜„ì¬_ìš”ì²­ìˆ˜ëŸ‰", "ì¦ê°€ë°°ìˆ˜", "BPëª…(ìš”ì²­ìˆ˜ëŸ‰)"]
    if cur_df.empty:
        return pd.DataFrame(columns=cols)

    cur_sku = (
        cur_df.groupby([COL_ITEM_CODE, COL_ITEM_NAME], dropna=False)[COL_QTY]
        .sum(min_count=1).reset_index(name="í˜„ì¬_ìš”ì²­ìˆ˜ëŸ‰")
    )
    prev_sku = (
        prev_df.groupby([COL_ITEM_CODE, COL_ITEM_NAME], dropna=False)[COL_QTY]
        .sum(min_count=1).reset_index(name="ì´ì „_ìš”ì²­ìˆ˜ëŸ‰")
    ) if not prev_df.empty else pd.DataFrame(columns=[COL_ITEM_CODE, COL_ITEM_NAME, "ì´ì „_ìš”ì²­ìˆ˜ëŸ‰"])

    cmp = cur_sku.merge(prev_sku, on=[COL_ITEM_CODE, COL_ITEM_NAME], how="left")
    cmp["ì´ì „_ìš”ì²­ìˆ˜ëŸ‰"] = cmp["ì´ì „_ìš”ì²­ìˆ˜ëŸ‰"].fillna(0)
    cmp["ì¦ê°€ë°°ìˆ˜"] = cmp.apply(
        lambda r: (r["í˜„ì¬_ìš”ì²­ìˆ˜ëŸ‰"] / r["ì´ì „_ìš”ì²­ìˆ˜ëŸ‰"]) if r["ì´ì „_ìš”ì²­ìˆ˜ëŸ‰"] > 0 else None,
        axis=1
    )

    spike = cmp[(cmp["ì´ì „_ìš”ì²­ìˆ˜ëŸ‰"] > 0) & (cmp["í˜„ì¬_ìš”ì²­ìˆ˜ëŸ‰"] >= cmp["ì´ì „_ìš”ì²­ìˆ˜ëŸ‰"] * SPIKE_FACTOR)].copy()
    bp_map = build_bp_list_map(cur_df)
    spike = spike.merge(bp_map, on=[COL_ITEM_CODE, COL_ITEM_NAME], how="left")

    spike = spike.sort_values("í˜„ì¬_ìš”ì²­ìˆ˜ëŸ‰", ascending=False, na_position="last")
    spike["í˜„ì¬_ìš”ì²­ìˆ˜ëŸ‰"] = spike["í˜„ì¬_ìš”ì²­ìˆ˜ëŸ‰"].fillna(0).round(0).astype(int)
    spike["ì´ì „_ìš”ì²­ìˆ˜ëŸ‰"] = spike["ì´ì „_ìš”ì²­ìˆ˜ëŸ‰"].fillna(0).round(0).astype(int)
    spike["ì¦ê°€ë°°ìˆ˜"] = spike["ì¦ê°€ë°°ìˆ˜"].round(2)
    spike["BPëª…(ìš”ì²­ìˆ˜ëŸ‰)"] = spike["BPëª…(ìš”ì²­ìˆ˜ëŸ‰)"].fillna("")
    return spike[cols]

# =========================
# ìë™ ì½”ë©˜íŠ¸ (UX: ì„¹ì…˜ + ë²ˆí˜¸)
# =========================
def _fmt_int(x) -> str:
    try:
        return f"{int(round(float(x))):,}"
    except Exception:
        return "0"

def _fmt_date_or_mijung(x) -> str:
    if pd.isna(x) or x is None or str(x).strip() == "":
        return "ë¯¸ì •"
    try:
        return pd.to_datetime(x).strftime("%Y-%m-%d")
    except Exception:
        return str(x)

def _sku_label(code: str, name_map: dict[str, str]) -> str:
    n = name_map.get(str(code), "")
    if n:
        return f"{code} {n}"
    return str(code)

def comment_top_sku_changed(df_cur: pd.DataFrame, df_prev: pd.DataFrame, name_map: dict[str, str]) -> list[str]:
    if df_cur.empty or df_prev.empty:
        return []
    cur = df_cur.groupby(COL_ITEM_CODE, dropna=False)[COL_QTY].sum().sort_values(ascending=False)
    prev = df_prev.groupby(COL_ITEM_CODE, dropna=False)[COL_QTY].sum().sort_values(ascending=False)
    if cur.empty or prev.empty:
        return []
    a = str(prev.index[0]); b = str(cur.index[0])
    if a == b:
        return []
    return [f"ì „ê¸° Top1 â†’ ê¸ˆê¸° Top1 ë³€ê²½: `{_sku_label(a, name_map)}` â†’ `{_sku_label(b, name_map)}`"]

def comment_growth_30_sku(df_cur: pd.DataFrame, df_prev: pd.DataFrame, name_map: dict[str, str], top_n=5) -> list[str]:
    if df_cur.empty or df_prev.empty:
        return []
    cur = df_cur.groupby(COL_ITEM_CODE, dropna=False)[COL_QTY].sum().reset_index(name="cur_qty")
    prev = df_prev.groupby(COL_ITEM_CODE, dropna=False)[COL_QTY].sum().reset_index(name="prev_qty")
    m = cur.merge(prev, on=COL_ITEM_CODE, how="left").fillna({"prev_qty": 0})
    hit = m[(m["prev_qty"] > 0) & (m["cur_qty"] >= m["prev_qty"] * SPIKE_FACTOR)].copy()
    if hit.empty:
        return []
    hit["growth_pct"] = (hit["cur_qty"] / hit["prev_qty"] - 1) * 100
    hit = hit.sort_values("growth_pct", ascending=False).head(top_n)
    out = []
    for _, r in hit.iterrows():
        code = str(r[COL_ITEM_CODE])
        out.append(
            f"`{_sku_label(code, name_map)}` ì „ê¸° {_fmt_int(r['prev_qty'])} â†’ ê¸ˆê¸° {_fmt_int(r['cur_qty'])} (**+{r['growth_pct']:.0f}%**)"
        )
    return out

def comment_sku_concentration(df_cur: pd.DataFrame, name_map: dict[str, str],
                              conc_threshold=0.5, other_bp_min_share=0.15, top_n=10) -> list[str]:
    if df_cur.empty:
        return []

    lines = []
    bp_tot = df_cur.groupby(COL_BP, dropna=False)[COL_QTY].sum()
    bp_sku = df_cur.groupby([COL_BP, COL_ITEM_CODE], dropna=False)[COL_QTY].sum().reset_index()

    for bp, tot in bp_tot.items():
        if tot is None or float(tot) <= 0:
            continue
        sub = bp_sku[bp_sku[COL_BP] == bp].sort_values(COL_QTY, ascending=False)
        if sub.empty:
            continue
        top_row = sub.iloc[0]
        sku = str(top_row[COL_ITEM_CODE])
        share_in_bp = float(top_row[COL_QTY]) / float(tot)

        if share_in_bp < conc_threshold:
            continue

        if str(bp) in SPECIAL_BPS:
            sku_by_bp = (
                df_cur[df_cur[COL_ITEM_CODE] == sku]
                .groupby(COL_BP, dropna=False)[COL_QTY].sum()
                .sort_values(ascending=False)
            )
            sku_total = float(sku_by_bp.sum()) if not sku_by_bp.empty else 0.0
            if sku_total <= 0:
                lines.append(f"{bp} : `{_sku_label(sku, name_map)}` ë¹„ì¤‘ **{share_in_bp*100:.0f}%**")
                continue

            top_bp = str(sku_by_bp.index[0])
            others = sku_by_bp[sku_by_bp.index.astype(str) != top_bp]
            meaningful = others[(others / sku_total) >= other_bp_min_share]

            if meaningful.empty:
                lines.append(f"{bp} : `{_sku_label(sku, name_map)}` ë¹„ì¤‘ **{share_in_bp*100:.0f}%**")
            else:
                other_parts = ", ".join([f"{idx}({_fmt_int(val)})" for idx, val in meaningful.items()])
                lines.append(f"{bp} : `{_sku_label(sku, name_map)}` ë¹„ì¤‘ **{share_in_bp*100:.0f}%** (íƒ€ BP í›„ìˆœìœ„: {other_parts})")
        else:
            lines.append(f"{bp} : `{_sku_label(sku, name_map)}` ë¹„ì¤‘ **{share_in_bp*100:.0f}%**")

    return lines[:top_n]

def build_bp_first_seen_maps(full_df: pd.DataFrame) -> tuple[dict[str, str], dict[str, str]]:
    """
    âœ… ì‹ ê·œ BP ê¸°ì¤€ì„ "ì „ì²´ ëˆ„ì "ìœ¼ë¡œ ë³€ê²½:
    - BPê°€ ì „ì²´ rawì—ì„œ ì²˜ìŒ ë“±ì¥í•œ ì£¼ì°¨/ì›”ì„ ê³„ì‚°
    - ì£¼ì°¨ ì½”ë©˜íŠ¸: bp_first_week[bp] == í˜„ì¬ì£¼ì°¨ ì¼ ë•Œë§Œ ì‹ ê·œ
    - ì›”ê°„ ì½”ë©˜íŠ¸: bp_first_month[bp] == í˜„ì¬ì›” ì¼ ë•Œë§Œ ì‹ ê·œ
    """
    if full_df.empty or COL_BP not in full_df.columns:
        return {}, {}

    d = full_df.copy()
    d[COL_BP] = d[COL_BP].astype(str).str.strip()

    # ì£¼ì°¨/ì›” ë¼ë²¨ì´ ì—†ìœ¼ë©´ ìƒì„± ì‹¤íŒ¨í•˜ë¯€ë¡œ ì•ˆì „ ì²˜ë¦¬
    if "_week_label" not in d.columns:
        d["_week_label"] = None
    if "_month_label" not in d.columns:
        d["_month_label"] = None

    # ì²« ë“±ì¥: "ë¼ë²¨ ê¸°ì¤€" ìµœì†Œê°’
    # ë¼ë²¨ ì •ë ¬í‚¤ë¥¼ ë§Œë“¤ì–´ì„œ min ì„ íƒ
    def wk_key(x: str):
        return parse_week_label_key(str(x)) if pd.notna(x) else (9999, 99, 99)

    def mo_key(x: str):
        return parse_month_label_key(str(x)) if pd.notna(x) else (9999, 99)

    bp_first_week = {}
    bp_first_month = {}

    for bp, sub in d.groupby(COL_BP, dropna=False):
        wk_vals = [x for x in sub["_week_label"].dropna().astype(str).tolist() if x.strip() != ""]
        mo_vals = [x for x in sub["_month_label"].dropna().astype(str).tolist() if x.strip() != ""]
        if wk_vals:
            bp_first_week[str(bp)] = sorted(wk_vals, key=wk_key)[0]
        if mo_vals:
            bp_first_month[str(bp)] = sorted(mo_vals, key=mo_key)[0]

    return bp_first_week, bp_first_month

def comment_new_bp_by_first_seen(df_cur: pd.DataFrame, full_df: pd.DataFrame, current_label: str,
                                bp_first_map: dict[str, str], label_col: str, top_n=10) -> list[str]:
    """
    label_col: "_week_label" or "_month_label"
    """
    if df_cur.empty or COL_BP not in df_cur.columns:
        return []

    cur_bps = sorted(df_cur[COL_BP].dropna().astype(str).str.strip().unique().tolist())
    new_bps = [bp for bp in cur_bps if bp_first_map.get(bp) == current_label]
    if not new_bps:
        return []

    sub = df_cur[df_cur[COL_BP].astype(str).str.strip().isin(new_bps)].copy()
    g = sub.groupby(COL_BP, dropna=False).agg(
        qty=(COL_QTY, "sum"),
        first_ship=(COL_SHIP, "min"),
    ).reset_index().sort_values("qty", ascending=False).head(top_n)

    lines = []
    for _, r in g.iterrows():
        lines.append(f"{r[COL_BP]} / ìš”ì²­ìˆ˜ëŸ‰ {_fmt_int(r['qty'])} / ì¶œê³ ì¼ì {_fmt_date_or_mijung(r['first_ship'])}")
    return lines

def comment_leadtime_outlier(df_cur: pd.DataFrame, invoice_col: str | None,
                             name_map: dict[str, str], z=2.0, min_delta_if_no_std=2.0, top_n=10) -> list[str]:
    if df_cur.empty or (COL_LT2 not in df_cur.columns) or (COL_CUST2 not in df_cur.columns):
        return []
    d = df_cur.dropna(subset=[COL_LT2]).copy()
    if d.empty:
        return []

    stats = d.groupby(COL_CUST2, dropna=False)[COL_LT2].agg(["mean", "std"]).reset_index()
    d = d.merge(stats, on=COL_CUST2, how="left")

    d["is_outlier"] = False
    has_std = d["std"].fillna(0) > 0
    d.loc[has_std, "is_outlier"] = d.loc[has_std, COL_LT2] > (d.loc[has_std, "mean"] + z * d.loc[has_std, "std"])
    d.loc[~has_std, "is_outlier"] = d.loc[~has_std, COL_LT2] > (d.loc[~has_std, "mean"] + min_delta_if_no_std)

    out = d[d["is_outlier"]].copy()
    if out.empty:
        return []

    out["delta"] = out[COL_LT2] - out["mean"]
    out = out.sort_values("delta", ascending=False).head(top_n)

    lines = []
    for _, r in out.iterrows():
        inv = "-"
        if invoice_col and invoice_col in out.columns:
            v = r.get(invoice_col, None)
            inv = "-" if pd.isna(v) else str(v).strip()

        bp = str(r.get(COL_BP, "-")).strip()
        sku = str(r.get(COL_ITEM_CODE, "-")).strip()
        grp = str(r.get(COL_CUST2, "-")).strip()

        lines.append(
            f"[{grp}] ì¸ë³´ì´ìŠ¤ `{inv}` / {bp} / `{_sku_label(sku, name_map)}` "
            f"ë¦¬ë“œíƒ€ì„ {float(r[COL_LT2]):.1f} (í‰ê·  {float(r['mean']):.1f}, +{float(r['delta']):.1f})"
        )
    return lines

def comment_shipcount_spike_sku(df_cur: pd.DataFrame, df_prev: pd.DataFrame,
                                name_map: dict[str, str], spike_ratio=1.3, min_increase=3, top_n=10) -> list[str]:
    if df_cur.empty or df_prev.empty:
        return []
    if COL_ORDERNO not in df_cur.columns or COL_ORDERNO not in df_prev.columns:
        return []

    cur = df_cur.groupby(COL_ITEM_CODE, dropna=False)[COL_ORDERNO].nunique().reset_index(name="cur_cnt")
    prev = df_prev.groupby(COL_ITEM_CODE, dropna=False)[COL_ORDERNO].nunique().reset_index(name="prev_cnt")
    m = cur.merge(prev, on=COL_ITEM_CODE, how="left").fillna({"prev_cnt": 0})
    m["inc"] = m["cur_cnt"] - m["prev_cnt"]

    hit = m[(m["prev_cnt"] > 0) & (m["cur_cnt"] >= m["prev_cnt"] * spike_ratio) & (m["inc"] >= min_increase)].copy()
    if hit.empty:
        return []
    hit["growth_pct"] = (hit["cur_cnt"] / hit["prev_cnt"] - 1) * 100
    hit = hit.sort_values("growth_pct", ascending=False).head(top_n)

    lines = []
    for _, r in hit.iterrows():
        code = str(r[COL_ITEM_CODE])
        lines.append(
            f"`{_sku_label(code, name_map)}` {int(r['prev_cnt'])}ê±´ â†’ {int(r['cur_cnt'])}ê±´ (**+{r['growth_pct']:.0f}%**)"
        )
    return lines

def comment_bp_qty_spike(df_cur: pd.DataFrame, df_prev: pd.DataFrame, spike_ratio=1.3, top_n=10) -> list[str]:
    if df_cur.empty or df_prev.empty:
        return []
    cur = df_cur.groupby(COL_BP, dropna=False)[COL_QTY].sum().reset_index(name="cur_qty")
    prev = df_prev.groupby(COL_BP, dropna=False)[COL_QTY].sum().reset_index(name="prev_qty")
    m = cur.merge(prev, on=COL_BP, how="left").fillna({"prev_qty": 0})

    hit = m[(m["prev_qty"] > 0) & (m["cur_qty"] >= m["prev_qty"] * spike_ratio)].copy()
    if hit.empty:
        return []
    hit["growth_pct"] = (hit["cur_qty"] / hit["prev_qty"] - 1) * 100
    hit = hit.sort_values("growth_pct", ascending=False).head(top_n)

    lines = []
    for _, r in hit.iterrows():
        lines.append(f"{r[COL_BP]} {_fmt_int(r['prev_qty'])} â†’ {_fmt_int(r['cur_qty'])} (**+{r['growth_pct']:.0f}%**)")
    return lines

def render_comment_sections(sections: dict[str, list[str]]):
    """
    âœ… UX: ì„¹ì…˜ íƒ€ì´í‹€ + ë²ˆí˜¸ ë¦¬ìŠ¤íŠ¸
    """
    shown = False
    for title, items in sections.items():
        if not items:
            continue
        shown = True
        st.markdown(f"**{title}**")
        for i, line in enumerate(items, start=1):
            st.markdown(f"{i}) {line}")
        st.markdown("---")
    if not shown:
        st.caption("íŠ¹ì´ì‚¬í•­ ì—†ìŒ")

# -------------------------
# Load RAW
# -------------------------
@st.cache_data(ttl=300)
def load_raw_from_gsheet() -> pd.DataFrame:
    csv_url = f"https://docs.google.com/spreadsheets/d/{GSHEET_ID}/export?format=csv&gid={GSHEET_GID}"
    df = pd.read_csv(csv_url, header=HEADER_ROW_0BASED)

    df.columns = df.columns.astype(str).str.strip()
    df = df.loc[:, ~df.columns.str.match(r"^Unnamed")]

    for c in [COL_SHIP, COL_DONE, COL_ORDER_DATE]:
        safe_dt(df, c)

    for c in [COL_QTY, COL_LT2, "ë¦¬ë“œíƒ€ì„1"]:
        safe_num(df, c)

    if (COL_LT2 not in df.columns) or (df[COL_LT2].dropna().empty):
        if all(c in df.columns for c in [COL_DONE, COL_ORDER_DATE]):
            df[COL_LT2] = (df[COL_DONE] - df[COL_ORDER_DATE]).dt.days
            safe_num(df, COL_LT2)

    normalize_text_cols(
        df,
        [COL_BP, COL_ITEM_CODE, COL_ITEM_NAME, COL_CUST1, COL_CUST2, COL_WEEK_LABEL, COL_CLASS, COL_MAIN, COL_ORDERNO]
    )

    if COL_MAIN in df.columns:
        df["_is_rep"] = to_bool_true(df[COL_MAIN])
    else:
        df["_is_rep"] = False

    # âœ… ì£¼ì°¨ ë¼ë²¨: ì•ˆì „ ë¡œì§ ì ìš© (ì˜¤ë¥˜ ë¼ë²¨ ìƒì„± ë°©ì§€)
    df["_week_label"] = df.apply(build_week_label_from_raw_safe, axis=1)

    # ì›” ë¼ë²¨ (ë…„+ì›”1 ê¸°ë°˜)
    if (COL_YEAR in df.columns) and (COL_MONTH in df.columns):
        y = pd.to_numeric(df[COL_YEAR], errors="coerce")
        m = pd.to_numeric(df[COL_MONTH], errors="coerce")
        df["_month_label"] = [
            make_month_label(yy, mm) if pd.notna(yy) and pd.notna(mm) else None
            for yy, mm in zip(y, m)
        ]
    else:
        # fallback: ì¶œê³ ì¼ì ê¸°ë°˜ ì›” ë¼ë²¨
        if COL_SHIP in df.columns:
            ship = pd.to_datetime(df[COL_SHIP], errors="coerce")
            df["_month_label"] = ship.apply(lambda x: make_month_label(x.year, x.month) if pd.notna(x) else None)
        else:
            df["_month_label"] = None

    return df

# -------------------------
# Main
# -------------------------
st.title("ğŸ“¦ B2B ì¶œê³  ëŒ€ì‹œë³´ë“œ")
st.caption("Google Sheet RAW ê¸°ë°˜ | ì œí’ˆë¶„ë¥˜ B0/B1 ê³ ì • | í•„í„°(ê±°ë˜ì²˜êµ¬ë¶„1/2/ì›”/BP) ë°˜ì˜")

if st.button("ğŸ”„ ë°ì´í„° ìƒˆë¡œê³ ì¹¨"):
    st.cache_data.clear()
    reset_keys = [
        "nav_menu", "wk_sel_week", "m_sel_month",
        "sku_query", "sku_candidate_pick", "sku_show_all_history",
        "f_cust1", "f_cust2", "f_month", "f_bp"
    ]
    for k in reset_keys:
        if k in st.session_state:
            del st.session_state[k]
    st.session_state["nav_menu"] = "â‘  ì£¼ì°¨ìš”ì•½"
    st.rerun()

try:
    raw = load_raw_from_gsheet().copy()
except Exception as e:
    st.error("Google Sheetì—ì„œ RAW ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì˜¤ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
    st.code(str(e))
    st.stop()

# ì œí’ˆë¶„ë¥˜ ê³ ì •
if COL_CLASS in raw.columns:
    raw = raw[raw[COL_CLASS].astype(str).str.strip().isin(KEEP_CLASSES)].copy()
else:
    st.warning(f"'{COL_CLASS}' ì»¬ëŸ¼ì´ ì—†ì–´ ì œí’ˆë¶„ë¥˜(B0/B1) ê³ ì • í•„í„°ë¥¼ ì ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

invoice_col = find_invoice_col(raw)

# âœ… ì „ì²´ ëˆ„ì  ê¸°ì¤€ ì‹ ê·œ BP ê³„ì‚°ìš©: first seen ë§µ ìƒì„±
bp_first_week_map, bp_first_month_map = build_bp_first_seen_maps(raw)

# âœ… í’ˆëª©ì½”ë“œ â†’ í’ˆëª… ë§µ (ì½”ë©˜íŠ¸ìš©)
name_map_global = build_item_name_map(raw)

# =========================
# Sidebar filters
# =========================
st.sidebar.header("í•„í„°")
st.sidebar.caption("ì œí’ˆë¶„ë¥˜ ê³ ì •: B0, B1")

cust1_list = uniq_sorted(raw, COL_CUST1)
sel_cust1 = st.sidebar.selectbox("ê±°ë˜ì²˜êµ¬ë¶„1", ["ì „ì²´"] + cust1_list, index=0, key="f_cust1")

pool1 = raw.copy()
if sel_cust1 != "ì „ì²´" and COL_CUST1 in pool1.columns:
    pool1 = pool1[pool1[COL_CUST1].astype(str).str.strip() == sel_cust1]

cust2_list = uniq_sorted(pool1, COL_CUST2)
sel_cust2 = st.sidebar.selectbox("ê±°ë˜ì²˜êµ¬ë¶„2", ["ì „ì²´"] + cust2_list, index=0, key="f_cust2")

pool2 = pool1.copy()
if sel_cust2 != "ì „ì²´" and COL_CUST2 in pool2.columns:
    pool2 = pool2[pool2[COL_CUST2].astype(str).str.strip() == sel_cust2]

month_labels = []
if "_month_label" in pool2.columns:
    month_labels = [x for x in pool2["_month_label"].dropna().astype(str).unique().tolist() if x.strip() != ""]
    month_labels = list(dict.fromkeys(month_labels))
    month_labels = sorted(month_labels, key=parse_month_label_key)

sel_month_label = st.sidebar.selectbox("ì›”", ["ì „ì²´"] + month_labels, index=0, key="f_month")

pool3 = pool2.copy()
if sel_month_label != "ì „ì²´":
    pool3 = pool3[pool3["_month_label"].astype(str) == str(sel_month_label)]

bp_list = uniq_sorted(pool3, COL_BP)
sel_bp = st.sidebar.selectbox("BPëª…", ["ì „ì²´"] + bp_list, index=0, key="f_bp")

df_view = pool3.copy()
if sel_bp != "ì „ì²´" and COL_BP in df_view.columns:
    df_view = df_view[df_view[COL_BP].astype(str).str.strip() == sel_bp]

df_rep = df_view[df_view["_is_rep"]].copy()

# =========================
# KPI cards
# =========================
total_qty = df_view[COL_QTY].fillna(0).sum() if COL_QTY in df_view.columns else None

if COL_ORDERNO in df_view.columns and not df_view.empty:
    total_cnt = int(df_view[COL_ORDERNO].dropna().astype(str).nunique())
else:
    total_cnt = int(df_rep.shape[0])

latest_done = df_view[COL_DONE].max() if COL_DONE in df_view.columns else None

avg_lt2_overseas = None
if all(c in df_view.columns for c in [COL_CUST1, COL_LT2]):
    overseas = df_view[df_view[COL_CUST1].astype(str).str.strip() == LT_ONLY_CUST1]
    if not overseas.empty and not overseas[COL_LT2].dropna().empty:
        avg_lt2_overseas = float(overseas[COL_LT2].dropna().mean())

top_bp_qty_name = "-"
top_bp_qty_val = "-"
if all(c in df_view.columns for c in [COL_BP, COL_QTY]) and not df_view.empty:
    g = df_view.groupby(COL_BP, dropna=False)[COL_QTY].sum().sort_values(ascending=False)
    if not g.empty:
        top_bp_qty_name = str(g.index[0])
        top_bp_qty_val = f"{float(g.iloc[0]):,.0f}"

top_bp_cnt_name = "-"
top_bp_cnt_val = "-"
if COL_BP in df_view.columns and not df_view.empty:
    if COL_ORDERNO in df_view.columns:
        g2 = df_view.groupby(COL_BP, dropna=False)[COL_ORDERNO].nunique().sort_values(ascending=False)
    else:
        g2 = df_rep.groupby(COL_BP).size().sort_values(ascending=False)
    if not g2.empty:
        top_bp_cnt_name = str(g2.index[0])
        top_bp_cnt_val = f"{int(g2.iloc[0]):,}"

st.markdown(
    f"""
    <div class="kpi-wrap">
      <div class="kpi-card">
        <div class="kpi-title">ì´ ì¶œê³ ìˆ˜ëŸ‰(í•©)</div>
        <div class="kpi-value">{(f"{total_qty:,.0f}" if total_qty is not None else "-")}</div>
      </div>
      <div class="kpi-card">
        <div class="kpi-title">ì´ ì¶œê³ ê±´ìˆ˜(í•©)</div>
        <div class="kpi-value">{total_cnt:,}</div>
      </div>
      <div class="kpi-card">
        <div class="kpi-title">ìµœê·¼ ì‘ì—…ì™„ë£Œì¼</div>
        <div class="kpi-value">{fmt_date(latest_done)}</div>
      </div>
      <div class="kpi-card">
        <div class="kpi-title">ë¦¬ë“œíƒ€ì„2 í‰ê·  (í•´ì™¸B2B)</div>
        <div class="kpi-value">{(f"{avg_lt2_overseas:.1f}ì¼" if avg_lt2_overseas is not None else "-")}</div>
      </div>
      <div class="kpi-card">
        <div class="kpi-title">ì¶œê³ ìˆ˜ëŸ‰ TOP BP</div>
        <div class="kpi-big">{html.escape(top_bp_qty_val)}</div>
        <div class="kpi-muted">{html.escape(top_bp_qty_name)}</div>
      </div>
      <div class="kpi-card">
        <div class="kpi-title">ì¶œê³ ê±´ìˆ˜ TOP BP</div>
        <div class="kpi-big">{html.escape(top_bp_cnt_val)}</div>
        <div class="kpi-muted">{html.escape(top_bp_cnt_name)}</div>
      </div>
    </div>
    """,
    unsafe_allow_html=True
)
st.caption("â€» ë¦¬ë“œíƒ€ì„2 ì§€í‘œëŠ” í•´ì™¸B2B(ê±°ë˜ì²˜êµ¬ë¶„1=í•´ì™¸B2B)ë§Œì„ ëŒ€ìƒìœ¼ë¡œ ê³„ì‚°ë©ë‹ˆë‹¤.")
st.divider()

# =========================
# Navigation
# =========================
nav = st.radio(
    "ë©”ë‰´",
    ["â‘  ì£¼ì°¨ìš”ì•½", "â‘¡ ì›”ê°„ìš”ì•½", "â‘¢ êµ­ê°€ë³„ ì¡°íšŒ", "â‘£ BPëª…ë³„ ì¡°íšŒ", "â‘¤ SKUë³„ ì¡°íšŒ"],
    horizontal=True,
    key="nav_menu"
)

# =========================
# â‘  ì£¼ì°¨ìš”ì•½
# =========================
if nav == "â‘  ì£¼ì°¨ìš”ì•½":
    st.subheader("ì£¼ì°¨ ì„ íƒ â†’ Top 10 (BP/í’ˆëª©ì½”ë“œ/í’ˆëª©ëª…/ìš”ì²­ìˆ˜ëŸ‰)")

    d = df_view.copy()
    if not need_cols(d, [COL_QTY, COL_BP, COL_ITEM_CODE, COL_ITEM_NAME], "ì£¼ì°¨ìš”ì•½"):
        st.stop()

    week_list = [x for x in d["_week_label"].dropna().astype(str).unique().tolist() if x.strip() != ""]
    week_list = sorted(week_list, key=parse_week_label_key)

    if not week_list:
        st.info("ì£¼ì°¨ ëª©ë¡ì´ ì—†ìŠµë‹ˆë‹¤.")
        st.stop()

    sel_week = st.selectbox("ì£¼ì°¨ ì„ íƒ", week_list, index=len(week_list) - 1, key="wk_sel_week")
    wdf = d[d["_week_label"].astype(str) == str(sel_week)].copy()

    cur_idx = week_list.index(sel_week) if sel_week in week_list else None
    prev_week = None
    prev_wdf = pd.DataFrame()
    if cur_idx is not None and cur_idx > 0:
        prev_week = week_list[cur_idx - 1]
        prev_wdf = d[d["_week_label"].astype(str) == str(prev_week)].copy()

    # âœ… ìë™ ì½”ë©˜íŠ¸(UX ê°œì„ )
    with st.expander("ì£¼ì°¨ìš”ì•½ ìë™ ì½”ë©˜íŠ¸ (íŠ¹ì´/ì´ìŠˆ í¬ì¸íŠ¸)", expanded=True):
        if prev_week is None:
            st.caption("ì „ì£¼ ë¹„êµë¥¼ ìœ„í•´ì„œëŠ” ì„ íƒ ì£¼ì°¨ ì´ì „ì˜ ì£¼ì°¨ ë°ì´í„°ê°€ í•„ìš”í•©ë‹ˆë‹¤.")
        else:
            # ì£¼ì°¨ ë‹¨ìœ„ì—ì„œëŠ” "ì´ë²ˆ ì£¼ì°¨ì— ì²˜ìŒ ë“±ì¥í•œ BP(ì „ì²´ ëˆ„ì  ê¸°ì¤€)"ë§Œ ì‹ ê·œë¡œ í‘œê¸°
            sections = {}

            inc_sku = comment_growth_30_sku(wdf, prev_wdf, name_map_global)
            if inc_sku:
                sections["ì „ì£¼ ëŒ€ë¹„ +30% ì´ìƒ ì¦ê°€ SKU"] = inc_sku

            top_changed = comment_top_sku_changed(wdf, prev_wdf, name_map_global)
            if top_changed:
                sections["Top SKU ë³€ê²½"] = top_changed

            conc = comment_sku_concentration(wdf, name_map_global)
            if conc:
                sections["SKU ì§‘ì¤‘ë„ (BP ë‚´ Top SKU ë¹„ì¤‘ â‰¥ 50%)"] = conc

            new_bp = comment_new_bp_by_first_seen(
                df_cur=wdf,
                full_df=raw,
                current_label=sel_week,
                bp_first_map=bp_first_week_map,
                label_col="_week_label",
            )
            if new_bp:
                sections["ì‹ ê·œ BP (ì „ì²´ ëˆ„ì  ê¸°ì¤€ ìµœì´ˆ ë“±ì¥)"] = new_bp

            out_lt = comment_leadtime_outlier(wdf, invoice_col, name_map_global)
            if out_lt:
                sections["ë¦¬ë“œíƒ€ì„ ì´ìƒì¹˜ (ê±°ë˜ì²˜êµ¬ë¶„2 í‰ê·  ëŒ€ë¹„)"] = out_lt

            if prev_week is not None:
                cnt_spike = comment_shipcount_spike_sku(wdf, prev_wdf, name_map_global)
                if cnt_spike:
                    sections["ì „ì£¼ ëŒ€ë¹„ ì¶œê³ ê±´ìˆ˜ ê¸‰ì¦ SKU"] = cnt_spike

            render_comment_sections(sections)

    top10 = (
        wdf.groupby([COL_BP, COL_ITEM_CODE, COL_ITEM_NAME], dropna=False)[COL_QTY]
        .sum(min_count=1)
        .reset_index()
        .sort_values(COL_QTY, ascending=False, na_position="last")
        .head(10)
        .copy()
    )
    top10.insert(0, "ìˆœìœ„", range(1, len(top10) + 1))
    top10[COL_QTY] = top10[COL_QTY].fillna(0).round(0).astype(int)

    render_pretty_table(
        top10,
        height=420,
        wrap_cols=[COL_BP, COL_ITEM_NAME],
        col_width_px={"ìˆœìœ„": 60, COL_BP: 240, COL_ITEM_CODE: 120, COL_ITEM_NAME: 420, COL_QTY: 120},
        number_cols=[COL_QTY],
    )

    st.divider()
    st.subheader("ì£¼ì°¨ ì„ íƒ â†’ í’ˆëª© Top 5 (í’ˆëª© ê¸°ì¤€) + BPëª…(ë³µìˆ˜)")
    top5_item = build_item_top5_with_bp(wdf)
    render_pretty_table(
        top5_item,
        height=360,
        wrap_cols=[COL_ITEM_NAME, "BPëª…(ìš”ì²­ìˆ˜ëŸ‰)"],
        col_width_px={"ìˆœìœ„": 60, COL_ITEM_CODE: 130, COL_ITEM_NAME: 420, "ìš”ì²­ìˆ˜ëŸ‰_í•©": 120, "BPëª…(ìš”ì²­ìˆ˜ëŸ‰)": 520},
        number_cols=["ìš”ì²­ìˆ˜ëŸ‰_í•©"],
    )

    st.divider()
    st.subheader("ì „ì£¼ ëŒ€ë¹„ ê¸‰ì¦ SKU ë¦¬í¬íŠ¸ (+30% ì´ìƒ ì¦ê°€)")
    if prev_week is None:
        st.info("ì „ì£¼ ë¹„êµë¥¼ ìœ„í•´ì„œëŠ” ì„ íƒ ì£¼ì°¨ ì´ì „ì˜ ì£¼ì°¨ ë°ì´í„°ê°€ í•„ìš”í•©ë‹ˆë‹¤.")
    else:
        spike_df = build_spike_report_only(wdf, prev_wdf)
        st.caption(
            f"â€» ë¹„êµ ê¸°ì¤€: ì„ íƒ ì£¼ì°¨({sel_week}) vs ì „ì£¼({prev_week}) | "
            f"ê¸‰ì¦ ì •ì˜: í˜„ì¬ ìš”ì²­ìˆ˜ëŸ‰ â‰¥ ì „ì£¼ ìš”ì²­ìˆ˜ëŸ‰ Ã— {SPIKE_FACTOR} (ì „ì£¼ ëŒ€ë¹„ +30% ì´ìƒ ì¦ê°€)"
        )
        render_pretty_table(
            spike_df,
            height=520,
            wrap_cols=[COL_ITEM_NAME, "BPëª…(ìš”ì²­ìˆ˜ëŸ‰)"],
            col_width_px={
                COL_ITEM_CODE: 130, COL_ITEM_NAME: 420,
                "ì´ì „_ìš”ì²­ìˆ˜ëŸ‰": 120, "í˜„ì¬_ìš”ì²­ìˆ˜ëŸ‰": 120,
                "ì¦ê°€ë°°ìˆ˜": 90, "BPëª…(ìš”ì²­ìˆ˜ëŸ‰)": 520
            },
            number_cols=["ì´ì „_ìš”ì²­ìˆ˜ëŸ‰", "í˜„ì¬_ìš”ì²­ìˆ˜ëŸ‰", "ì¦ê°€ë°°ìˆ˜"],
        )

# =========================
# â‘¡ ì›”ê°„ìš”ì•½
# =========================
elif nav == "â‘¡ ì›”ê°„ìš”ì•½":
    st.subheader("ì›” ì„ íƒ â†’ Top 10 (BP/í’ˆëª©ì½”ë“œ/í’ˆëª©ëª…/ìš”ì²­ìˆ˜ëŸ‰)")

    d = df_view.copy()
    if not need_cols(d, [COL_QTY, COL_BP, COL_ITEM_CODE, COL_ITEM_NAME], "ì›”ê°„ìš”ì•½"):
        st.stop()

    month_list = [x for x in d["_month_label"].dropna().astype(str).unique().tolist() if x.strip() != ""]
    month_list = list(dict.fromkeys(month_list))
    month_list = sorted(month_list, key=parse_month_label_key)

    if not month_list:
        st.info("ì›” ëª©ë¡ì´ ì—†ìŠµë‹ˆë‹¤.")
        st.stop()

    sel_month_label2 = st.selectbox("ì›” ì„ íƒ", month_list, index=len(month_list) - 1, key="m_sel_month")
    mdf = d[d["_month_label"].astype(str) == str(sel_month_label2)].copy()

    cur_idx = month_list.index(sel_month_label2) if sel_month_label2 in month_list else None
    prev_month_label = None
    prev_mdf = pd.DataFrame()
    if cur_idx is not None and cur_idx > 0:
        prev_month_label = month_list[cur_idx - 1]
        prev_mdf = d[d["_month_label"].astype(str) == str(prev_month_label)].copy()

    with st.expander("ì›”ê°„ìš”ì•½ ìë™ ì½”ë©˜íŠ¸ (íŠ¹ì´/ì´ìŠˆ í¬ì¸íŠ¸)", expanded=True):
        if prev_month_label is None:
            st.caption("ì „ì›” ë¹„êµë¥¼ ìœ„í•´ì„œëŠ” ì„ íƒ ì›” ì´ì „ì˜ ì›” ë°ì´í„°ê°€ í•„ìš”í•©ë‹ˆë‹¤.")
        else:
            sections = {}

            inc_sku = comment_growth_30_sku(mdf, prev_mdf, name_map_global)
            if inc_sku:
                sections["ì „ì›” ëŒ€ë¹„ +30% ì´ìƒ ì¦ê°€ SKU"] = inc_sku

            top_changed = comment_top_sku_changed(mdf, prev_mdf, name_map_global)
            if top_changed:
                sections["Top SKU ë³€ê²½"] = top_changed

            conc = comment_sku_concentration(mdf, name_map_global)
            if conc:
                sections["SKU ì§‘ì¤‘ë„ (BP ë‚´ Top SKU ë¹„ì¤‘ â‰¥ 50%)"] = conc

            new_bp = comment_new_bp_by_first_seen(
                df_cur=mdf,
                full_df=raw,
                current_label=sel_month_label2,
                bp_first_map=bp_first_month_map,
                label_col="_month_label",
            )
            if new_bp:
                sections["ì‹ ê·œ BP (ì „ì²´ ëˆ„ì  ê¸°ì¤€ ìµœì´ˆ ë“±ì¥)"] = new_bp

            out_lt = comment_leadtime_outlier(mdf, invoice_col, name_map_global)
            if out_lt:
                sections["ë¦¬ë“œíƒ€ì„ ì´ìƒì¹˜ (ê±°ë˜ì²˜êµ¬ë¶„2 í‰ê·  ëŒ€ë¹„)"] = out_lt

            if prev_month_label is not None:
                bp_spike = comment_bp_qty_spike(mdf, prev_mdf)
                if bp_spike:
                    sections["ì „ì›” ëŒ€ë¹„ ì¶œê³ ìˆ˜ëŸ‰ ê¸‰ì¦ BP"] = bp_spike

            render_comment_sections(sections)

    top10 = (
        mdf.groupby([COL_BP, COL_ITEM_CODE, COL_ITEM_NAME], dropna=False)[COL_QTY]
        .sum(min_count=1)
        .reset_index()
        .sort_values(COL_QTY, ascending=False, na_position="last")
        .head(10)
        .copy()
    )
    top10.insert(0, "ìˆœìœ„", range(1, len(top10) + 1))
    top10[COL_QTY] = top10[COL_QTY].fillna(0).round(0).astype(int)

    render_pretty_table(
        top10,
        height=420,
        wrap_cols=[COL_BP, COL_ITEM_NAME],
        col_width_px={"ìˆœìœ„": 60, COL_BP: 240, COL_ITEM_CODE: 120, COL_ITEM_NAME: 420, COL_QTY: 120},
        number_cols=[COL_QTY],
    )

    st.divider()
    st.subheader("ì›” ì„ íƒ â†’ í’ˆëª© Top 5 (í’ˆëª© ê¸°ì¤€) + BPëª…(ë³µìˆ˜)")
    top5_item = build_item_top5_with_bp(mdf)
    render_pretty_table(
        top5_item,
        height=360,
        wrap_cols=[COL_ITEM_NAME, "BPëª…(ìš”ì²­ìˆ˜ëŸ‰)"],
        col_width_px={"ìˆœìœ„": 60, COL_ITEM_CODE: 130, COL_ITEM_NAME: 420, "ìš”ì²­ìˆ˜ëŸ‰_í•©": 120, "BPëª…(ìš”ì²­ìˆ˜ëŸ‰)": 520},
        number_cols=["ìš”ì²­ìˆ˜ëŸ‰_í•©"],
    )

    st.divider()
    st.subheader("ì „ì›” ëŒ€ë¹„ ê¸‰ì¦ SKU ë¦¬í¬íŠ¸ (+30% ì´ìƒ ì¦ê°€)")
    if prev_month_label is None:
        st.info("ì „ì›” ë¹„êµë¥¼ ìœ„í•´ì„œëŠ” ì„ íƒ ì›” ì´ì „ì˜ ì›” ë°ì´í„°ê°€ í•„ìš”í•©ë‹ˆë‹¤.")
    else:
        spike_df = build_spike_report_only(mdf, prev_mdf)
        st.caption(
            f"â€» ë¹„êµ ê¸°ì¤€: ì„ íƒ ì›”({sel_month_label2}) vs ì „ì›”({prev_month_label}) | "
            f"ê¸‰ì¦ ì •ì˜: í˜„ì¬ ìš”ì²­ìˆ˜ëŸ‰ â‰¥ ì „ì›” ìš”ì²­ìˆ˜ëŸ‰ Ã— {SPIKE_FACTOR} (ì „ì›” ëŒ€ë¹„ +30% ì´ìƒ ì¦ê°€)"
        )
        render_pretty_table(
            spike_df,
            height=520,
            wrap_cols=[COL_ITEM_NAME, "BPëª…(ìš”ì²­ìˆ˜ëŸ‰)"],
            col_width_px={
                COL_ITEM_CODE: 130, COL_ITEM_NAME: 420,
                "ì´ì „_ìš”ì²­ìˆ˜ëŸ‰": 120, "í˜„ì¬_ìš”ì²­ìˆ˜ëŸ‰": 120,
                "ì¦ê°€ë°°ìˆ˜": 90, "BPëª…(ìš”ì²­ìˆ˜ëŸ‰)": 520
            },
            number_cols=["ì´ì „_ìš”ì²­ìˆ˜ëŸ‰", "í˜„ì¬_ìš”ì²­ìˆ˜ëŸ‰", "ì¦ê°€ë°°ìˆ˜"],
        )

# =========================
# â‘¢ êµ­ê°€ë³„ ì¡°íšŒ
# =========================
elif nav == "â‘¢ êµ­ê°€ë³„ ì¡°íšŒ":
    st.subheader("êµ­ê°€ë³„ ì¡°íšŒ (ê±°ë˜ì²˜êµ¬ë¶„2 ê¸°ì¤€)")

    if not need_cols(df_view, [COL_CUST2, COL_QTY, COL_LT2], "êµ­ê°€ë³„ ì¡°íšŒ"):
        st.stop()

    base = df_view.copy()

    out = base.groupby(COL_CUST2, dropna=False).agg(
        ìš”ì²­ìˆ˜ëŸ‰_í•©=(COL_QTY, "sum"),
        í‰ê· _ë¦¬ë“œíƒ€ì„_ì‘ì—…ì™„ë£Œê¸°ì¤€=(COL_LT2, "mean"),
        ë¦¬ë“œíƒ€ì„_ì¤‘ê°„ê°’_ì‘ì—…ì™„ë£Œê¸°ì¤€=(COL_LT2, "median"),
        p90_tmp=(COL_LT2, lambda s: s.quantile(0.9)),
        ì§‘ê³„í–‰ìˆ˜_í‘œë³¸=(COL_CUST2, "size"),
    ).reset_index()

    out = out.rename(columns={"p90_tmp": "ë¦¬ë“œíƒ€ì„ ëŠë¦° ìƒìœ„10% ê¸°ì¤€(P90)"})

    if COL_ORDERNO in base.columns:
        rep_cnt = base.groupby(COL_CUST2, dropna=False)[COL_ORDERNO].nunique()
    else:
        rep_cnt = base[base["_is_rep"]].groupby(COL_CUST2).size()
    out["ì¶œê³ ê±´ìˆ˜"] = out[COL_CUST2].astype(str).map(rep_cnt).fillna(0).astype(int)

    out = out[
        [COL_CUST2, "ìš”ì²­ìˆ˜ëŸ‰_í•©", "í‰ê· _ë¦¬ë“œíƒ€ì„_ì‘ì—…ì™„ë£Œê¸°ì¤€", "ë¦¬ë“œíƒ€ì„_ì¤‘ê°„ê°’_ì‘ì—…ì™„ë£Œê¸°ì¤€",
         "ë¦¬ë“œíƒ€ì„ ëŠë¦° ìƒìœ„10% ê¸°ì¤€(P90)", "ì¶œê³ ê±´ìˆ˜", "ì§‘ê³„í–‰ìˆ˜_í‘œë³¸"]
    ]

    for c in ["í‰ê· _ë¦¬ë“œíƒ€ì„_ì‘ì—…ì™„ë£Œê¸°ì¤€", "ë¦¬ë“œíƒ€ì„_ì¤‘ê°„ê°’_ì‘ì—…ì™„ë£Œê¸°ì¤€", "ë¦¬ë“œíƒ€ì„ ëŠë¦° ìƒìœ„10% ê¸°ì¤€(P90)"]:
        out[c] = out[c].round(2)

    out = out.sort_values("ìš”ì²­ìˆ˜ëŸ‰_í•©", ascending=False, na_position="last")

    render_pretty_table(
        out,
        height=520,
        wrap_cols=[COL_CUST2],
        col_width_px={COL_CUST2: 200, "ìš”ì²­ìˆ˜ëŸ‰_í•©": 120, "ì¶œê³ ê±´ìˆ˜": 90, "ì§‘ê³„í–‰ìˆ˜_í‘œë³¸": 110},
        number_cols=["ìš”ì²­ìˆ˜ëŸ‰_í•©", "ì¶œê³ ê±´ìˆ˜", "ì§‘ê³„í–‰ìˆ˜_í‘œë³¸"],
    )

# =========================
# â‘£ BPëª…ë³„ ì¡°íšŒ
# =========================
elif nav == "â‘£ BPëª…ë³„ ì¡°íšŒ":
    st.subheader("BPëª…ë³„ ì¡°íšŒ")

    if not need_cols(df_view, [COL_BP, COL_QTY, COL_LT2], "BPëª…ë³„ ì¡°íšŒ"):
        st.stop()

    base = df_view.copy()

    out = base.groupby(COL_BP, dropna=False).agg(
        ìš”ì²­ìˆ˜ëŸ‰_í•©=(COL_QTY, "sum"),
        í‰ê· _ë¦¬ë“œíƒ€ì„_ì‘ì—…ì™„ë£Œê¸°ì¤€=(COL_LT2, "mean"),
        ë¦¬ë“œíƒ€ì„_ì¤‘ê°„ê°’_ì‘ì—…ì™„ë£Œê¸°ì¤€=(COL_LT2, "median"),
        ìµœê·¼_ì¶œê³ ì¼=(COL_SHIP, "max"),
        ìµœê·¼_ì‘ì—…ì™„ë£Œì¼=(COL_DONE, "max"),
        ì§‘ê³„í–‰ìˆ˜_í‘œë³¸=(COL_BP, "size"),
    ).reset_index()

    if COL_ORDERNO in base.columns:
        rep_cnt = base.groupby(COL_BP, dropna=False)[COL_ORDERNO].nunique()
    else:
        rep_cnt = base[base["_is_rep"]].groupby(COL_BP).size()
    out["ì¶œê³ ê±´ìˆ˜"] = out[COL_BP].astype(str).map(rep_cnt).fillna(0).astype(int)

    out["ìµœê·¼_ì¶œê³ ì¼"] = out["ìµœê·¼_ì¶œê³ ì¼"].apply(fmt_date)
    out["ìµœê·¼_ì‘ì—…ì™„ë£Œì¼"] = out["ìµœê·¼_ì‘ì—…ì™„ë£Œì¼"].apply(fmt_date)

    for c in ["í‰ê· _ë¦¬ë“œíƒ€ì„_ì‘ì—…ì™„ë£Œê¸°ì¤€", "ë¦¬ë“œíƒ€ì„_ì¤‘ê°„ê°’_ì‘ì—…ì™„ë£Œê¸°ì¤€"]:
        out[c] = out[c].round(2)

    out = out[
        [COL_BP, "ìš”ì²­ìˆ˜ëŸ‰_í•©", "í‰ê· _ë¦¬ë“œíƒ€ì„_ì‘ì—…ì™„ë£Œê¸°ì¤€", "ë¦¬ë“œíƒ€ì„_ì¤‘ê°„ê°’_ì‘ì—…ì™„ë£Œê¸°ì¤€",
         "ìµœê·¼_ì¶œê³ ì¼", "ìµœê·¼_ì‘ì—…ì™„ë£Œì¼", "ì¶œê³ ê±´ìˆ˜", "ì§‘ê³„í–‰ìˆ˜_í‘œë³¸"]
    ].sort_values("ìš”ì²­ìˆ˜ëŸ‰_í•©", ascending=False, na_position="last")

    render_pretty_table(
        out,
        height=520,
        wrap_cols=[COL_BP],
        col_width_px={COL_BP: 280, "ìš”ì²­ìˆ˜ëŸ‰_í•©": 120, "ì¶œê³ ê±´ìˆ˜": 90, "ì§‘ê³„í–‰ìˆ˜_í‘œë³¸": 110},
        number_cols=["ìš”ì²­ìˆ˜ëŸ‰_í•©", "ì¶œê³ ê±´ìˆ˜", "ì§‘ê³„í–‰ìˆ˜_í‘œë³¸"],
    )

# =========================
# â‘¤ SKUë³„ ì¡°íšŒ
# =========================
elif nav == "â‘¤ SKUë³„ ì¡°íšŒ":
    st.subheader("SKUë³„ ì¡°íšŒ")

    if not need_cols(df_view, [COL_ITEM_CODE, COL_ITEM_NAME, COL_QTY, COL_SHIP, COL_BP], "SKUë³„ ì¡°íšŒ"):
        st.stop()

    period_title = "ëˆ„ì  SKU Top10 (ìš”ì²­ìˆ˜ëŸ‰ ê¸°ì¤€)" if sel_month_label == "ì „ì²´" else f"{sel_month_label} SKU Top10 (ìš”ì²­ìˆ˜ëŸ‰ ê¸°ì¤€)"
    st.subheader(period_title)

    top10_sku = build_item_top10_with_bp(df_view.copy())
    render_pretty_table(
        top10_sku,
        height=420,
        wrap_cols=[COL_ITEM_NAME, "BPëª…(ìš”ì²­ìˆ˜ëŸ‰)"],
        col_width_px={"ìˆœìœ„": 60, COL_ITEM_CODE: 130, COL_ITEM_NAME: 420, "ìš”ì²­ìˆ˜ëŸ‰_í•©": 120, "BPëª…(ìš”ì²­ìˆ˜ëŸ‰)": 520},
        number_cols=["ìš”ì²­ìˆ˜ëŸ‰_í•©"],
    )
    st.caption("â€» BPëª…(ìš”ì²­ìˆ˜ëŸ‰)ì€ í•´ë‹¹ SKUì˜ ì¶œê³ ì²˜ë³„ ìˆ˜ëŸ‰ í•©ê³„ì…ë‹ˆë‹¤. (ì™¼ìª½ í•„í„° ë²”ìœ„ ê¸°ì¤€)")

    st.divider()

    show_all_history = st.checkbox("ì „ì²´ íˆìŠ¤í† ë¦¬ ë³´ê¸°", value=True, key="sku_show_all_history")

    base = df_view.copy()
    base[COL_ITEM_CODE] = base[COL_ITEM_CODE].astype(str).str.strip()
    base[COL_ITEM_NAME] = base[COL_ITEM_NAME].astype(str).str.strip()

    q = st.text_input(
        "í’ˆëª©ì½”ë“œ ê²€ìƒ‰ (ë¶€ë¶„ê²€ìƒ‰ ê°€ëŠ¥)",
        value="",
        placeholder="ì˜ˆ: B5SN005A1",
        key="sku_query"
    )

    if not q.strip():
        st.info("ìƒë‹¨ì— í’ˆëª©ì½”ë“œë¥¼ ì…ë ¥í•˜ë©´, í•´ë‹¹ SKUì˜ ì¶œê³ ì¼ì/BPëª…/ìš”ì²­ìˆ˜ëŸ‰ì´ í‘œì‹œë©ë‹ˆë‹¤.")
        st.stop()

    q_norm = q.strip().upper()

    candidates = (
        base[base[COL_ITEM_CODE].str.upper().str.contains(re.escape(q_norm), na=False)][[COL_ITEM_CODE, COL_ITEM_NAME]]
        .dropna(subset=[COL_ITEM_CODE])
        .drop_duplicates(subset=[COL_ITEM_CODE])
        .sort_values(COL_ITEM_CODE)
        .reset_index(drop=True)
    )

    if candidates.empty:
        st.warning("í•´ë‹¹ í’ˆëª©ì½”ë“œê°€ í˜„ì¬ í•„í„° ë²”ìœ„ì—ì„œ ì¡°íšŒë˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
        st.stop()

    if len(candidates) > 1:
        cand_map = dict(zip(candidates[COL_ITEM_CODE], candidates[COL_ITEM_NAME]))
        sel_code = st.selectbox(
            "ê²€ìƒ‰ ê²°ê³¼ì—ì„œ ì„ íƒ",
            candidates[COL_ITEM_CODE].tolist(),
            key="sku_candidate_pick",
            format_func=lambda x: f"{x} / {cand_map.get(x, '')}".strip()
        )
    else:
        sel_code = candidates.iloc[0][COL_ITEM_CODE]

    d = base[base[COL_ITEM_CODE] == sel_code].copy()

    item_name = "-"
    nn = d[COL_ITEM_NAME].dropna()
    if not nn.empty:
        item_name = str(nn.iloc[0]).strip()

    st.markdown(f"- **í’ˆëª©ì½”ë“œ:** {html.escape(sel_code)}")
    st.markdown(f"- **í’ˆëª©ëª…:** {html.escape(item_name)}")

    d[COL_SHIP] = d[COL_SHIP].replace("", pd.NA)

    month_filter_is_all = (sel_month_label == "ì „ì²´")
    if (not show_all_history) and month_filter_is_all:
        today_ts = pd.Timestamp(date.today())
        ship_dt = pd.to_datetime(d[COL_SHIP], errors="coerce")
        d = d[(ship_dt.isna()) | (ship_dt >= today_ts)].copy()

    def ship_to_label(x):
        if pd.isna(x):
            return "ë¯¸ì •"
        return fmt_date(x)

    d["ì¶œê³ ì˜ˆì •ì¼"] = d[COL_SHIP].apply(ship_to_label)

    out = (
        d.groupby(["ì¶œê³ ì˜ˆì •ì¼", COL_BP], dropna=False)[COL_QTY]
        .sum(min_count=1)
        .reset_index()
        .rename(columns={COL_BP: "BPëª…", COL_QTY: "ìš”ì²­ìˆ˜ëŸ‰"})
    )
    out["ìš”ì²­ìˆ˜ëŸ‰"] = out["ìš”ì²­ìˆ˜ëŸ‰"].fillna(0).round(0).astype(int)

    total_sku_qty = int(out["ìš”ì²­ìˆ˜ëŸ‰"].fillna(0).sum()) if not out.empty else 0
    render_mini_kpi("ìš”ì²­ìˆ˜ëŸ‰ í•©ì‚°", f"{total_sku_qty:,}")

    out["_sort_date"] = pd.to_datetime(out["ì¶œê³ ì˜ˆì •ì¼"], errors="coerce")
    out = out.sort_values(
        by=["_sort_date", "ì¶œê³ ì˜ˆì •ì¼", "ìš”ì²­ìˆ˜ëŸ‰"],
        ascending=[True, True, False],
        na_position="last"
    ).drop(columns=["_sort_date"])

    render_pretty_table(
        out[["ì¶œê³ ì˜ˆì •ì¼", "BPëª…", "ìš”ì²­ìˆ˜ëŸ‰"]],
        height=520,
        wrap_cols=["BPëª…"],
        col_width_px={"ì¶œê³ ì˜ˆì •ì¼": 140, "BPëª…": 420, "ìš”ì²­ìˆ˜ëŸ‰": 120},
        number_cols=["ìš”ì²­ìˆ˜ëŸ‰"],
    )

st.caption("â€» ëª¨ë“  ì§‘ê³„ëŠ” Google Sheet RAW ê¸°ë°˜ì´ë©°, ì œí’ˆë¶„ë¥˜(B0/B1) ê³ ì • + ì„ íƒí•œ í•„í„° ë²”ìœ„ ë‚´ì—ì„œ ê³„ì‚°ë©ë‹ˆë‹¤.")
