# ==========================================
# B2B ì¶œê³  ëŒ€ì‹œë³´ë“œ (Google Sheet ê¸°ë°˜) - ìµœì¢… ì •ë¦¬ë³¸ (ì˜µì…˜ A)
#
# âœ… ì ìš©ì‚¬í•­
# 1) ì¿¼ë¦¬íŒŒë¼ë¯¸í„° ë‚´ë¹„ê²Œì´ì…˜ ì œê±°
# 2) ìƒˆíƒ­ ë°©ì§€: ìº˜ë¦°ë” BP í´ë¦­/ì´ì „ë‹¬/ë‹¤ìŒë‹¬/ë”ë³´ê¸°/ì ‘ê¸°/ë’¤ë¡œê°€ê¸° => st.button + session_state
# 3) 10ë§Œí–‰ ëŒ€ë¹„: df.apply(axis=1) ì œê±°(ì£¼ì°¨ ë²¡í„°í™”) + ìº˜ë¦°ë”ìš© ì§‘ê³„(cal_agg) ìºì‹œ ìƒì„±
# 4) ìº˜ë¦°ë” í‘œê¸°: íƒœê·¸(ğŸŸ¦ í•´ì™¸ / ğŸŸ© êµ­ë‚´)
#
# âœ… ë°˜ì˜(ì¶œê³ ê±´ìˆ˜)
# - ì¶œê³ ê±´ìˆ˜ = ì£¼ë¬¸ë²ˆí˜¸(distinct) ê¸°ì¤€ í†µì¼
#
# âœ… ì´ë²ˆ ìš”ì²­ ë°˜ì˜(2ê°€ì§€)
# - ë©”ë‰´ ì´ë™ ì‹œ â‘  ì¶œê³  ìº˜ë¦°ë”ëŠ” í•­ìƒ 'ìº˜ë¦°ë” ë©”ì¸'ìœ¼ë¡œ ì§„ì…(ìƒì„¸ í™”ë©´ ìƒíƒœ ìœ ì§€ ë°©ì§€)
# - ìƒì„¸ í™”ë©´ ì‘ì—…ì™„ë£Œê°€ ë‹¨ì¼ ë‚ ì§œë©´ 'YYYY-MM-DD'ë¡œ ë‹¨ì¼ í‘œì‹œ(ë™ì¼ì¼ì ~ ë™ì¼ì¼ì ì œê±°)
# ==========================================

import re
import html
import hashlib
import calendar as pycal
from datetime import date

import streamlit as st
import pandas as pd


# =========================
# ì»¬ëŸ¼ëª… í‘œì¤€í™” (RAW ê¸°ì¤€)
# =========================
COL_QTY = "ìš”ì²­ìˆ˜ëŸ‰"
COL_YEAR = "ë…„"
COL_MONTH = "ì›”1"
COL_DONE = "ì‘ì—…ì™„ë£Œ"
COL_SHIP = "ì¶œê³ ì¼ì"
COL_LT2 = "ë¦¬ë“œíƒ€ì„"
COL_BP = "BPëª…"
COL_MAIN = "ëŒ€í‘œí–‰"
COL_CUST1 = "ê±°ë˜ì²˜êµ¬ë¶„1"
COL_CUST2 = "ê±°ë˜ì²˜êµ¬ë¶„2"
COL_CLASS = "ì œí’ˆë¶„ë¥˜"
COL_ITEM_CODE = "í’ˆëª©ì½”ë“œ"
COL_ITEM_NAME = "í’ˆëª©ëª…"
COL_ORDER_DATE = "ë°œì£¼ì¼ì"
COL_ORDER_NO = "ì£¼ë¬¸ë²ˆí˜¸"

CATEGORY_COL_CANDIDATES = [
    "ì¹´í…Œê³ ë¦¬ ë¼ì¸", "ì¹´í…Œê³ ë¦¬ë¼ì¸", "ì¹´í…Œê³ ë¦¬", "ì¹´í…Œê³ ë¦¬(Line)", "ì¹´í…Œê³ ë¦¬_LINE",
    "Category Line", "Category"
]

KEEP_CLASSES = ["B0", "B1"]
LT_ONLY_CUST1 = "í•´ì™¸B2B"
SPIKE_FACTOR = 1.3


# =========================
# Google Sheet ì„¤ì •
# =========================
GSHEET_ID = "1jbWMgV3fudWCQ1qhG0lCysZGGFCo4loTIf-j3iuaqOI"
GSHEET_GID = "15468212"
HEADER_ROW_0BASED = 6

# âœ… ì„±ëŠ¥: ì‹¤ì œ ì‚¬ìš©í•˜ëŠ” ì»¬ëŸ¼ë§Œ ë¡œë“œ (ì‹œíŠ¸ ì»¬ëŸ¼ëª…ê³¼ ì •í™•íˆ ì¼ì¹˜í•´ì•¼ í•¨)
USECOLS = [
    COL_QTY, COL_YEAR, COL_MONTH,
    COL_DONE, COL_SHIP, COL_LT2,
    COL_BP, COL_MAIN,
    COL_CUST1, COL_CUST2,
    COL_CLASS,
    COL_ITEM_CODE, COL_ITEM_NAME,
    COL_ORDER_DATE, COL_ORDER_NO,
]

# âœ… ì„±ëŠ¥: ë¬¸ìì—´ dtype ê°•ì œ(íŒŒì‹± ë¹„ìš©/ì˜¤ë¥˜ ê°ì†Œ)
DTYPE_MAP = {
    COL_YEAR: "string",
    COL_MONTH: "string",
    COL_BP: "string",
    COL_MAIN: "string",
    COL_CUST1: "string",
    COL_CUST2: "string",
    COL_CLASS: "string",
    COL_ITEM_CODE: "string",
    COL_ITEM_NAME: "string",
    COL_ORDER_NO: "string",
}


# =========================
# Streamlit ì„¤ì •
# =========================
st.set_page_config(page_title="B2B ì¶œê³  ëŒ€ì‹œë³´ë“œ (Google Sheet ê¸°ë°˜)", layout="wide")


def safe_rerun():
    if hasattr(st, "rerun"):
        st.rerun()
    else:
        st.experimental_rerun()


# -------------------------
# UI Style
# -------------------------
BASE_CSS = """
<style>
.block-container {padding-top: 1.2rem; padding-bottom: 2.5rem;}
h1, h2, h3 {letter-spacing: -0.2px;}

.kpi-wrap {display:flex; gap:0.75rem; flex-wrap:wrap; margin: 0.25rem 0 0.75rem 0;}
.kpi-card {
  background: #ffffff;
  border: 1px solid #e5e7eb;
  border-radius: 14px;
  padding: 0.9rem 0.95rem;
  min-width: 180px;
  flex: 1 1 180px;
  box-shadow: 0 1px 0 rgba(0,0,0,0.02);
}
.kpi-title {color:#6b7280; font-size:0.9rem; margin-bottom:0.35rem;}
.kpi-value {font-size:1.35rem; font-weight:700; color:#111827; line-height:1.2;}
.kpi-big {font-size:1.55rem; font-weight:800; color:#111827; line-height:1.15;}
.kpi-muted {color:#6b7280; font-size:0.85rem; margin-top:0.15rem; white-space:normal; word-break:break-word;}

.pretty-table-wrap {margin-top: 0.25rem;}
.table-frame{
  border: 1px solid #e5e7eb;
  border-radius: 14px;
  overflow: hidden;
  background: #fff;
}
.table-scroll{
  height: 520px;
  overflow: auto;
  position: relative;
}
table.pretty-table{
  width: 100%;
  border-collapse: separate;
  border-spacing: 0;
  background: #fff;
  font-size: 0.93rem;
}
.pretty-table thead th{
  position: -webkit-sticky;
  position: sticky;
  top: 0;
  background: #f9fafb;
  color:#111827;
  text-align: left;
  padding: 10px 10px;
  border-bottom: 1px solid #e5e7eb;
  z-index: 10;
  white-space: nowrap;
  box-shadow: 0 1px 0 rgba(0,0,0,0.06);
}
.pretty-table tbody td{
  padding: 10px 10px;
  border-bottom: 1px solid #f3f4f6;
  vertical-align: top;
}
.pretty-table tbody tr:nth-child(even) td {background: #fcfcfd;}
.pretty-table tbody tr:hover td {background: #f7fbff;}
.wrap {white-space: normal; word-break: break-word; line-height: 1.25rem;}
.mono {font-variant-numeric: tabular-nums;}

.comment-block { margin: 0.6rem 0 1.05rem 0; }
.comment-title{
  font-weight: 900;
  font-size: 1.06rem;
  margin: 0.2rem 0 0.25rem 0;
}
.comment{ margin: 0.08rem 0 0 0; line-height: 1.55; }

.cal-note {color:#6b7280; font-size:0.9rem; margin-top:0.2rem;}
</style>
"""
st.markdown(BASE_CSS, unsafe_allow_html=True)


# =========================
# Utils
# =========================
def make_btn_key(*parts) -> str:
    raw = "|".join([str(p) for p in parts])
    return hashlib.md5(raw.encode("utf-8")).hexdigest()


def to_bool_true(s: pd.Series) -> pd.Series:
    x = s.fillna("").astype(str).str.strip().str.upper()
    return x.isin(["TRUE", "T", "1", "Y", "YES"])


def safe_dt(df: pd.DataFrame, col: str) -> None:
    if col in df.columns:
        df[col] = pd.to_datetime(df[col], errors="coerce")


def safe_num(df: pd.DataFrame, col: str) -> None:
    if col in df.columns:
        s = df[col].astype(str).str.replace(",", "", regex=False).str.strip()
        s = s.replace({"": None, "nan": None, "None": None})
        df[col] = pd.to_numeric(s, errors="coerce")


def uniq_sorted(df: pd.DataFrame, col: str):
    if df is None or df.empty or col not in df.columns:
        return []
    return sorted(df[col].dropna().astype(str).unique().tolist())


def fmt_date(dtval) -> str:
    if pd.isna(dtval):
        return "-"
    return pd.to_datetime(dtval).strftime("%Y-%m-%d")


def need_cols(df: pd.DataFrame, cols: list[str], title: str = "í•„ìš” ì»¬ëŸ¼ ëˆ„ë½"):
    missing = [c for c in cols if c not in df.columns]
    if missing:
        st.warning(f"{title}: {missing}")
        return False
    return True


def normalize_text_cols(df: pd.DataFrame, cols: list[str]) -> None:
    for c in cols:
        if c in df.columns:
            df[c] = df[c].astype(str).str.strip()


def safe_selectbox(label: str, options: list[str], key: str, default="ì „ì²´"):
    if not options:
        options = [default]
    if key not in st.session_state:
        st.session_state[key] = default
    if st.session_state[key] not in options:
        st.session_state[key] = default if default in options else options[0]
    return st.selectbox(label, options, key=key)


def _escape(x) -> str:
    if pd.isna(x):
        return ""
    return html.escape(str(x))


def _fmt_num_for_table(v) -> str:
    if pd.isna(v):
        return ""
    try:
        if isinstance(v, (int,)) and not isinstance(v, bool):
            return f"{v:,}"
        if isinstance(v, float):
            if float(v).is_integer():
                return f"{int(v):,}"
            return f"{v:,.2f}"
        vv = float(v)
        if vv.is_integer():
            return f"{int(vv):,}"
        return f"{vv:,.2f}"
    except Exception:
        return str(v)


def render_pretty_table(
    df: pd.DataFrame,
    height: int = 520,
    wrap_cols=None,
    number_cols=None,
    max_rows: int = 500,
):
    """
    - ì‘ì€ í‘œ: HTML pretty table
    - ë„ˆë¬´ í° í‘œ: st.dataframe fallback (ë¸Œë¼ìš°ì € ë Œë” ë¶€ë‹´/ì˜¤ë¥˜ ë°©ì§€)
    """
    wrap_cols = set(wrap_cols or [])
    number_cols = set(number_cols or [])

    if df is None or df.empty:
        st.info("í‘œì‹œí•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return

    if len(df) > max_rows:
        st.caption(f"í–‰ì´ ë§ì•„({len(df):,}í–‰) DataFrame ë·°ë¡œ í‘œì‹œí•©ë‹ˆë‹¤.")
        st.dataframe(df, use_container_width=True, height=height)
        return

    cols = list(df.columns)

    colgroup = "<colgroup>" + "".join(["<col>" for _ in cols]) + "</colgroup>"
    thead = "<thead><tr>" + "".join([f"<th>{_escape(c)}</th>" for c in cols]) + "</tr></thead>"

    tbody_rows = []
    for _, row in df.iterrows():
        tds = []
        for c in cols:
            v = row[c]
            cls = []
            if c in wrap_cols:
                cls.append("wrap")
            if c in number_cols:
                cls.append("mono")
                v_disp = _fmt_num_for_table(v)
            else:
                v_disp = "" if pd.isna(v) else str(v)
            class_attr = f' class="{" ".join(cls)}"' if cls else ""
            tds.append(f"<td{class_attr}>{_escape(v_disp)}</td>")
        tbody_rows.append("<tr>" + "".join(tds) + "</tr>")
    tbody = "<tbody>" + "".join(tbody_rows) + "</tbody>"

    st.markdown(
        f"""
        <div class="pretty-table-wrap">
          <div class="table-frame">
            <div class="table-scroll" style="height:{int(height)}px;">
              <table class="pretty-table">
                {colgroup}
                {thead}
                {tbody}
              </table>
            </div>
          </div>
        </div>
        """,
        unsafe_allow_html=True
    )


def render_numbered_block(title: str, items: list[str]):
    if not items:
        return
    st.markdown(
        f"""
        <div class="comment-block">
          <div class="comment-title">{html.escape(title)}</div>
        """,
        unsafe_allow_html=True
    )
    for i, line in enumerate(items, start=1):
        st.markdown(f"""<div class="comment">{i}) {line}</div>""", unsafe_allow_html=True)
    st.markdown("</div>", unsafe_allow_html=True)


# =========================
# Label helpers
# =========================
def make_month_label(year: int, month: int) -> str:
    return f"{int(year)}ë…„ {int(month)}ì›”"


def parse_month_label_key(label: str) -> tuple[int, int]:
    y = m = 0
    try:
        my = re.search(r"(\d{4})\s*ë…„", str(label))
        mm = re.search(r"(\d+)\s*ì›”", str(label))
        if my:
            y = int(my.group(1))
        if mm:
            m = int(mm.group(1))
    except Exception:
        pass
    return (y, m)


def parse_week_label_key(label: str) -> tuple[int, int, int]:
    y = m = w = 0
    try:
        my = re.search(r"(\d{4})\s*ë…„", str(label))
        mm = re.search(r"(\d+)\s*ì›”", str(label))
        mw = re.search(r"(\d+)\s*ì£¼ì°¨", str(label))
        if my:
            y = int(my.group(1))
        if mm:
            m = int(mm.group(1))
        if mw:
            w = int(mw.group(1))
    except Exception:
        pass
    return (y, m, w)


def month_key_num_from_label(label: str):
    y, m = parse_month_label_key(label)
    if y <= 0 or m <= 0:
        return None
    return y * 100 + m


def month_label_next(label: str):
    y, m = parse_month_label_key(label)
    if y <= 0 or m <= 0:
        return None
    if m == 12:
        return make_month_label(y + 1, 1)
    return make_month_label(y, m + 1)


# =========================
# SKU ìë™ ì½”ë©˜íŠ¸(ì›ë³¸ ê¸°ëŠ¥ ìœ ì§€)
# =========================
def _fmt_int(x) -> str:
    try:
        return f"{int(round(float(x))):,}"
    except Exception:
        return "0"


def sku_comment_mom(sku_month: pd.DataFrame) -> list[str]:
    if sku_month is None or sku_month.empty:
        return []
    m = sku_month.sort_values("_month_key")
    if len(m) < 2:
        return []
    prev = m.iloc[-2]
    cur = m.iloc[-1]
    prev_q = float(prev["qty"]) if pd.notna(prev["qty"]) else 0.0
    cur_q = float(cur["qty"]) if pd.notna(cur["qty"]) else 0.0
    if prev_q <= 0:
        return [f"ìµœê·¼ ì›”({cur['_month_label']}) ì¶œê³ ìˆ˜ëŸ‰ {_fmt_int(cur_q)} (ì§ì „ì›”({prev['_month_label']}) ë°ì´í„° 0/ë¶€ì¡±ìœ¼ë¡œ ì¦ê°ë¥  ì‚°ì • ë¶ˆê°€)"]
    pct = (cur_q / prev_q - 1) * 100
    direction = "ìƒìŠ¹" if pct > 0 else "í•˜ë½" if pct < 0 else "ë³€ë™ ì—†ìŒ"
    return [f"{prev['_month_label']} ëŒ€ë¹„ {cur['_month_label']} ì¶œê³ ëŸ‰ **{direction} ({pct:+.0f}%)** Â· {_fmt_int(prev_q)} â†’ {_fmt_int(cur_q)}"]


def sku_comment_trend(sku_month: pd.DataFrame) -> list[str]:
    if sku_month is None or sku_month.empty:
        return []
    m = sku_month.sort_values("_month_key")
    if len(m) < 3:
        return []

    last3 = m.iloc[-3:].copy()
    q0, q1, q2 = [float(x) if pd.notna(x) else 0.0 for x in last3["qty"].tolist()]
    l0, l1, l2 = last3["_month_label"].astype(str).tolist()

    if q0 < q1 < q2:
        return [f"ìµœê·¼ 3ê°œì›”({l0} â†’ {l2}) ê¸°ì¤€: ì¶œê³ ëŸ‰ **ì§€ì† ìƒìŠ¹** ( {_fmt_int(q0)} â†’ {_fmt_int(q2)} )"]
    if q0 > q1 > q2:
        return [f"ìµœê·¼ 3ê°œì›”({l0} â†’ {l2}) ê¸°ì¤€: ì¶œê³ ëŸ‰ **ì§€ì† í•˜ë½** ( {_fmt_int(q0)} â†’ {_fmt_int(q2)} )"]

    return [f"ìµœê·¼ 3ê°œì›”({l0} â†’ {l2}) ê¸°ì¤€: **ë³€ë™(í˜¼ì¡°)**"]


def sku_comment_bp_spike(df_sku: pd.DataFrame, spike_factor=1.5, top_n=3) -> list[str]:
    if df_sku.empty or (COL_BP not in df_sku.columns) or (COL_QTY not in df_sku.columns):
        return []
    if "_month_label" not in df_sku.columns:
        return []

    m = (
        df_sku.dropna(subset=["_month_label"])
        .groupby([COL_BP, "_month_label"], dropna=False)[COL_QTY]
        .sum(min_count=1)
        .reset_index()
        .rename(columns={COL_QTY: "m_qty"})
    )
    if m.empty:
        return []

    m["_month_key"] = m["_month_label"].astype(str).apply(parse_month_label_key)

    spikes = []
    for bp, sub in m.groupby(COL_BP, dropna=False):
        sub = sub.sort_values("_month_key")
        if len(sub) < 2:
            continue

        for _, r in sub.iterrows():
            cur_month = r["_month_label"]
            cur_qty = float(r["m_qty"]) if pd.notna(r["m_qty"]) else 0.0
            others = sub[sub["_month_label"] != cur_month]["m_qty"].astype(float)
            baseline = float(others.mean()) if len(others) > 0 else 0.0
            if baseline <= 0:
                continue
            if cur_qty < baseline * spike_factor:
                continue
            pct = (cur_qty / baseline - 1) * 100
            spikes.append({"bp": str(bp), "month": str(cur_month), "pct": pct, "qty": cur_qty, "baseline": baseline})

    if not spikes:
        return []

    spikes = sorted(spikes, key=lambda x: x["pct"], reverse=True)[:top_n]
    return [f"{s['bp']} ({s['month']}) í‰ê·  ëŒ€ë¹„ **{s['pct']:+.0f}%** Â· {_fmt_int(s['baseline'])} â†’ {_fmt_int(s['qty'])}" for s in spikes]


# =========================
# TopN breakdown(ëŒ€ìš©ëŸ‰ ìµœì í™”)
# =========================
def build_bp_list_map_for_items(df_period: pd.DataFrame, items: pd.DataFrame) -> pd.DataFrame:
    if df_period.empty or items.empty:
        return pd.DataFrame(columns=[COL_ITEM_CODE, COL_ITEM_NAME, "BPëª…(ìš”ì²­ìˆ˜ëŸ‰)"])

    key_df = items[[COL_ITEM_CODE, COL_ITEM_NAME]].drop_duplicates()
    sub = df_period.merge(key_df, on=[COL_ITEM_CODE, COL_ITEM_NAME], how="inner")
    if sub.empty:
        return pd.DataFrame(columns=[COL_ITEM_CODE, COL_ITEM_NAME, "BPëª…(ìš”ì²­ìˆ˜ëŸ‰)"])

    bp_break = (
        sub.groupby([COL_ITEM_CODE, COL_ITEM_NAME, COL_BP], dropna=False)[COL_QTY]
        .sum(min_count=1)
        .reset_index()
        .rename(columns={COL_QTY: "BPìš”ì²­ìˆ˜ëŸ‰"})
    )

    def format_bp_list(x: pd.DataFrame) -> str:
        x = x.sort_values("BPìš”ì²­ìˆ˜ëŸ‰", ascending=False, na_position="last")
        out = []
        for _, r in x.iterrows():
            bp = str(r[COL_BP]).strip()
            q = r["BPìš”ì²­ìˆ˜ëŸ‰"]
            q = 0 if pd.isna(q) else q
            out.append(f"{bp}({int(round(float(q))):,})")
        return "/ ".join(out)

    return (
        bp_break.groupby([COL_ITEM_CODE, COL_ITEM_NAME], dropna=False)
        .apply(format_bp_list)
        .reset_index(name="BPëª…(ìš”ì²­ìˆ˜ëŸ‰)")
    )


def build_item_topn_with_bp(df_period: pd.DataFrame, n: int) -> pd.DataFrame:
    if df_period.empty:
        return pd.DataFrame(columns=["ìˆœìœ„", COL_ITEM_CODE, COL_ITEM_NAME, "ìš”ì²­ìˆ˜ëŸ‰_í•©", "BPëª…(ìš”ì²­ìˆ˜ëŸ‰)"])

    topn = (
        df_period.groupby([COL_ITEM_CODE, COL_ITEM_NAME], dropna=False)[COL_QTY]
        .sum(min_count=1)
        .reset_index(name="ìš”ì²­ìˆ˜ëŸ‰_í•©")
        .sort_values("ìš”ì²­ìˆ˜ëŸ‰_í•©", ascending=False, na_position="last")
        .head(n)
        .copy()
    )
    bp_map = build_bp_list_map_for_items(df_period, topn)
    topn = topn.merge(bp_map, on=[COL_ITEM_CODE, COL_ITEM_NAME], how="left")
    topn.insert(0, "ìˆœìœ„", range(1, len(topn) + 1))
    topn["ìš”ì²­ìˆ˜ëŸ‰_í•©"] = pd.to_numeric(topn["ìš”ì²­ìˆ˜ëŸ‰_í•©"], errors="coerce").fillna(0).round(0).astype(int)
    topn["BPëª…(ìš”ì²­ìˆ˜ëŸ‰)"] = topn["BPëª…(ìš”ì²­ìˆ˜ëŸ‰)"].fillna("")
    return topn[["ìˆœìœ„", COL_ITEM_CODE, COL_ITEM_NAME, "ìš”ì²­ìˆ˜ëŸ‰_í•©", "BPëª…(ìš”ì²­ìˆ˜ëŸ‰)"]]


def build_spike_report_only(cur_df: pd.DataFrame, prev_df: pd.DataFrame) -> pd.DataFrame:
    cols = [COL_ITEM_CODE, COL_ITEM_NAME, "ì´ì „_ìš”ì²­ìˆ˜ëŸ‰", "í˜„ì¬_ìš”ì²­ìˆ˜ëŸ‰", "ì¦ê°€ë°°ìˆ˜", "BPëª…(ìš”ì²­ìˆ˜ëŸ‰)"]
    if cur_df.empty:
        return pd.DataFrame(columns=cols)

    cur_sku = (
        cur_df.groupby([COL_ITEM_CODE, COL_ITEM_NAME], dropna=False)[COL_QTY]
        .sum(min_count=1)
        .reset_index(name="í˜„ì¬_ìš”ì²­ìˆ˜ëŸ‰")
    )

    prev_sku = (
        prev_df.groupby([COL_ITEM_CODE, COL_ITEM_NAME], dropna=False)[COL_QTY]
        .sum(min_count=1)
        .reset_index(name="ì´ì „_ìš”ì²­ìˆ˜ëŸ‰")
    ) if not prev_df.empty else pd.DataFrame(columns=[COL_ITEM_CODE, COL_ITEM_NAME, "ì´ì „_ìš”ì²­ìˆ˜ëŸ‰"])

    cmp = cur_sku.merge(prev_sku, on=[COL_ITEM_CODE, COL_ITEM_NAME], how="left")
    cmp["ì´ì „_ìš”ì²­ìˆ˜ëŸ‰"] = pd.to_numeric(cmp["ì´ì „_ìš”ì²­ìˆ˜ëŸ‰"], errors="coerce").fillna(0)
    cmp["í˜„ì¬_ìš”ì²­ìˆ˜ëŸ‰"] = pd.to_numeric(cmp["í˜„ì¬_ìš”ì²­ìˆ˜ëŸ‰"], errors="coerce").fillna(0)

    cmp["ì¦ê°€ë°°ìˆ˜"] = cmp.apply(
        lambda r: (r["í˜„ì¬_ìš”ì²­ìˆ˜ëŸ‰"] / r["ì´ì „_ìš”ì²­ìˆ˜ëŸ‰"]) if r["ì´ì „_ìš”ì²­ìˆ˜ëŸ‰"] > 0 else pd.NA,
        axis=1
    )

    spike = cmp[(cmp["ì´ì „_ìš”ì²­ìˆ˜ëŸ‰"] > 0) & (cmp["í˜„ì¬_ìš”ì²­ìˆ˜ëŸ‰"] >= cmp["ì´ì „_ìš”ì²­ìˆ˜ëŸ‰"] * SPIKE_FACTOR)].copy()
    if spike.empty:
        spike["BPëª…(ìš”ì²­ìˆ˜ëŸ‰)"] = ""
        return spike[cols]

    bp_map = build_bp_list_map_for_items(cur_df, spike[[COL_ITEM_CODE, COL_ITEM_NAME]])
    spike = spike.merge(bp_map, on=[COL_ITEM_CODE, COL_ITEM_NAME], how="left")

    spike["í˜„ì¬_ìš”ì²­ìˆ˜ëŸ‰"] = spike["í˜„ì¬_ìš”ì²­ìˆ˜ëŸ‰"].round(0).astype(int)
    spike["ì´ì „_ìš”ì²­ìˆ˜ëŸ‰"] = spike["ì´ì „_ìš”ì²­ìˆ˜ëŸ‰"].round(0).astype(int)
    spike["ì¦ê°€ë°°ìˆ˜"] = pd.to_numeric(spike["ì¦ê°€ë°°ìˆ˜"], errors="coerce").round(2)
    spike["BPëª…(ìš”ì²­ìˆ˜ëŸ‰)"] = spike["BPëª…(ìš”ì²­ìˆ˜ëŸ‰)"].fillna("")
    spike = spike.sort_values("í˜„ì¬_ìš”ì²­ìˆ˜ëŸ‰", ascending=False)
    return spike[cols]


# =========================
# ì£¼ì°¨/ì›”ê°„ ìë™ ì½”ë©˜íŠ¸ helpers
# =========================
def _delta_arrow(diff: float) -> str:
    if pd.isna(diff) or abs(diff) < 1e-12:
        return "-"
    return "â–²" if diff > 0 else "â–¼"


def _delta_text(diff: float) -> str:
    if pd.isna(diff):
        return "-"
    try:
        d = int(round(float(diff)))
        return f"{d:+,}"
    except Exception:
        return "-"


def _fmt_delta(diff: float) -> str:
    return f"{_delta_text(diff)} {_delta_arrow(diff)}"


def _clean_nunique(series: pd.Series) -> int:
    if series is None:
        return 0
    s = series.astype(str).str.strip()
    s = s.replace({"": pd.NA, "nan": pd.NA, "None": pd.NA})
    return int(s.dropna().nunique())


def _get_order_cnt(df: pd.DataFrame) -> int:
    if df is None or df.empty or COL_ORDER_NO not in df.columns:
        return 0
    return _clean_nunique(df[COL_ORDER_NO])


def _get_ship_cnt(df: pd.DataFrame) -> int:
    """
    âœ… ì¶œê³ ê±´ìˆ˜ = ì£¼ë¬¸ë²ˆí˜¸ distinct
    """
    if df is None or df.empty or COL_ORDER_NO not in df.columns:
        return 0
    return _clean_nunique(df[COL_ORDER_NO])


def _get_qty(df: pd.DataFrame) -> int:
    if df is None or df.empty or COL_QTY not in df.columns:
        return 0
    return int(round(float(df[COL_QTY].fillna(0).sum()), 0))


def _get_lt_mean(df: pd.DataFrame) -> float:
    if df is None or df.empty or COL_LT2 not in df.columns:
        return float("nan")
    s = pd.to_numeric(df[COL_LT2], errors="coerce").dropna()
    if s.empty:
        return float("nan")
    return float(s.mean())


def _find_category_col(df: pd.DataFrame):
    for c in CATEGORY_COL_CANDIDATES:
        if c in df.columns:
            return c
    return None


def new_bp_comment(all_df: pd.DataFrame, cur_df: pd.DataFrame, key_col_num: str, cur_key_num, top_n: int = 5) -> list[str]:
    if cur_df is None or cur_df.empty or COL_BP not in cur_df.columns:
        return []

    hist = all_df.copy()
    if key_col_num in hist.columns and cur_key_num is not None:
        hist_key = pd.to_numeric(hist[key_col_num], errors="coerce")
        hist = hist[hist_key.notna() & (hist_key.astype(int) < int(cur_key_num))]

    hist_bps = set(hist[COL_BP].dropna().astype(str).str.strip().tolist()) if (COL_BP in hist.columns and not hist.empty) else set()
    cur_bps = set(cur_df[COL_BP].dropna().astype(str).str.strip().tolist())

    new_bps = [bp for bp in cur_bps if bp and bp not in hist_bps]
    if not new_bps:
        return ["ì‹ ê·œ ì¶œê³  BP: ì—†ìŒ"]

    sub = cur_df[cur_df[COL_BP].astype(str).str.strip().isin(new_bps)].copy()
    if COL_QTY in sub.columns:
        g = sub.groupby(COL_BP)[COL_QTY].sum().sort_values(ascending=False).head(top_n)
        desc = ", ".join([f"{idx}({_fmt_int(val)})" for idx, val in g.items()])
    else:
        desc = ", ".join(new_bps[:top_n])

    return [f"ì‹ ê·œ ì¶œê³  BP: {desc}"]


def category_top_comment(cur_df: pd.DataFrame, top_n: int = 2) -> list[str]:
    if cur_df is None or cur_df.empty or COL_QTY not in cur_df.columns:
        return []
    cat_col = _find_category_col(cur_df)
    if not cat_col:
        return []
    tmp = cur_df.copy()
    tmp[cat_col] = tmp[cat_col].astype(str).str.strip()
    g = tmp.groupby(cat_col, dropna=False)[COL_QTY].sum(min_count=1).sort_values(ascending=False).head(top_n)
    if g.empty:
        return []
    desc = ", ".join([f"{idx}({_fmt_int(val)})" for idx, val in g.items()])
    return [f"ì¹´í…Œê³ ë¦¬ TOP{top_n}: {desc}"]


def concentration_comment(cur_df: pd.DataFrame) -> list[str]:
    if cur_df is None or cur_df.empty or COL_QTY not in cur_df.columns:
        return []
    total = float(cur_df[COL_QTY].fillna(0).sum())
    if total <= 0:
        return []

    out = []
    if COL_BP in cur_df.columns:
        g = cur_df.groupby(COL_BP, dropna=False)[COL_QTY].sum(min_count=1).sort_values(ascending=False)
        if not g.empty:
            top_bp = str(g.index[0]).strip()
            top_bp_qty = float(g.iloc[0])
            out.append(f"Top BP ì§‘ì¤‘ë„: 1ìœ„ {top_bp}({_fmt_int(top_bp_qty)}) {top_bp_qty/total*100:.0f}%")

    if all(c in cur_df.columns for c in [COL_ITEM_CODE, COL_ITEM_NAME]):
        g2 = cur_df.groupby([COL_ITEM_CODE, COL_ITEM_NAME], dropna=False)[COL_QTY].sum(min_count=1).sort_values(ascending=False)
        if not g2.empty:
            (top_code, top_name) = g2.index[0]
            top_qty = float(g2.iloc[0])
            out.append(f"Top SKU ì§‘ì¤‘ë„: 1ìœ„ {str(top_code).strip()} / {str(top_name).strip()}({_fmt_int(top_qty)}) {top_qty/total*100:.0f}%")

    return out[:2]


def undated_ship_risk_comment(cur_df: pd.DataFrame) -> list[str]:
    if cur_df is None or cur_df.empty or COL_SHIP not in cur_df.columns or COL_QTY not in cur_df.columns:
        return []
    total_qty = float(cur_df[COL_QTY].fillna(0).sum())
    if total_qty <= 0:
        return []
    ship_dt = pd.to_datetime(cur_df[COL_SHIP], errors="coerce")
    miss = cur_df[ship_dt.isna()].copy()
    miss_qty = float(miss[COL_QTY].fillna(0).sum()) if not miss.empty else 0.0
    if miss_qty <= 0:
        return []
    return [f"ì¶œê³ ì¼ ë¯¸ì • ìˆ˜ëŸ‰: {_fmt_int(miss_qty)} ({miss_qty/total_qty*100:.0f}%)"]


def period_kpi_delta_comment(cur_df: pd.DataFrame, prev_df: pd.DataFrame) -> list[str]:
    cur_order = _get_order_cnt(cur_df); prev_order = _get_order_cnt(prev_df)
    cur_ship = _get_ship_cnt(cur_df);  prev_ship = _get_ship_cnt(prev_df)
    cur_qty = _get_qty(cur_df);        prev_qty = _get_qty(prev_df)
    cur_lt = _get_lt_mean(cur_df);     prev_lt = _get_lt_mean(prev_df)

    order_part = f"ë°œì£¼ê±´ìˆ˜ {cur_order}ê±´ ({_fmt_delta(cur_order - prev_order)})"
    ship_part = f"ì¶œê³ ê±´ìˆ˜ {cur_ship}ê±´ ({_fmt_delta(cur_ship - prev_ship)})"
    qty_part = f"ì¶œê³ ìˆ˜ëŸ‰ {cur_qty:,}ê°œ ({_fmt_delta(cur_qty - prev_qty)})"

    if (not pd.isna(cur_lt)) and (not pd.isna(prev_lt)):
        lt_part = f"í‰ê·  ë¦¬ë“œíƒ€ì„ {cur_lt:.1f}ì¼ ({_fmt_delta(cur_lt - prev_lt)})"
    elif (not pd.isna(cur_lt)) and pd.isna(prev_lt):
        lt_part = f"í‰ê·  ë¦¬ë“œíƒ€ì„ {cur_lt:.1f}ì¼ (ì§ì „ê¸°ê°„ ë°ì´í„° ë¶€ì¡±)"
    else:
        lt_part = "í‰ê·  ë¦¬ë“œíƒ€ì„ -"

    return [f"ì§ì „ê¸°ê°„ ëŒ€ë¹„: {order_part} / {ship_part} / {qty_part} / {lt_part}"]


# =========================
# ì›”ê°„ ë¦¬í¬íŠ¸ helpers (ì›ë³¸ ê¸°ëŠ¥ ìœ ì§€)
# =========================
def _is_jp_cn_line(item_name: str) -> bool:
    s = (item_name or "").upper()
    return (" JP" in s) or (" CN" in s) or ("JP " in s) or ("CN " in s) or ("JP" in s and "JPG" not in s) or ("CN" in s)


def _bp_item_qty_breakdown(df: pd.DataFrame, code: str, name: str, top_n: int = 3) -> str:
    if df is None or df.empty:
        return ""
    sub = df[(df[COL_ITEM_CODE].astype(str).str.strip() == str(code).strip()) &
             (df[COL_ITEM_NAME].astype(str).str.strip() == str(name).strip())].copy()
    if sub.empty:
        return ""
    g = sub.groupby(COL_BP)[COL_QTY].sum().sort_values(ascending=False).head(top_n)
    return "/ ".join([f"{bp}({int(round(q)):,})" for bp, q in g.items()])


def _sku_mom_change_lines(cur_df: pd.DataFrame, prev_df: pd.DataFrame, top_n: int = 6) -> list[str]:
    if cur_df is None or cur_df.empty or COL_QTY not in cur_df.columns:
        return []

    cur = cur_df.groupby([COL_ITEM_CODE, COL_ITEM_NAME], dropna=False)[COL_QTY].sum(min_count=1).reset_index(name="cur")
    prev = prev_df.groupby([COL_ITEM_CODE, COL_ITEM_NAME], dropna=False)[COL_QTY].sum(min_count=1).reset_index(name="prev") if (prev_df is not None and not prev_df.empty and COL_QTY in prev_df.columns) else pd.DataFrame(columns=[COL_ITEM_CODE, COL_ITEM_NAME, "prev"])

    m = cur.merge(prev, on=[COL_ITEM_CODE, COL_ITEM_NAME], how="left")
    m["prev"] = pd.to_numeric(m["prev"], errors="coerce").fillna(0)
    m["cur"] = pd.to_numeric(m["cur"], errors="coerce").fillna(0)

    m = m[m["prev"] > 0].copy()
    if m.empty:
        return []

    m["pct"] = (m["cur"] / m["prev"] - 1.0) * 100.0
    m = m.sort_values(["cur"], ascending=False).head(top_n)

    out = []
    for _, r in m.iterrows():
        code = str(r[COL_ITEM_CODE]).strip()
        name = str(r[COL_ITEM_NAME]).strip()
        out.append(f"- {code} {name} : {float(r['pct']):+.0f}% ({int(r['prev']):,} â†’ {int(r['cur']):,})")
    return out


def _new_bp_first_ship_lines(all_df_section: pd.DataFrame, cur_df_section: pd.DataFrame, cur_month_key: int | None, top_items: int = 4) -> list[str]:
    if cur_df_section is None or cur_df_section.empty or COL_BP not in cur_df_section.columns:
        return []

    hist = all_df_section.copy()
    if "_month_key_num" in hist.columns and cur_month_key is not None:
        hist = hist[pd.to_numeric(hist["_month_key_num"], errors="coerce").fillna(0).astype(int) < int(cur_month_key)]

    hist_bps = set(hist[COL_BP].dropna().astype(str).str.strip().tolist()) if not hist.empty else set()
    cur_bps = sorted(set(cur_df_section[COL_BP].dropna().astype(str).str.strip().tolist()))

    new_bps = [bp for bp in cur_bps if bp and bp not in hist_bps]
    if not new_bps:
        return ["- ì‹ ê·œ BP ì²« ì¶œê³ : ì—†ìŒ"]

    out = []
    for bp in new_bps[:5]:
        sub = cur_df_section[cur_df_section[COL_BP].astype(str).str.strip() == bp].copy()
        total_qty = int(round(sub[COL_QTY].fillna(0).sum(), 0)) if COL_QTY in sub.columns else 0
        sku_cnt = int(sub[COL_ITEM_CODE].dropna().astype(str).str.strip().nunique()) if COL_ITEM_CODE in sub.columns else 0

        top = (
            sub.groupby([COL_ITEM_CODE, COL_ITEM_NAME])[COL_QTY]
            .sum().reset_index(name="qty")
            .sort_values("qty", ascending=False)
            .head(top_items)
        )
        top_list = [f"{r[COL_ITEM_CODE]} {r[COL_ITEM_NAME]}({int(round(r['qty'])):,})" for _, r in top.iterrows()] if not top.empty else []
        top_txt = " / ".join(top_list) if top_list else "-"

        out.append(f"- {bp}: ì´ {sku_cnt}SKU / {total_qty:,}ê°œ | ì£¼ìš” í’ˆëª©: {top_txt}")
    return out


def _qty_delta_summary(cur_df: pd.DataFrame, prev_df: pd.DataFrame) -> str:
    cur_qty = _get_qty(cur_df)
    prev_qty = _get_qty(prev_df)
    diff = cur_qty - prev_qty
    sign = "+" if diff >= 0 else ""
    return f"ì¶œê³ ìˆ˜ëŸ‰ ì „ì›” ëŒ€ë¹„ {sign}{diff:,}ê°œ Â· {prev_qty:,} â†’ {cur_qty:,}"


def _top_bp_lines(cur_df: pd.DataFrame, top_n: int = 3) -> list[str]:
    if cur_df is None or cur_df.empty or COL_BP not in cur_df.columns or COL_QTY not in cur_df.columns:
        return []
    g = cur_df.groupby(COL_BP)[COL_QTY].sum().sort_values(ascending=False).head(top_n)
    if g.empty:
        return []
    return [f"- ì£¼ìš” BP: " + " / ".join([f"{bp}({int(round(q)):,})" for bp, q in g.items()])]


def _big_sku_lines(cur_df: pd.DataFrame, top_n: int = 4) -> list[str]:
    if cur_df is None or cur_df.empty or COL_QTY not in cur_df.columns:
        return []
    g = (
        cur_df.groupby([COL_ITEM_CODE, COL_ITEM_NAME])[COL_QTY]
        .sum().reset_index(name="qty")
        .sort_values("qty", ascending=False)
        .head(top_n)
    )
    out = []
    for i, r in g.iterrows():
        code = str(r[COL_ITEM_CODE]).strip()
        name = str(r[COL_ITEM_NAME]).strip()
        qty = int(round(float(r["qty"]), 0))
        bp_break = _bp_item_qty_breakdown(cur_df, code, name, top_n=3)
        out.append(f"- {i+1:02d}) {code} {name} : {qty:,}ê°œ" + (f" â†’ {bp_break}" if bp_break else ""))
    return out


def _jp_cn_excluded_increase_lines(cur_df: pd.DataFrame, prev_df: pd.DataFrame, top_n: int = 3) -> list[str]:
    if cur_df is None or cur_df.empty or COL_QTY not in cur_df.columns:
        return []
    if prev_df is None or prev_df.empty:
        return []

    cur = cur_df.groupby([COL_ITEM_CODE, COL_ITEM_NAME])[COL_QTY].sum().reset_index(name="cur")
    prev = prev_df.groupby([COL_ITEM_CODE, COL_ITEM_NAME])[COL_QTY].sum().reset_index(name="prev")

    m = cur.merge(prev, on=[COL_ITEM_CODE, COL_ITEM_NAME], how="left")
    m["prev"] = pd.to_numeric(m["prev"], errors="coerce").fillna(0)
    m["cur"] = pd.to_numeric(m["cur"], errors="coerce").fillna(0)

    m["is_jpcn"] = m[COL_ITEM_NAME].astype(str).apply(_is_jp_cn_line)
    m = m[~m["is_jpcn"]].copy()
    m = m[(m["prev"] > 0) & (m["cur"] > m["prev"])].copy()
    if m.empty:
        return []

    m["pct"] = (m["cur"] / m["prev"] - 1) * 100.0
    m = m.sort_values(["pct", "cur"], ascending=[False, False]).head(top_n)

    out = []
    for _, r in m.iterrows():
        code = str(r[COL_ITEM_CODE]).strip()
        name = str(r[COL_ITEM_NAME]).strip()
        prev_qty = int(round(float(r["prev"]), 0))
        cur_qty = int(round(float(r["cur"]), 0))
        pct = float(r["pct"])
        bp_break = _bp_item_qty_breakdown(cur_df, code, name, top_n=3)
        out.append(f"- {code} {name} : {prev_qty:,} â†’ {cur_qty:,} (ì•½ {pct:+.0f}%)" + (f" â†’ {bp_break}" if bp_break else ""))
    return out


def _next_month_top3_plan_lines(next_df: pd.DataFrame, section_name: str) -> list[str]:
    if next_df is None or next_df.empty or COL_QTY not in next_df.columns:
        return []

    bp_tot = next_df.groupby(COL_BP)[COL_QTY].sum().sort_values(ascending=False)
    if bp_tot.empty:
        return []

    total = float(next_df[COL_QTY].fillna(0).sum())

    def is_significant(qty: float) -> bool:
        return (qty >= 10000) or (total > 0 and (qty / total) >= 0.15)

    candidates = [(bp, float(q)) for bp, q in bp_tot.items() if is_significant(float(q))]
    if not candidates:
        return []

    candidates = candidates[:3]
    out = [f"- {section_name} ì°¨ì›” ëŒ€ëŸ‰ ì¶œê³ (Top{len(candidates)})"]
    for bp, _q in candidates:
        sub = next_df[next_df[COL_BP].astype(str).str.strip() == str(bp).strip()].copy()
        sku_top = (
            sub.groupby([COL_ITEM_CODE, COL_ITEM_NAME])[COL_QTY]
            .sum().reset_index(name="qty")
            .sort_values("qty", ascending=False)
            .head(1)
        )
        if sku_top.empty:
            continue
        r = sku_top.iloc[0]
        code = str(r[COL_ITEM_CODE]).strip()
        name = str(r[COL_ITEM_NAME]).strip()
        qty = int(round(float(r["qty"]), 0))
        out.append(f"  â€¢ {bp}: {code} {name} {qty:,}ê°œ")
    return out


def _build_monthly_report_text(base_df: pd.DataFrame, sel_month_label: str, prev_month_label: str | None, next_month_label: str | None) -> str:
    cur_df = base_df[base_df["_month_label"].astype(str) == str(sel_month_label)].copy()
    prev_df = base_df[base_df["_month_label"].astype(str) == str(prev_month_label)].copy() if prev_month_label else pd.DataFrame()
    next_df = base_df[base_df["_month_label"].astype(str) == str(next_month_label)].copy() if next_month_label else pd.DataFrame()

    def pick_section(df: pd.DataFrame, cust1_val: str) -> pd.DataFrame:
        if df is None or df.empty or COL_CUST1 not in df.columns:
            return pd.DataFrame()
        return df[df[COL_CUST1].astype(str).str.strip() == cust1_val].copy()

    cur_over = pick_section(cur_df, "í•´ì™¸B2B")
    prev_over = pick_section(prev_df, "í•´ì™¸B2B")
    next_over = pick_section(next_df, "í•´ì™¸B2B")

    cur_dom = pick_section(cur_df, "êµ­ë‚´B2B")
    prev_dom = pick_section(prev_df, "êµ­ë‚´B2B")
    next_dom = pick_section(next_df, "êµ­ë‚´B2B")

    cur_key = month_key_num_from_label(sel_month_label)

    lines = []
    lines.append(f"{sel_month_label} B2B í˜„í™© ê³µìœ  ë“œë¦½ë‹ˆë‹¤. (SAPí˜„í™©ì— ë”°ë¼ ìë£ŒëŠ” ì˜¤ì°¨ë²”ìœ„ê°€ ìˆì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤ğŸ™‚)")
    lines.append("")

    lines.append("*í•´ì™¸B2B*")
    all_over = base_df[base_df[COL_CUST1].astype(str).str.strip() == "í•´ì™¸B2B"].copy() if COL_CUST1 in base_df.columns else pd.DataFrame()
    lines.append(":white_check_mark: ì‹ ê·œ ì—…ì²´ ì²« ì¶œê³ ")
    lines.extend(_new_bp_first_ship_lines(all_over, cur_over, cur_key))
    lines.append("")

    lines.append(":white_check_mark: ì¶œê³ ëŸ‰ ì¦ê° ìš”ì•½")
    lines.append(f"- {_qty_delta_summary(cur_over, prev_over)}")
    lines.extend(_top_bp_lines(cur_over, top_n=3))
    lines.append("")

    lines.append(":white_check_mark: íŠ¹ì • SKU ëŒ€ëŸ‰ ì¶œê³  (Top)")
    big_over = _big_sku_lines(cur_over, top_n=4)
    lines.extend(big_over if big_over else ["- (í‘œì‹œí•  ë°ì´í„° ì—†ìŒ)"])
    lines.append("")

    lines.append(":white_check_mark: ì „ì›” ëŒ€ë¹„ ì£¼ìš” SKU ì¦ê°")
    mom_over = _sku_mom_change_lines(cur_over, prev_over, top_n=6)
    lines.extend(mom_over if mom_over else ["- ì „ì›” ë°ì´í„° ë¶€ì¡± ë˜ëŠ” prev=0ìœ¼ë¡œ ì‚°ì • ë¶ˆê°€ SKUë§Œ ì¡´ì¬"])
    lines.append("")

    lines.append(":white_check_mark: JP, CN ë¼ì¸ ì œì™¸ ì „ì›” ëŒ€ë¹„ ì¶œê³ ëŸ‰ ì¦ê°€ SKU")
    jpcn_over = _jp_cn_excluded_increase_lines(cur_over, prev_over, top_n=3)
    lines.extend(jpcn_over if jpcn_over else ["- í•´ë‹¹ ì—†ìŒ"])
    lines.append("")

    plan_over = _next_month_top3_plan_lines(next_over, "í•´ì™¸B2B")
    if plan_over:
        lines.append(":spiral_calendar_pad: ì°¨ì›” ê°„ëµ ì¼ì •(ëŒ€ëŸ‰ ì¶œê³  ì¤‘ì‹¬)")
        lines.extend(plan_over)
        lines.append("")

    lines.append("*êµ­ë‚´B2B*")
    all_dom = base_df[base_df[COL_CUST1].astype(str).str.strip() == "êµ­ë‚´B2B"].copy() if COL_CUST1 in base_df.columns else pd.DataFrame()
    lines.append(":white_check_mark: ì‹ ê·œ ì—…ì²´ ì²« ì¶œê³ ")
    lines.extend(_new_bp_first_ship_lines(all_dom, cur_dom, cur_key))
    lines.append("")

    lines.append(":white_check_mark: ì¶œê³ ëŸ‰ ì¦ê° ìš”ì•½")
    lines.append(f"- {_qty_delta_summary(cur_dom, prev_dom)}")
    lines.extend(_top_bp_lines(cur_dom, top_n=3))
    lines.append("")

    lines.append(":white_check_mark: íŠ¹ì • SKU ëŒ€ëŸ‰ ì¶œê³  (Top)")
    big_dom = _big_sku_lines(cur_dom, top_n=4)
    lines.extend(big_dom if big_dom else ["- (í‘œì‹œí•  ë°ì´í„° ì—†ìŒ)"])
    lines.append("")

    lines.append(":white_check_mark: ì „ì›” ëŒ€ë¹„ ì£¼ìš” SKU ì¦ê°")
    mom_dom = _sku_mom_change_lines(cur_dom, prev_dom, top_n=6)
    lines.extend(mom_dom if mom_dom else ["- ì „ì›” ë°ì´í„° ë¶€ì¡± ë˜ëŠ” prev=0ìœ¼ë¡œ ì‚°ì • ë¶ˆê°€ SKUë§Œ ì¡´ì¬"])
    lines.append("")

    plan_dom = _next_month_top3_plan_lines(next_dom, "êµ­ë‚´B2B")
    if plan_dom:
        lines.append(":spiral_calendar_pad: ì°¨ì›” ê°„ëµ ì¼ì •(ëŒ€ëŸ‰ ì¶œê³  ì¤‘ì‹¬)")
        lines.extend(plan_dom)
        lines.append("")

    return "\n".join(lines).strip()


# =========================
# Load + Prepare (RAW + cal_agg)
# =========================
@st.cache_data(ttl=1800, show_spinner=False)
def load_prepared_from_gsheet() -> tuple[pd.DataFrame, pd.DataFrame]:
    csv_url = f"https://docs.google.com/spreadsheets/d/{GSHEET_ID}/export?format=csv&gid={GSHEET_GID}"

    try:
        df = pd.read_csv(
            csv_url,
            header=HEADER_ROW_0BASED,
            usecols=USECOLS,
            dtype=DTYPE_MAP,
        )
    except Exception:
        df = pd.read_csv(csv_url, header=HEADER_ROW_0BASED)

    df.columns = df.columns.astype(str).str.strip()
    df = df.loc[:, ~df.columns.str.match(r"^Unnamed")]

    for c in [COL_SHIP, COL_DONE, COL_ORDER_DATE]:
        safe_dt(df, c)
    for c in [COL_QTY, COL_LT2, "ë¦¬ë“œíƒ€ì„1"]:
        safe_num(df, c)

    if (COL_LT2 not in df.columns) or (df[COL_LT2].dropna().empty):
        if all(c in df.columns for c in [COL_DONE, COL_ORDER_DATE]):
            df[COL_LT2] = (df[COL_DONE] - df[COL_ORDER_DATE]).dt.days
            safe_num(df, COL_LT2)

    normalize_text_cols(df, [COL_BP, COL_ITEM_CODE, COL_ITEM_NAME, COL_CUST1, COL_CUST2, COL_CLASS, COL_MAIN, COL_ORDER_NO])

    if COL_CLASS in df.columns:
        df = df[df[COL_CLASS].astype(str).str.strip().isin(KEEP_CLASSES)].copy()

    df["_is_rep"] = to_bool_true(df[COL_MAIN]) if COL_MAIN in df.columns else False

    ship_dt = pd.to_datetime(df[COL_SHIP], errors="coerce") if COL_SHIP in df.columns else pd.Series(pd.NaT, index=df.index)
    done_dt = pd.to_datetime(df[COL_DONE], errors="coerce") if COL_DONE in df.columns else pd.Series(pd.NaT, index=df.index)
    base_dt = ship_dt.fillna(done_dt)

    wk = ((base_dt.dt.day - 1) // 7 + 1).astype("Int64")
    mask = base_dt.notna() & wk.notna()

    df["_week_label"] = pd.NA
    df.loc[mask, "_week_label"] = (
        base_dt.dt.year.astype(str) + "ë…„ " +
        base_dt.dt.month.astype(str) + "ì›” " +
        wk.astype(str) + "ì£¼ì°¨"
    )

    df["_week_key_num"] = pd.NA
    df.loc[mask, "_week_key_num"] = (
        base_dt.dt.year.astype("Int64") * 10000 +
        base_dt.dt.month.astype("Int64") * 100 +
        wk
    ).astype("Int64")

    if (COL_YEAR in df.columns) and (COL_MONTH in df.columns):
        y = pd.to_numeric(df[COL_YEAR], errors="coerce").astype("Int64")
        m = pd.to_numeric(df[COL_MONTH], errors="coerce").astype("Int64")
        mmask = y.notna() & m.notna()

        df["_month_label"] = pd.NA
        df.loc[mmask, "_month_label"] = y.astype(str) + "ë…„ " + m.astype(str) + "ì›”"

        df["_month_key_num"] = pd.NA
        df.loc[mmask, "_month_key_num"] = (y * 100 + m).astype("Int64")
    else:
        df["_month_label"] = pd.NA
        df["_month_key_num"] = pd.NA

    df["_ship_date"] = ship_dt.dt.date
    df["_ship_ym"] = ship_dt.dt.strftime("%Y-%m")

    cal_src = df.dropna(subset=["_ship_date"]).copy()
    if cal_src.empty:
        cal_agg = pd.DataFrame(columns=["_ship_ym", "_ship_date", COL_BP, COL_CUST1, COL_CUST2, "qty_sum"])
    else:
        cal_agg = (
            cal_src.groupby(["_ship_ym", "_ship_date", COL_BP, COL_CUST1, COL_CUST2], dropna=False)[COL_QTY]
            .sum(min_count=1)
            .reset_index()
            .rename(columns={COL_QTY: "qty_sum"})
        )
        cal_agg["qty_sum"] = pd.to_numeric(cal_agg["qty_sum"], errors="coerce").fillna(0).round(0).astype(int)

    return df, cal_agg


# =========================
# KPI
# =========================
def compute_kpis(df_view: pd.DataFrame):
    total_qty = float(df_view[COL_QTY].fillna(0).sum()) if (df_view is not None and COL_QTY in df_view.columns) else 0.0

    # âœ… ì¶œê³ ê±´ìˆ˜ = ì£¼ë¬¸ë²ˆí˜¸ distinct
    total_cnt = _clean_nunique(df_view[COL_ORDER_NO]) if (df_view is not None and not df_view.empty and COL_ORDER_NO in df_view.columns) else 0

    latest_done = df_view[COL_DONE].max() if (df_view is not None and COL_DONE in df_view.columns) else pd.NaT

    avg_lt2_overseas = None
    if df_view is not None and all(c in df_view.columns for c in [COL_CUST1, COL_LT2]):
        overseas = df_view[df_view[COL_CUST1].astype(str).str.strip() == LT_ONLY_CUST1]
        if not overseas.empty and not overseas[COL_LT2].dropna().empty:
            avg_lt2_overseas = float(overseas[COL_LT2].dropna().mean())

    top_bp_qty_name = "-"
    top_bp_qty_val = "-"
    if df_view is not None and (not df_view.empty) and all(c in df_view.columns for c in [COL_BP, COL_QTY]):
        g = df_view.groupby(COL_BP, dropna=False)[COL_QTY].sum().sort_values(ascending=False)
        if not g.empty:
            top_bp_qty_name = str(g.index[0])
            top_bp_qty_val = f"{float(g.iloc[0]):,.0f}"

    # âœ… ì¶œê³ ê±´ìˆ˜ TOP BP = ì£¼ë¬¸ë²ˆí˜¸ distinct by BP
    top_bp_cnt_name = "-"
    top_bp_cnt_val = "-"
    if df_view is not None and (not df_view.empty) and all(c in df_view.columns for c in [COL_BP, COL_ORDER_NO]):
        tmp = df_view[[COL_BP, COL_ORDER_NO]].copy()
        tmp["_ord"] = tmp[COL_ORDER_NO].astype(str).str.strip().replace({"": pd.NA, "nan": pd.NA, "None": pd.NA})
        tmp = tmp.dropna(subset=["_ord"])
        if not tmp.empty:
            g2 = tmp.groupby(COL_BP)["_ord"].nunique().sort_values(ascending=False)
            if not g2.empty:
                top_bp_cnt_name = str(g2.index[0])
                top_bp_cnt_val = f"{int(g2.iloc[0]):,}"

    return {
        "total_qty": total_qty,
        "total_cnt": int(total_cnt),
        "latest_done": latest_done,
        "avg_lt2_overseas": avg_lt2_overseas,
        "top_bp_qty_name": top_bp_qty_name,
        "top_bp_qty_val": top_bp_qty_val,
        "top_bp_cnt_name": top_bp_cnt_name,
        "top_bp_cnt_val": top_bp_cnt_val,
    }


# =========================
# Calendar (same-tab routing)
# =========================
def init_calendar_state():
    st.session_state.setdefault("cal_view", "calendar")  # calendar | detail
    st.session_state.setdefault("cal_ym", "")
    st.session_state.setdefault("cal_selected_date", None)
    st.session_state.setdefault("cal_selected_bp", "")
    st.session_state.setdefault("cal_expanded", set())


def ym_to_year_month(ym: str) -> tuple[int, int]:
    try:
        y, m = ym.split("-")
        return int(y), int(m)
    except Exception:
        today = date.today()
        return today.year, today.month


def add_months(ym: str, delta: int) -> str:
    y, m = ym_to_year_month(ym)
    m2 = m + delta
    while m2 <= 0:
        y -= 1
        m2 += 12
    while m2 >= 13:
        y += 1
        m2 -= 12
    return f"{y:04d}-{m2:02d}"


def build_day_map_from_cal_agg(cal_agg: pd.DataFrame, ym: str) -> dict[date, list[dict]]:
    if cal_agg is None or cal_agg.empty:
        return {}

    sub = cal_agg[cal_agg["_ship_ym"].astype(str) == str(ym)].copy()
    if sub.empty:
        return {}

    total = (
        sub.groupby(["_ship_date", COL_BP], dropna=False)["qty_sum"]
        .sum()
        .reset_index()
        .rename(columns={"qty_sum": "qty_total"})
    )

    pick = (
        sub.sort_values("qty_sum", ascending=False)
        .drop_duplicates(subset=["_ship_date", COL_BP], keep="first")[["_ship_date", COL_BP, COL_CUST1]]
        .copy()
    )
    pick[COL_CUST1] = pick[COL_CUST1].fillna("").astype(str).str.strip()

    merged = total.merge(pick, on=["_ship_date", COL_BP], how="left")
    merged["qty_total"] = pd.to_numeric(merged["qty_total"], errors="coerce").fillna(0).astype(int)
    merged[COL_CUST1] = merged[COL_CUST1].fillna("").astype(str)

    out: dict[date, list[dict]] = {}
    for d, grp in merged.groupby("_ship_date"):
        grp = grp.sort_values("qty_total", ascending=False, na_position="last")
        out[d] = [
            {"bp": str(r[COL_BP]).strip(), "qty": int(r["qty_total"]), "cust1": str(r[COL_CUST1]).strip()}
            for _, r in grp.iterrows()
        ]
    return out


def render_month_calendar(cal_agg_filtered: pd.DataFrame, ym: str):
    y, m = ym_to_year_month(ym)
    day_map = build_day_map_from_cal_agg(cal_agg_filtered, ym)

    prev_ym = add_months(ym, -1)
    next_ym = add_months(ym, +1)

    c1, c2, c3 = st.columns([1.2, 2.2, 1.2], vertical_alignment="center")
    with c1:
        if st.button("â—€ ì´ì „ë‹¬", key=f"cal_prev_{ym}", use_container_width=True):
            st.session_state["cal_ym"] = prev_ym
            st.session_state["cal_view"] = "calendar"
            safe_rerun()
    with c2:
        st.markdown(f"### {y}ë…„ {m}ì›” ì¶œê³  ìº˜ë¦°ë”")
        st.markdown('<div class="cal-note">â€» BP ë²„íŠ¼ í´ë¦­ ì‹œ ìƒì„¸ í™”ë©´ìœ¼ë¡œ ì´ë™í•©ë‹ˆë‹¤. (ê°™ì€ íƒ­)</div>', unsafe_allow_html=True)
    with c3:
        if st.button("ë‹¤ìŒë‹¬ â–¶", key=f"cal_next_{ym}", use_container_width=True):
            st.session_state["cal_ym"] = next_ym
            st.session_state["cal_view"] = "calendar"
            safe_rerun()

    weekdays = ["ì¼", "ì›”", "í™”", "ìˆ˜", "ëª©", "ê¸ˆ", "í† "]
    header_cols = st.columns(7)
    for i, w in enumerate(weekdays):
        with header_cols[i]:
            st.markdown(f"**{w}**")

    cal = pycal.Calendar(firstweekday=6)
    weeks = cal.monthdayscalendar(y, m)

    expanded: set[date] = st.session_state.get("cal_expanded", set())

    for wk in weeks:
        cols = st.columns(7, gap="small")
        for i, day_num in enumerate(wk):
            with cols[i]:
                if day_num == 0:
                    st.container(border=True).markdown("&nbsp;")
                    continue

                d = date(y, m, day_num)
                events = day_map.get(d, [])
                is_expanded = d in expanded

                show_n = len(events) if is_expanded else min(3, len(events))
                hidden = max(0, len(events) - show_n)

                with st.container(border=True):
                    st.markdown(f"**{day_num}**")

                    for idx in range(show_n):
                        e = events[idx]
                        bp = e.get("bp", "")
                        qsum = int(e.get("qty", 0))
                        cust1 = (e.get("cust1", "") or "").strip()

                        tag = "ğŸŸ¦" if cust1 == "í•´ì™¸B2B" else "ğŸŸ©" if cust1 == "êµ­ë‚´B2B" else "â¬œ"
                        label = f"{tag} {bp} ({qsum:,})"
                        k = "cal_bp_" + make_btn_key(ym, d.isoformat(), bp, idx)

                        if st.button(label, key=k, use_container_width=True):
                            st.session_state["cal_selected_date"] = d
                            st.session_state["cal_selected_bp"] = bp
                            st.session_state["cal_view"] = "detail"
                            safe_rerun()

                    if hidden > 0 and (not is_expanded):
                        if st.button(f"+{hidden}ê±´ ë” ë³´ê¸°", key="cal_more_" + make_btn_key(ym, d.isoformat()), use_container_width=True):
                            expanded.add(d)
                            st.session_state["cal_expanded"] = expanded
                            safe_rerun()

                    if is_expanded and len(events) > 3:
                        if st.button("ì ‘ê¸°", key="cal_less_" + make_btn_key(ym, d.isoformat()), use_container_width=True):
                            expanded.discard(d)
                            st.session_state["cal_expanded"] = expanded
                            safe_rerun()


def format_done_range(done_min, done_max) -> str:
    """
    âœ… ìƒì„¸ í™”ë©´ ì‘ì—…ì™„ë£Œ í‘œê¸° ê°œì„ :
    - ë‘˜ ë‹¤ ì—†ìœ¼ë©´ "-"
    - í•˜ë‚˜ë§Œ ìˆìœ¼ë©´ ê·¸ ë‚ ì§œ
    - ë‘˜ ë‹¤ ìˆê³  ê°™ì€ ë‚ ì´ë©´ ë‹¨ì¼ ë‚ ì§œ
    - ë‹¤ë¥´ë©´ "min ~ max"
    """
    if pd.isna(done_min) and pd.isna(done_max):
        return "-"

    dmin = pd.to_datetime(done_min, errors="coerce")
    dmax = pd.to_datetime(done_max, errors="coerce")

    if pd.isna(dmin) and pd.isna(dmax):
        return "-"

    if pd.isna(dmin):
        return fmt_date(dmax)
    if pd.isna(dmax):
        return fmt_date(dmin)

    if dmin.date() == dmax.date():
        return fmt_date(dmin)

    return f"{fmt_date(dmin)} ~ {fmt_date(dmax)}"


# =========================
# Main
# =========================
st.title("ğŸ“¦ B2B ì¶œê³  ëŒ€ì‹œë³´ë“œ")
st.caption("Google Sheet RAW ê¸°ë°˜ | ì œí’ˆë¶„ë¥˜ B0/B1 ê³ ì • | í•„í„°(ê±°ë˜ì²˜êµ¬ë¶„1/2/ì›”/BP) ë°˜ì˜")

if st.button("ğŸ”„ ë°ì´í„° ìƒˆë¡œê³ ì¹¨"):
    st.cache_data.clear()
    for k in list(st.session_state.keys()):
        if k.startswith(("cal_", "f_", "sku_", "wk_", "m_")) or k in ("nav_menu", "monthly_report_text", "_prev_nav_menu"):
            del st.session_state[k]
    safe_rerun()

with st.spinner("Google Sheet RAW ë¡œë”©/ì „ì²˜ë¦¬ ì¤‘..."):
    try:
        raw, cal_agg = load_prepared_from_gsheet()
    except Exception as e:
        st.error("Google Sheetì—ì„œ RAW ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì˜¤ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
        st.code(str(e))
        st.stop()

# =========================
# Sidebar filters
# =========================
st.sidebar.header("í•„í„°")
st.sidebar.caption("ì œí’ˆë¶„ë¥˜ ê³ ì •: B0, B1")

st.session_state.setdefault("f_cust1", "ì „ì²´")
st.session_state.setdefault("f_cust2", "ì „ì²´")
st.session_state.setdefault("f_month", "ì „ì²´")
st.session_state.setdefault("f_bp", "ì „ì²´")

cust1_list = uniq_sorted(raw, COL_CUST1)

with st.sidebar.form("filters_form", border=True):
    sel_cust1 = safe_selectbox("ê±°ë˜ì²˜êµ¬ë¶„1", ["ì „ì²´"] + cust1_list, key="f_cust1")

    pool1 = raw.copy()
    if sel_cust1 != "ì „ì²´" and COL_CUST1 in pool1.columns:
        pool1 = pool1[pool1[COL_CUST1].astype(str).str.strip() == sel_cust1]

    cust2_list = uniq_sorted(pool1, COL_CUST2)
    sel_cust2 = safe_selectbox("ê±°ë˜ì²˜êµ¬ë¶„2", ["ì „ì²´"] + cust2_list, key="f_cust2")

    pool2 = pool1.copy()
    if sel_cust2 != "ì „ì²´" and COL_CUST2 in pool2.columns:
        pool2 = pool2[pool2[COL_CUST2].astype(str).str.strip() == sel_cust2]

    month_labels = []
    if "_month_label" in pool2.columns and "_month_key_num" in pool2.columns:
        tmp = pool2[["_month_label", "_month_key_num"]].dropna().drop_duplicates("_month_label").copy()
        tmp["_month_key_num"] = pd.to_numeric(tmp["_month_key_num"], errors="coerce")
        tmp = tmp.dropna(subset=["_month_key_num"]).sort_values("_month_key_num")
        month_labels = tmp["_month_label"].astype(str).tolist()

    sel_month_label = safe_selectbox("ì›”", ["ì „ì²´"] + month_labels, key="f_month")

    pool3 = pool2.copy()
    if sel_month_label != "ì „ì²´":
        pool3 = pool3[pool3["_month_label"].astype(str) == str(sel_month_label)]

    bp_list = uniq_sorted(pool3, COL_BP)
    sel_bp = safe_selectbox("BPëª…", ["ì „ì²´"] + bp_list, key="f_bp")

    st.form_submit_button("âœ… í•„í„° ì ìš©", use_container_width=True)

# âœ… view êµ¬ì„±
pool1 = raw.copy()
if st.session_state["f_cust1"] != "ì „ì²´":
    pool1 = pool1[pool1[COL_CUST1].astype(str).str.strip() == st.session_state["f_cust1"]]

pool2 = pool1.copy()
if st.session_state["f_cust2"] != "ì „ì²´":
    pool2 = pool2[pool2[COL_CUST2].astype(str).str.strip() == st.session_state["f_cust2"]]

pool3 = pool2.copy()
if st.session_state["f_month"] != "ì „ì²´":
    pool3 = pool3[pool3["_month_label"].astype(str) == str(st.session_state["f_month"])]

df_view = pool3.copy()
if st.session_state["f_bp"] != "ì „ì²´":
    df_view = df_view[df_view[COL_BP].astype(str).str.strip() == st.session_state["f_bp"]]

# (ëŒ€í‘œí–‰ì€ ìœ ì§€í•˜ë˜, ì¶œê³ ê±´ìˆ˜ ì§‘ê³„ì—ëŠ” ì‚¬ìš©í•˜ì§€ ì•ŠìŒ)
df_rep = df_view[df_view["_is_rep"]].copy() if "_is_rep" in df_view.columns else pd.DataFrame()

# =========================
# KPI cards
# =========================
k = compute_kpis(df_view)

st.markdown(
    f"""
    <div class="kpi-wrap">
      <div class="kpi-card">
        <div class="kpi-title">ì´ ì¶œê³ ìˆ˜ëŸ‰(í•©)</div>
        <div class="kpi-value">{k['total_qty']:,.0f}</div>
      </div>
      <div class="kpi-card">
        <div class="kpi-title">ì´ ì¶œê³ ê±´ìˆ˜(í•©) <span style="color:#6b7280;font-size:0.85rem;">(ì£¼ë¬¸ë²ˆí˜¸ distinct)</span></div>
        <div class="kpi-value">{k['total_cnt']:,}</div>
      </div>
      <div class="kpi-card">
        <div class="kpi-title">ìµœê·¼ ì‘ì—…ì™„ë£Œì¼</div>
        <div class="kpi-value">{fmt_date(k['latest_done'])}</div>
      </div>
      <div class="kpi-card">
        <div class="kpi-title">ë¦¬ë“œíƒ€ì„ í‰ê·  (í•´ì™¸B2B)</div>
        <div class="kpi-value">{(f"{k['avg_lt2_overseas']:.1f}ì¼" if k['avg_lt2_overseas'] is not None else "-")}</div>
      </div>
      <div class="kpi-card">
        <div class="kpi-title">ì¶œê³ ìˆ˜ëŸ‰ TOP BP</div>
        <div class="kpi-big">{html.escape(k['top_bp_qty_val'])}</div>
        <div class="kpi-muted">{html.escape(k['top_bp_qty_name'])}</div>
      </div>
      <div class="kpi-card">
        <div class="kpi-title">ì¶œê³ ê±´ìˆ˜ TOP BP <span style="color:#6b7280;font-size:0.85rem;">(ì£¼ë¬¸ë²ˆí˜¸ distinct)</span></div>
        <div class="kpi-big">{html.escape(k['top_bp_cnt_val'])}</div>
        <div class="kpi-muted">{html.escape(k['top_bp_cnt_name'])}</div>
      </div>
    </div>
    """,
    unsafe_allow_html=True
)
st.caption("â€» ë¦¬ë“œíƒ€ì„ ì§€í‘œëŠ” í•´ì™¸B2B(ê±°ë˜ì²˜êµ¬ë¶„1=í•´ì™¸B2B)ë§Œì„ ëŒ€ìƒìœ¼ë¡œ ê³„ì‚°ë©ë‹ˆë‹¤.")
st.divider()

# =========================
# Navigation
# =========================
nav = st.radio(
    "ë©”ë‰´",
    ["â‘  ì¶œê³  ìº˜ë¦°ë”", "â‘¡ SKUë³„ ì¡°íšŒ", "â‘¢ ì£¼ì°¨ìš”ì•½", "â‘£ ì›”ê°„ìš”ì•½", "â‘¤ êµ­ê°€ë³„ ì¡°íšŒ", "â‘¥ BPëª…ë³„ ì¡°íšŒ"],
    horizontal=True,
    key="nav_menu"
)

# âœ… (ìš”ì²­ì‚¬í•­ 1) ë©”ë‰´ ì´ë™ ì‹œ â‘  ì¶œê³  ìº˜ë¦°ë”ëŠ” í•­ìƒ ìº˜ë¦°ë” ë©”ì¸ìœ¼ë¡œ ì§„ì…
prev_nav = st.session_state.get("_prev_nav_menu", None)
if prev_nav != nav:
    if nav == "â‘  ì¶œê³  ìº˜ë¦°ë”":
        st.session_state["cal_view"] = "calendar"
        st.session_state["cal_selected_date"] = None
        st.session_state["cal_selected_bp"] = ""
        st.session_state["cal_expanded"] = set()

    if prev_nav == "â‘  ì¶œê³  ìº˜ë¦°ë”" and nav != "â‘  ì¶œê³  ìº˜ë¦°ë”":
        st.session_state["cal_view"] = "calendar"
        st.session_state["cal_selected_date"] = None
        st.session_state["cal_selected_bp"] = ""
        st.session_state["cal_expanded"] = set()

    st.session_state["_prev_nav_menu"] = nav

# =========================
# â‘  ì¶œê³  ìº˜ë¦°ë”
# =========================
if nav == "â‘  ì¶œê³  ìº˜ë¦°ë”":
    init_calendar_state()

    cal_pool = cal_agg.copy()
    if st.session_state["f_cust1"] != "ì „ì²´":
        cal_pool = cal_pool[cal_pool[COL_CUST1].astype(str).str.strip() == st.session_state["f_cust1"]]
    if st.session_state["f_cust2"] != "ì „ì²´":
        cal_pool = cal_pool[cal_pool[COL_CUST2].astype(str).str.strip() == st.session_state["f_cust2"]]
    if st.session_state["f_bp"] != "ì „ì²´":
        cal_pool = cal_pool[cal_pool[COL_BP].astype(str).str.strip() == st.session_state["f_bp"]]

    if st.session_state["cal_ym"].strip() == "":
        if cal_pool is not None and (not cal_pool.empty) and "_ship_ym" in cal_pool.columns:
            st.session_state["cal_ym"] = cal_pool["_ship_ym"].dropna().astype(str).max()
        else:
            st.session_state["cal_ym"] = date.today().strftime("%Y-%m")

    ym = st.session_state["cal_ym"]

    if st.session_state["cal_view"] == "detail":
        ship_date = st.session_state.get("cal_selected_date")
        bp_s = st.session_state.get("cal_selected_bp", "")

        st.subheader("ì¶œê³  ìƒì„¸ ë‚´ì—­")
        if st.button("â† ìº˜ë¦°ë”ë¡œ ëŒì•„ê°€ê¸°", key="btn_cal_back"):
            st.session_state["cal_view"] = "calendar"
            safe_rerun()

        if ship_date is None or not str(bp_s).strip():
            st.warning("ìƒì„¸ ì¡°íšŒ ëŒ€ìƒì´ ì—†ìŠµë‹ˆë‹¤. ìº˜ë¦°ë”ì—ì„œ BPë¥¼ í´ë¦­í•´ ì£¼ì„¸ìš”.")
            st.stop()

        d = pool2.copy()
        if not need_cols(d, ["_ship_date", COL_BP, COL_QTY, COL_ITEM_CODE, COL_ITEM_NAME], "ì¶œê³  ìƒì„¸"):
            st.stop()

        sub = d[(d["_ship_date"] == ship_date) & (d[COL_BP].astype(str).str.strip() == str(bp_s).strip())].copy()
        if sub.empty:
            st.info("í•´ë‹¹ ì¡°ê±´ì˜ ì¶œê³  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. (ì¢Œì¸¡ í•„í„° ì¡°ê±´ë„ í•¨ê»˜ í™•ì¸)")
            st.stop()

        total_qty2 = int(round(sub[COL_QTY].fillna(0).sum(), 0))
        done_max = sub[COL_DONE].max() if COL_DONE in sub.columns else pd.NaT
        done_min = sub[COL_DONE].min() if COL_DONE in sub.columns else pd.NaT

        st.markdown(f"- **ì¶œê³ ì¼ì:** {ship_date.isoformat()}")
        st.markdown(f"- **BPëª…:** {html.escape(str(bp_s))}")
        st.markdown(f"- **ìš”ì²­ìˆ˜ëŸ‰ í•©:** {total_qty2:,}")
        if COL_DONE in sub.columns:
            # âœ… (ìš”ì²­ì‚¬í•­ 2) ë‹¨ì¼ ë‚ ì§œë©´ ë‹¨ì¼ë¡œ í‘œê¸°
            st.markdown(f"- **ì‘ì—…ì™„ë£Œ:** {format_done_range(done_min, done_max)}")
        st.divider()

        g = (
            sub.groupby([COL_ITEM_CODE, COL_ITEM_NAME], dropna=False)
            .agg(ìš”ì²­ìˆ˜ëŸ‰=(COL_QTY, "sum"), ì‘ì—…ì™„ë£Œ=(COL_DONE, "max") if COL_DONE in sub.columns else (COL_QTY, "size"))
            .reset_index()
        )
        g["ì¶œê³ ì¼ì"] = ship_date.isoformat()
        g["ì‘ì—…ì™„ë£Œ"] = g["ì‘ì—…ì™„ë£Œ"].apply(fmt_date) if COL_DONE in sub.columns else "-"
        g["ìš”ì²­ìˆ˜ëŸ‰"] = pd.to_numeric(g["ìš”ì²­ìˆ˜ëŸ‰"], errors="coerce").fillna(0).round(0).astype(int)
        g = g.sort_values("ìš”ì²­ìˆ˜ëŸ‰", ascending=False, na_position="last")

        render_pretty_table(
            g[["ì¶œê³ ì¼ì", "ì‘ì—…ì™„ë£Œ", COL_ITEM_CODE, COL_ITEM_NAME, "ìš”ì²­ìˆ˜ëŸ‰"]],
            height=520,
            wrap_cols=[COL_ITEM_NAME],
            number_cols=["ìš”ì²­ìˆ˜ëŸ‰"],
        )
    else:
        st.subheader("ì¶œê³  ìº˜ë¦°ë” (ì›”ë³„)")
        render_month_calendar(cal_pool, ym)

# =========================
# â‘¡ SKUë³„ ì¡°íšŒ
# =========================
elif nav == "â‘¡ SKUë³„ ì¡°íšŒ":
    st.subheader("SKUë³„ ì¡°íšŒ")

    ignore_month = st.checkbox("ì›” í•„í„° ë¬´ì‹œ(ì „ì²´ê¸°ê°„ ê¸°ì¤€ìœ¼ë¡œ SKU ì¡°íšŒ/ì½”ë©˜íŠ¸)", value=True, key="sku_ignore_month_filter")
    sku_scope = pool2.copy() if ignore_month else df_view.copy()

    if not need_cols(sku_scope, [COL_ITEM_CODE, COL_ITEM_NAME, COL_QTY, COL_SHIP, COL_BP], "SKUë³„ ì¡°íšŒ"):
        st.stop()

    st.markdown("### í’ˆëª©ì½”ë“œ ê²€ìƒ‰")
    show_all_history = st.checkbox("ì „ì²´ íˆìŠ¤í† ë¦¬ ë³´ê¸°", value=True, key="sku_show_all_history")

    base = sku_scope.copy()
    base[COL_ITEM_CODE] = base[COL_ITEM_CODE].astype(str).str.strip()
    base[COL_ITEM_NAME] = base[COL_ITEM_NAME].astype(str).str.strip()

    q = st.text_input("í’ˆëª©ì½”ë“œ ê²€ìƒ‰ (ë¶€ë¶„ê²€ìƒ‰ ê°€ëŠ¥)", value="", placeholder="ì˜ˆ: B0GF057A1", key="sku_query")

    if q.strip():
        q_norm = q.strip().upper()
        candidates = (
            base[base[COL_ITEM_CODE].str.upper().str.contains(re.escape(q_norm), na=False)][[COL_ITEM_CODE, COL_ITEM_NAME]]
            .dropna(subset=[COL_ITEM_CODE])
            .drop_duplicates(subset=[COL_ITEM_CODE])
            .sort_values(COL_ITEM_CODE)
            .reset_index(drop=True)
        )

        if candidates.empty:
            st.warning("í•´ë‹¹ í’ˆëª©ì½”ë“œê°€ í˜„ì¬ í•„í„° ë²”ìœ„ì—ì„œ ì¡°íšŒë˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
        else:
            if len(candidates) > 1:
                cand_map = dict(zip(candidates[COL_ITEM_CODE], candidates[COL_ITEM_NAME]))
                sel_code = st.selectbox(
                    "ê²€ìƒ‰ ê²°ê³¼ì—ì„œ ì„ íƒ",
                    candidates[COL_ITEM_CODE].tolist(),
                    key="sku_candidate_pick",
                    format_func=lambda x: f"{x} / {cand_map.get(x, '')}".strip()
                )
            else:
                sel_code = candidates.iloc[0][COL_ITEM_CODE]

            dsku = base[base[COL_ITEM_CODE] == sel_code].copy()

            item_name = "-"
            nn = dsku[COL_ITEM_NAME].dropna()
            if not nn.empty:
                item_name = str(nn.iloc[0]).strip()

            st.markdown(f"- **í’ˆëª©ì½”ë“œ:** {html.escape(sel_code)}")
            st.markdown(f"- **í’ˆëª©ëª…:** {html.escape(item_name)}")

            if not show_all_history:
                today_ts = pd.Timestamp(date.today())
                ship_dt = pd.to_datetime(dsku[COL_SHIP], errors="coerce")
                dsku = dsku[(ship_dt.isna()) | (ship_dt >= today_ts)].copy()

            dsku["ì¶œê³ ì˜ˆì •ì¼"] = dsku[COL_SHIP].apply(lambda x: "ë¯¸ì •" if pd.isna(x) else fmt_date(x))

            st.markdown("### íŠ¹ì´ / ì´ìŠˆ í¬ì¸íŠ¸ (SKU ìë™ ì½”ë©˜íŠ¸)")

            sku_month = (
                dsku.dropna(subset=["_month_label"])
                .assign(_month_key=lambda x: x["_month_label"].astype(str).apply(parse_month_label_key))
                .groupby(["_month_label", "_month_key"], dropna=False)[COL_QTY]
                .sum(min_count=1)
                .reset_index()
                .rename(columns={COL_QTY: "qty"})
                .sort_values("_month_key")
            )

            mom_items = sku_comment_mom(sku_month)
            trend_items = sku_comment_trend(sku_month)
            bp_spike_items = sku_comment_bp_spike(dsku)

            if mom_items:
                render_numbered_block("ì›”ê°„ ì¦ê° (ìµœê·¼ 2ê°œì›”)", mom_items)
            if trend_items:
                render_numbered_block("ì¶”ì´ ì½”ë©˜íŠ¸ (ìµœê·¼ 3ê°œì›”, ë£° ê¸°ë°˜)", trend_items)
            if bp_spike_items:
                render_numbered_block("BPë³„ í‰ì†Œ ëŒ€ë¹„ ê¸‰ì¦ ì‚¬ë¡€(ì›” ë‹¨ìœ„)", bp_spike_items)

            st.divider()

            out = (
                dsku.groupby(["ì¶œê³ ì˜ˆì •ì¼", COL_BP], dropna=False)[COL_QTY]
                .sum(min_count=1)
                .reset_index()
                .rename(columns={COL_BP: "BPëª…", COL_QTY: "ìš”ì²­ìˆ˜ëŸ‰"})
            )
            out["ìš”ì²­ìˆ˜ëŸ‰"] = pd.to_numeric(out["ìš”ì²­ìˆ˜ëŸ‰"], errors="coerce").fillna(0).round(0).astype(int)

            render_pretty_table(out[["ì¶œê³ ì˜ˆì •ì¼", "BPëª…", "ìš”ì²­ìˆ˜ëŸ‰"]], height=520, wrap_cols=["BPëª…"], number_cols=["ìš”ì²­ìˆ˜ëŸ‰"])
    else:
        st.info("ìƒë‹¨ì— í’ˆëª©ì½”ë“œë¥¼ ì…ë ¥í•˜ë©´, í•´ë‹¹ SKUì˜ ì½”ë©˜íŠ¸ ë° íˆìŠ¤í† ë¦¬ê°€ í‘œì‹œë©ë‹ˆë‹¤.")

    st.divider()
    period_title = "ëˆ„ì  SKU Top10 (ìš”ì²­ìˆ˜ëŸ‰ ê¸°ì¤€)" if st.session_state["f_month"] == "ì „ì²´" else f"{st.session_state['f_month']} SKU Top10 (ìš”ì²­ìˆ˜ëŸ‰ ê¸°ì¤€)"
    st.markdown(f"### {period_title}")

    top10_sku = build_item_topn_with_bp(df_view.copy(), 10)
    render_pretty_table(top10_sku, height=520, wrap_cols=[COL_ITEM_NAME, "BPëª…(ìš”ì²­ìˆ˜ëŸ‰)"], number_cols=["ìš”ì²­ìˆ˜ëŸ‰_í•©"])

# =========================
# â‘¢ ì£¼ì°¨ìš”ì•½
# =========================
elif nav == "â‘¢ ì£¼ì°¨ìš”ì•½":
    st.subheader("ì£¼ì°¨ìš”ì•½")
    d = df_view.copy()
    if d.empty:
        st.info("í‘œì‹œí•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        st.stop()

    if "_week_label" not in d.columns or "_week_key_num" not in d.columns:
        st.warning("ì£¼ì°¨ ë¼ë²¨/í‚¤ ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤.")
        st.stop()

    tmp = d[["_week_label", "_week_key_num"]].dropna().drop_duplicates("_week_label").copy()
    tmp["_week_key_num"] = pd.to_numeric(tmp["_week_key_num"], errors="coerce")
    tmp = tmp.dropna(subset=["_week_key_num"]).sort_values("_week_key_num")
    week_list = tmp["_week_label"].astype(str).tolist()

    if not week_list:
        st.info("ì£¼ì°¨ ëª©ë¡ì´ ì—†ìŠµë‹ˆë‹¤.")
        st.stop()

    sel_week = st.selectbox("ì£¼ì°¨ ì„ íƒ", week_list, index=len(week_list) - 1, key="wk_sel_week")
    wdf = d[d["_week_label"].astype(str) == str(sel_week)].copy()

    cur_key_num = None
    try:
        cur_key_num = int(pd.to_numeric(wdf["_week_key_num"], errors="coerce").dropna().iloc[0])
    except Exception:
        cur_key_num = None

    cur_idx = week_list.index(sel_week) if sel_week in week_list else None
    prev_wdf = pd.DataFrame()
    prev_week = None
    if cur_idx is not None and cur_idx > 0:
        prev_week = week_list[cur_idx - 1]
        prev_wdf = d[d["_week_label"].astype(str) == str(prev_week)].copy()

    comment_items = []
    comment_items += new_bp_comment(all_df=d, cur_df=wdf, key_col_num="_week_key_num", cur_key_num=cur_key_num)
    comment_items += period_kpi_delta_comment(cur_df=wdf, prev_df=prev_wdf)
    comment_items += category_top_comment(wdf, top_n=2)
    comment_items += concentration_comment(wdf)
    comment_items += undated_ship_risk_comment(wdf)
    render_numbered_block("ì£¼ê°„ íŠ¹ì´ì‚¬í•­ (ìë™ ì½”ë©˜íŠ¸)", comment_items)
    if prev_week:
        st.caption(f"â€» ë¹„êµ ê¸°ì¤€: ì„ íƒ ì£¼ì°¨({sel_week}) vs ì „ì£¼({prev_week})")
    st.divider()

    st.subheader("ì£¼ì°¨ ì„ íƒ â†’ Top 10 (BP/í’ˆëª©ì½”ë“œ/í’ˆëª©ëª…/ìš”ì²­ìˆ˜ëŸ‰)")
    top10 = (
        wdf.groupby([COL_BP, COL_ITEM_CODE, COL_ITEM_NAME], dropna=False)[COL_QTY]
        .sum(min_count=1).reset_index()
        .sort_values(COL_QTY, ascending=False)
        .head(10)
        .copy()
    )
    top10.insert(0, "ìˆœìœ„", range(1, len(top10) + 1))
    top10[COL_QTY] = pd.to_numeric(top10[COL_QTY], errors="coerce").fillna(0).round(0).astype(int)
    render_pretty_table(top10, height=520, wrap_cols=[COL_BP, COL_ITEM_NAME], number_cols=[COL_QTY])

    st.divider()
    st.subheader("ì „ì£¼ ëŒ€ë¹„ ê¸‰ì¦ SKU ë¦¬í¬íŠ¸ (+30% ì´ìƒ ì¦ê°€)")
    if prev_week is None:
        st.info("ì „ì£¼ ë¹„êµë¥¼ ìœ„í•´ì„œëŠ” ì„ íƒ ì£¼ì°¨ ì´ì „ì˜ ì£¼ì°¨ ë°ì´í„°ê°€ í•„ìš”í•©ë‹ˆë‹¤.")
    else:
        spike_df = build_spike_report_only(wdf, prev_wdf)
        render_pretty_table(spike_df, height=520, wrap_cols=[COL_ITEM_NAME, "BPëª…(ìš”ì²­ìˆ˜ëŸ‰)"], number_cols=["ì´ì „_ìš”ì²­ìˆ˜ëŸ‰", "í˜„ì¬_ìš”ì²­ìˆ˜ëŸ‰", "ì¦ê°€ë°°ìˆ˜"])

# =========================
# â‘£ ì›”ê°„ìš”ì•½
# =========================
elif nav == "â‘£ ì›”ê°„ìš”ì•½":
    st.subheader("ì›”ê°„ìš”ì•½")
    d = df_view.copy()
    if d.empty:
        st.info("í‘œì‹œí•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        st.stop()

    if "_month_label" not in d.columns or "_month_key_num" not in d.columns:
        st.warning("ì›” ë¼ë²¨/í‚¤ ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤.")
        st.stop()

    tmp = d[["_month_label", "_month_key_num"]].dropna().drop_duplicates("_month_label").copy()
    tmp["_month_key_num"] = pd.to_numeric(tmp["_month_key_num"], errors="coerce")
    tmp = tmp.dropna(subset=["_month_key_num"]).sort_values("_month_key_num")
    month_list = tmp["_month_label"].astype(str).tolist()

    if not month_list:
        st.info("ì›” ëª©ë¡ì´ ì—†ìŠµë‹ˆë‹¤. RAWì˜ 'ë…„', 'ì›”1' ì»¬ëŸ¼ì„ í™•ì¸í•´ ì£¼ì„¸ìš”.")
        st.stop()

    sel_month = st.selectbox("ì›” ì„ íƒ", month_list, index=len(month_list) - 1, key="m_sel_month")
    mdf = d[d["_month_label"].astype(str) == str(sel_month)].copy()

    cur_key_num = month_key_num_from_label(sel_month)
    cur_idx = month_list.index(sel_month) if sel_month in month_list else None
    prev_mdf = pd.DataFrame()
    prev_month = None
    if cur_idx is not None and cur_idx > 0:
        prev_month = month_list[cur_idx - 1]
        prev_mdf = d[d["_month_label"].astype(str) == str(prev_month)].copy()

    comment_items = []
    comment_items += new_bp_comment(all_df=d, cur_df=mdf, key_col_num="_month_key_num", cur_key_num=cur_key_num)
    comment_items += period_kpi_delta_comment(cur_df=mdf, prev_df=prev_mdf)
    comment_items += category_top_comment(mdf, top_n=2)
    comment_items += concentration_comment(mdf)
    comment_items += undated_ship_risk_comment(mdf)
    render_numbered_block("ì›”ê°„ íŠ¹ì´ì‚¬í•­ (ìë™ ì½”ë©˜íŠ¸)", comment_items)
    if prev_month:
        st.caption(f"â€» ë¹„êµ ê¸°ì¤€: ì„ íƒ ì›”({sel_month}) vs ì „ì›”({prev_month})")
    st.divider()

    st.markdown("### ğŸ“Œ ì›”ê°„ ë¦¬í¬íŠ¸ ìƒì„±(ë³µì‚¬í•´ì„œ ìŠ¬ë™ì— ë°”ë¡œ ë¶™ì—¬ë„£ê¸°)")
    next_month = month_label_next(sel_month)
    if st.button("ğŸ“ ì›”ê°„ ë¦¬í¬íŠ¸ ìƒì„±", key="btn_month_report"):
        st.session_state["monthly_report_text"] = _build_monthly_report_text(
            base_df=d,
            sel_month_label=sel_month,
            prev_month_label=prev_month,
            next_month_label=next_month
        )

    if "monthly_report_text" in st.session_state:
        st.text_area("ì›”ê°„ ë¦¬í¬íŠ¸ (Ctrl+Cë¡œ ë³µì‚¬)", value=st.session_state["monthly_report_text"], height=420)

    st.divider()
    st.subheader("ì›” ì„ íƒ â†’ Top 10 (BP/í’ˆëª©ì½”ë“œ/í’ˆëª©ëª…/ìš”ì²­ìˆ˜ëŸ‰)")
    top10 = (
        mdf.groupby([COL_BP, COL_ITEM_CODE, COL_ITEM_NAME], dropna=False)[COL_QTY]
        .sum(min_count=1).reset_index()
        .sort_values(COL_QTY, ascending=False)
        .head(10)
        .copy()
    )
    top10.insert(0, "ìˆœìœ„", range(1, len(top10) + 1))
    top10[COL_QTY] = pd.to_numeric(top10[COL_QTY], errors="coerce").fillna(0).round(0).astype(int)
    render_pretty_table(top10, height=520, wrap_cols=[COL_BP, COL_ITEM_NAME], number_cols=[COL_QTY])

    st.divider()
    st.subheader("ì „ì›” ëŒ€ë¹„ ê¸‰ì¦ SKU ë¦¬í¬íŠ¸ (+30% ì´ìƒ ì¦ê°€)")
    if prev_month is None:
        st.info("ì „ì›” ë¹„êµë¥¼ ìœ„í•´ì„œëŠ” ì„ íƒ ì›” ì´ì „ì˜ ì›” ë°ì´í„°ê°€ í•„ìš”í•©ë‹ˆë‹¤.")
    else:
        spike_df = build_spike_report_only(mdf, prev_mdf)
        render_pretty_table(spike_df, height=520, wrap_cols=[COL_ITEM_NAME, "BPëª…(ìš”ì²­ìˆ˜ëŸ‰)"], number_cols=["ì´ì „_ìš”ì²­ìˆ˜ëŸ‰", "í˜„ì¬_ìš”ì²­ìˆ˜ëŸ‰", "ì¦ê°€ë°°ìˆ˜"])

# =========================
# â‘¤ êµ­ê°€ë³„ ì¡°íšŒ
# =========================
elif nav == "â‘¤ êµ­ê°€ë³„ ì¡°íšŒ":
    st.subheader("êµ­ê°€ë³„ ì¡°íšŒ (ê±°ë˜ì²˜êµ¬ë¶„2 ê¸°ì¤€)")
    if not need_cols(df_view, [COL_CUST2, COL_QTY, COL_LT2, COL_ORDER_NO], "êµ­ê°€ë³„ ì¡°íšŒ"):
        st.stop()

    base = df_view.copy()
    out = base.groupby(COL_CUST2, dropna=False).agg(
        ìš”ì²­ìˆ˜ëŸ‰_í•©=(COL_QTY, "sum"),
        í‰ê· _ë¦¬ë“œíƒ€ì„_ì‘ì—…ì™„ë£Œê¸°ì¤€=(COL_LT2, "mean"),
        ë¦¬ë“œíƒ€ì„_ì¤‘ê°„ê°’_ì‘ì—…ì™„ë£Œê¸°ì¤€=(COL_LT2, "median"),
        p90_tmp=(COL_LT2, lambda s: s.quantile(0.9)),
        ì§‘ê³„í–‰ìˆ˜_í‘œë³¸=(COL_CUST2, "size"),
    ).reset_index()
    out = out.rename(columns={"p90_tmp": "ë¦¬ë“œíƒ€ì„ ëŠë¦° ìƒìœ„10% ê¸°ì¤€(P90)"})

    # âœ… ì¶œê³ ê±´ìˆ˜ = ì£¼ë¬¸ë²ˆí˜¸ distinct (ê±°ë˜ì²˜êµ¬ë¶„2ë³„)
    tmp = base[[COL_CUST2, COL_ORDER_NO]].copy()
    tmp["_ord"] = tmp[COL_ORDER_NO].astype(str).str.strip().replace({"": pd.NA, "nan": pd.NA, "None": pd.NA})
    rep_cnt = tmp.dropna(subset=["_ord"]).groupby(COL_CUST2)["_ord"].nunique()
    out["ì¶œê³ ê±´ìˆ˜"] = out[COL_CUST2].astype(str).map(rep_cnt).fillna(0).astype(int)

    for c in ["í‰ê· _ë¦¬ë“œíƒ€ì„_ì‘ì—…ì™„ë£Œê¸°ì¤€", "ë¦¬ë“œíƒ€ì„_ì¤‘ê°„ê°’_ì‘ì—…ì™„ë£Œê¸°ì¤€", "ë¦¬ë“œíƒ€ì„ ëŠë¦° ìƒìœ„10% ê¸°ì¤€(P90)"]:
        out[c] = pd.to_numeric(out[c], errors="coerce").round(2)

    out["ìš”ì²­ìˆ˜ëŸ‰_í•©"] = pd.to_numeric(out["ìš”ì²­ìˆ˜ëŸ‰_í•©"], errors="coerce").fillna(0).round(0).astype(int)
    out["ì§‘ê³„í–‰ìˆ˜_í‘œë³¸"] = pd.to_numeric(out["ì§‘ê³„í–‰ìˆ˜_í‘œë³¸"], errors="coerce").fillna(0).astype(int)

    out = out.sort_values("ìš”ì²­ìˆ˜ëŸ‰_í•©", ascending=False, na_position="last")

    render_pretty_table(out, height=520, wrap_cols=[COL_CUST2], number_cols=["ìš”ì²­ìˆ˜ëŸ‰_í•©", "ì¶œê³ ê±´ìˆ˜", "ì§‘ê³„í–‰ìˆ˜_í‘œë³¸"])
    st.caption("â€» P90ì€ â€˜ëŠë¦° ìƒìœ„ 10%â€™ ê²½ê³„ê°’(ë¦¬ë“œíƒ€ì„ì´ í° êµ¬ê°„)ì…ë‹ˆë‹¤.")

# =========================
# â‘¥ BPëª…ë³„ ì¡°íšŒ
# =========================
elif nav == "â‘¥ BPëª…ë³„ ì¡°íšŒ":
    st.subheader("BPëª…ë³„ ì¡°íšŒ")
    if not need_cols(df_view, [COL_BP, COL_QTY, COL_LT2, COL_ORDER_NO], "BPëª…ë³„ ì¡°íšŒ"):
        st.stop()

    base = df_view.copy()
    out = base.groupby(COL_BP, dropna=False).agg(
        ìš”ì²­ìˆ˜ëŸ‰_í•©=(COL_QTY, "sum"),
        í‰ê· _ë¦¬ë“œíƒ€ì„_ì‘ì—…ì™„ë£Œê¸°ì¤€=(COL_LT2, "mean"),
        ë¦¬ë“œíƒ€ì„_ì¤‘ê°„ê°’_ì‘ì—…ì™„ë£Œê¸°ì¤€=(COL_LT2, "median"),
        ìµœê·¼_ì¶œê³ ì¼=(COL_SHIP, "max"),
        ìµœê·¼_ì‘ì—…ì™„ë£Œì¼=(COL_DONE, "max"),
        ì§‘ê³„í–‰ìˆ˜_í‘œë³¸=(COL_BP, "size"),
    ).reset_index()

    # âœ… ì¶œê³ ê±´ìˆ˜ = ì£¼ë¬¸ë²ˆí˜¸ distinct (BPë³„)
    tmp = base[[COL_BP, COL_ORDER_NO]].copy()
    tmp["_ord"] = tmp[COL_ORDER_NO].astype(str).str.strip().replace({"": pd.NA, "nan": pd.NA, "None": pd.NA})
    rep_cnt = tmp.dropna(subset=["_ord"]).groupby(COL_BP)["_ord"].nunique()
    out["ì¶œê³ ê±´ìˆ˜"] = out[COL_BP].astype(str).map(rep_cnt).fillna(0).astype(int)

    out["ìš”ì²­ìˆ˜ëŸ‰_í•©"] = pd.to_numeric(out["ìš”ì²­ìˆ˜ëŸ‰_í•©"], errors="coerce").fillna(0).round(0).astype(int)
    for c in ["í‰ê· _ë¦¬ë“œíƒ€ì„_ì‘ì—…ì™„ë£Œê¸°ì¤€", "ë¦¬ë“œíƒ€ì„_ì¤‘ê°„ê°’_ì‘ì—…ì™„ë£Œê¸°ì¤€"]:
        out[c] = pd.to_numeric(out[c], errors="coerce").round(2)

    out["ìµœê·¼_ì¶œê³ ì¼"] = out["ìµœê·¼_ì¶œê³ ì¼"].apply(fmt_date)
    out["ìµœê·¼_ì‘ì—…ì™„ë£Œì¼"] = out["ìµœê·¼_ì‘ì—…ì™„ë£Œì¼"].apply(fmt_date)
    out["ì§‘ê³„í–‰ìˆ˜_í‘œë³¸"] = pd.to_numeric(out["ì§‘ê³„í–‰ìˆ˜_í‘œë³¸"], errors="coerce").fillna(0).astype(int)

    out = out.sort_values("ìš”ì²­ìˆ˜ëŸ‰_í•©", ascending=False, na_position="last")
    render_pretty_table(out, height=520, wrap_cols=[COL_BP], number_cols=["ìš”ì²­ìˆ˜ëŸ‰_í•©", "ì¶œê³ ê±´ìˆ˜", "ì§‘ê³„í–‰ìˆ˜_í‘œë³¸"])

st.caption("â€» ëª¨ë“  ì§‘ê³„ëŠ” Google Sheet RAW ê¸°ë°˜ì´ë©°, ì œí’ˆë¶„ë¥˜(B0/B1) ê³ ì • + ì„ íƒí•œ í•„í„° ë²”ìœ„ ë‚´ì—ì„œ ê³„ì‚°ë©ë‹ˆë‹¤.")
